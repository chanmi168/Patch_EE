{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression ultimate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import math\n",
    "from math import sin\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "torch.manual_seed(0)\n",
    "\n",
    "i_seed = 0\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../../PatchWand/') # add this line so Data and data are visible in this file\n",
    "\n",
    "# from PatchWand import *\n",
    "from plotting_tools import *\n",
    "from setting import *\n",
    "# from models import *\n",
    "# from models_CNN import *\n",
    "# from unet_extension.models import *\n",
    "# # from unet_extension.models_CNN import *\n",
    "# from unet_extension.training_util import *\n",
    "# from unet_extension.dataset_util import *\n",
    "# from EE_extension.models import *\n",
    "# from unet_extension.models_CNN import *\n",
    "# from EE_extension.training_util import *\n",
    "from VO2_extension1111.dataset_util import *\n",
    "from VO2_extension1111.training_util import *\n",
    "from VO2_extension1111.evaluation_util import *\n",
    "\n",
    "\n",
    "from evaluate import *\n",
    "\n",
    "from stage3_preprocess import *\n",
    "# from training_util import *\n",
    "# from dataset_util import *\n",
    "from dataIO import *\n",
    "from stage4_regression import *\n",
    "\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = MLPRegressor()\n",
    "\n",
    "# m.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import pytz\n",
    "\n",
    "# tz_NY = pytz.timezone('America/New_York') \n",
    "# datetime_start = datetime.now(tz_NY)\n",
    "# print(\"start time:\", datetime_start.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
    "\n",
    "\n",
    "\n",
    "# datetime_end = datetime.now(tz_NY)\n",
    "# print(\"end time:\", datetime_end.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
    "\n",
    "# duration = datetime_end-datetime_start\n",
    "# duration_in_s = duration.total_seconds()\n",
    "# days    = divmod(duration_in_s, 86400)        # Get days (without [0]!)\n",
    "# hours   = divmod(days[1], 3600)               # Use remainder of days to calc hours\n",
    "# minutes = divmod(hours[1], 60)                # Use remainder of hours to calc minutes\n",
    "# seconds = divmod(minutes[1], 1)               # Use remainder of minutes to calc seconds\n",
    "# print(\"Time between dates: %d days, %d hours, %d minutes and %d seconds\" % (days[0], hours[0], minutes[0], seconds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='EE_estimate')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--training_params_file', metavar='training_params_file', help='training_params_file',\n",
    "                    default='training_params_list.json')\n",
    "\n",
    "\n",
    "# checklist 3: comment first line, uncomment second line\n",
    "# args = parser.parse_args(['--input_folder', '../../data/stage3/', \n",
    "# args = parser.parse_args(['--input_folder', '../../data/stage3_norun/', \n",
    "# args = parser.parse_args(['--input_folder', '../../data/stage3-1_windowing/CDC_dataset/win60_overlap95_seq20_norm/', \n",
    "args = parser.parse_args(['--input_folder', '../../../data/stage3/win60_overlap90/', \n",
    "# args = parser.parse_args(['--input_folder', '../../data/stage3_TEST/', \n",
    "#                           '--output_folder', '../../data/stage4/ML_regression/',\n",
    "                          '--output_folder', '../../../data/stage4/ML_regression/TEST/',\n",
    "                          '--training_params_file', 'training_params_ML.json',\n",
    "#                           '--training_params_file', 'training_params_baseline.json',\n",
    "                         ])\n",
    "# args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir = args.input_folder\n",
    "outputdir = args.output_folder\n",
    "training_params_file = args.training_params_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get training params and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader('meta', inputdir).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3_dict = data_loader('stage3_dict', inputdir).item()\n",
    "# stage3_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['list_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_params_file) as json_file:\n",
    "    training_params_list = json.load(json_file)\n",
    "\n",
    "for training_params in training_params_list:\n",
    "    # include device in training_params\n",
    "#     device = torch.device('cuda:{}'.format(int(training_params['cuda_i'])) if torch.cuda.is_available() else 'cpu')\n",
    "#     training_params['device'] = device\n",
    "\n",
    "    if 'training_mode' in training_params:\n",
    "        training_mode = training_params['training_mode']\n",
    "    else:\n",
    "        training_params = 'subject_ind'\n",
    "\n",
    "#     training_params['CV_config'] = {\n",
    "#         'subject_id': 101,\n",
    "#         'task_ids': [0,1,2,3,4,5],\n",
    "#     }\n",
    "    \n",
    "    task_id = [0, 1, 2, 3, 4, 5]   \n",
    "    # task_id = [6]\n",
    "    # task_id = [1, 2]\n",
    "\n",
    "    training_params['CV_config'] = {\n",
    "        'subject_id': 113,\n",
    "        'task_ids': task_id,\n",
    "        # 'reject_subject_id': [101, 102, 103, 104, 105, 109]\n",
    "        # 'reject_subject_id': [101, 102, 103, 105, 109, 115]\n",
    "        'reject_subject_id': [101, 102, 103, 109]\n",
    "        # 'reject_subject_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,112,114, 115]\n",
    "    }\n",
    "    \n",
    "    stage3_dict = data_loader('stage3_dict', inputdir).item()\n",
    "    \n",
    "    training_params['sequence'] = stage3_dict['sequence']\n",
    "    training_params['list_signal'] = stage3_dict['list_signal']\n",
    "    training_params['list_feature'] = stage3_dict['list_feature']\n",
    "\n",
    "    print( training_params['list_feature'] )\n",
    "#           \"feature_names\": [\"HR_patch\", \"weight\", \"height\", \"gender\", \"age\", \"0.00Hz\", \"3.91Hz\", \"7.81Hz\", \"11.72Hz\", \"15.62Hz\", \"19.53Hz\", \"23.44Hz\", \"scg_std\", \"scg_std_perc\"],\n",
    "\n",
    "    training_params['list_output'] = stage3_dict['list_output']\n",
    "    training_params['list_meta'] = stage3_dict['list_meta']\n",
    "    training_params['FS_RESAMPLE_DL'] = stage3_dict['FS_RESAMPLE_DL']\n",
    "    training_params['subject_ids'] = stage3_dict['subject_ids']\n",
    "    training_params['task_ids'] = stage3_dict['task_ids']\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#           \"feature_names\": [\"HR_patch\", \"weight\", \"height\", \"gender\", \"age\", \"0.00Hz\", \"3.91Hz\", \"7.81Hz\", \"11.72Hz\", \"15.62Hz\", \"19.53Hz\", \"23.44Hz\"],\n",
    "\n",
    "#     input_CV = '../../data/stage3/113/CV2/'\n",
    "#     dataloaders, dataset_sizes = get_loaders(input_CV, training_params)\n",
    "    dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "    print('data dimensions are:', dataloaders['train'].dataset.ecg.shape)\n",
    "\n",
    "    data_dimensions = dataloaders['train'].dataset.__getitem__(0)[0].size()\n",
    "    training_params['data_dimensions'] = list(data_dimensions)\n",
    "    \n",
    "    # sweep_name = training_params['sweep_name'] \n",
    "    \n",
    "    sweep_name = training_params['model_name']\n",
    "    training_params['sweep_name'] = sweep_name\n",
    "\n",
    "training_params = training_params_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputdir = outputdir + training_params['model_name'] + '/'\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "    \n",
    "training_params['outputdir'] = outputdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dataloaders['train'].dataset.data[0,2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dataloaders['train'].dataset.data.ecg[50,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaa= dataloaders['train'].dataset.feature[:, training_params['feature_names'].index('scg_std')]\n",
    "# ccc= dataloaders['train'].dataset.feature[:, training_params['feature_names'].index('HR_patch')]\n",
    "\n",
    "\n",
    "# bbb = dataloaders['train'].dataset.label[:, training_params['output_names'].index('EErq_cosmed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders['train'].dataset.feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders['train'].dataset.label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, feature_name in enumerate(training_params['feature_names']):\n",
    "#     fig, ax = plt.subplots(1,1,figsize=(5,5), dpi=80)\n",
    "    \n",
    "#     ax.scatter(dataloaders['train'].dataset.feature[:,i], dataloaders['train'].dataset.label)\n",
    "#     ax.set_xlabel(feature_name)\n",
    "#     ax.set_ylabel('EE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['subject_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader('meta', inputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['output_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"feature_names\": [\"HR_patch\", \"weight\", \"height\", \"gender\", \"age\", \"0.00Hz\", \"3.91Hz\", \"7.81Hz\", \"11.72Hz\", \"15.62Hz\", \"19.53Hz\", \"23.44Hz\"],\n",
    "# training_params['feature_names'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['meta_names'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HP from Mobashir's paper\n",
    "- learning rate = 0.05, \n",
    "- max_depth=10, \n",
    "- subsample=0.6, \n",
    "- colsample_bytree = 0.7, \n",
    "- n_estimators = 100, \n",
    "- min_child_weight = 2, \n",
    "- gamma = 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders['val'].dataset.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dataloaders['train'].dataset.label[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train, feature_train, label_train, meta_train = get_samples(inputdir, 'train/', training_params)\n",
    "# data_val, feature_val, label_val, meta_val = get_samples(inputdir, 'val/', training_params)\n",
    "\n",
    "# # zero mean unit variance\n",
    "# feature_mean = np.mean(feature_train, axis=0)\n",
    "# feature_std = np.std(feature_train, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# addecd feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(feature_names, feature_importances, fig_name=None, outputdir=None, show_plot=False, log_wandb=False):\n",
    "\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5,5), dpi=100)\n",
    "    fontsize = 12\n",
    "    ax.barh(feature_names, feature_importances)\n",
    "    ax.tick_params(axis='both', labelsize=fontsize)\n",
    "    ax_no_top_right(ax)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if outputdir is not None:\n",
    "        if not os.path.exists(outputdir):\n",
    "            os.makedirs(outputdir)\n",
    "        if fig_name is None:\n",
    "            fig_name = 'feature_importance'\n",
    "        else:\n",
    "            fig_name = fig_name\n",
    "\n",
    "        fig.savefig(outputdir + fig_name, bbox_inches='tight', transparent=False)\n",
    "\n",
    "    if log_wandb:\n",
    "        wandb.log({fig_name: wandb.Image(fig)})\n",
    "        \n",
    "    if show_plot == False:\n",
    "        plt.close(fig)\n",
    "        pyplot.close(fig)\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_params['wandb']:\n",
    "    os.environ[\"WANDB_DIR\"] = os.path.abspath(outputdir)\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = 'ML_regression'\n",
    "    wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wandb login --relogin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputdir_numeric = outputdir + 'numeric_results/'\n",
    "# if outputdir_numeric is not None:\n",
    "#     if not os.path.exists(outputdir_numeric):\n",
    "#         os.makedirs(outputdir_numeric)\n",
    "        \n",
    "    \n",
    "# outputdir_modelout = outputdir + 'model_output/'\n",
    "# if outputdir_modelout is not None:\n",
    "#     if not os.path.exists(outputdir_modelout):\n",
    "#         os.makedirs(outputdir_modelout)\n",
    "        \n",
    "\n",
    "# outputdir_featureimportance = outputdir + 'feature_importance/'\n",
    "# if outputdir_modelout is not None:\n",
    "#     if not os.path.exists(outputdir_featureimportance):\n",
    "#         os.makedirs(outputdir_featureimportance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputdirs(training_params):\n",
    "\n",
    "    outputdir = training_params['outputdir']\n",
    "    i_rep = training_params['i_rep']\n",
    "\n",
    "    outputdir_sweep = outputdir+'rep{}/{}-{}feat/'.format(i_rep, training_params['model_name'], len(training_params['feature_names']))\n",
    "\n",
    "    outputdir_numeric = outputdir_sweep + 'numeric_results/'\n",
    "    if outputdir_numeric is not None:\n",
    "        if not os.path.exists(outputdir_numeric):\n",
    "            os.makedirs(outputdir_numeric)\n",
    "\n",
    "    outputdir_modelout = outputdir_sweep + 'model_output/'\n",
    "    if outputdir_modelout is not None:\n",
    "        if not os.path.exists(outputdir_modelout):\n",
    "            os.makedirs(outputdir_modelout)\n",
    "\n",
    "    outputdir_featureimportance = outputdir_sweep + 'feature_importance/'\n",
    "    if outputdir_modelout is not None:\n",
    "        if not os.path.exists(outputdir_featureimportance):\n",
    "            os.makedirs(outputdir_featureimportance)\n",
    "\n",
    "    training_params['outputdir_sweep'] = outputdir_sweep\n",
    "    training_params['outputdir_numeric'] = outputdir_numeric\n",
    "    training_params['outputdir_modelout'] = outputdir_modelout\n",
    "    training_params['outputdir_featureimportance'] = outputdir_featureimportance\n",
    "\n",
    "    return training_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, test, store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['CV_config']['subject_id'] = 106\n",
    "# dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_performance_train = pd.DataFrame()\n",
    "# df_performance_val = pd.DataFrame()\n",
    "\n",
    "# df_outputlabel_train = pd.DataFrame()\n",
    "# df_outputlabel_val = pd.DataFrame()\n",
    "\n",
    "\n",
    "# # training_params['output_names'] = ['EE_cosmed']\n",
    "\n",
    "# for subject_id in training_params['subject_ids']:\n",
    "    \n",
    "# #     if subject_id!=117:\n",
    "# #         continue\n",
    "#     print(subject_id)\n",
    "#     training_params['CV_config']['subject_id'] = subject_id\n",
    "\n",
    "#     try:\n",
    "#         dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "#     except:\n",
    "#         print('An exception occurred for subject:', subject_id)\n",
    "#         continue\n",
    "\n",
    "    \n",
    "# #     i_feature = training_params['feature_names'].index('HR_patch')\n",
    "# #     i_label = training_params['output_names'].index('EE_cosmed')\n",
    "\n",
    "    \n",
    "#     if training_params['model_name']=='LinearRegression':\n",
    "#         model = LinearRegression()\n",
    "#     elif training_params['model_name']=='XGBRegressor':\n",
    "# #         model = XGBRegressor(learning_rate=0.05, max_depth=10, subsample=0.6, colsample_bytree=0.7, n_estimators=100, min_child_weight=2, gamma=0.3)\n",
    "#         model = XGBRegressor(learning_rate=0.05, max_depth=50, subsample=0.6, colsample_bytree=0.7, n_estimators=100, min_child_weight=2, gamma=0.001)\n",
    "    \n",
    "#     feature_train = dataloaders['train'].dataset.feature\n",
    "#     feature_val = dataloaders['val'].dataset.feature\n",
    "    \n",
    "# #     sys.exit()\n",
    "\n",
    "#     # zero mean unit variance\n",
    "# #     feature_mean = np.mean(feature_train, axis=0)\n",
    "# #     feature_std = np.std(feature_train, axis=0)\n",
    "\n",
    "# #     feature_train = (feature_train-feature_mean)/feature_std\n",
    "# #     feature_val = (feature_val-feature_mean)/feature_std\n",
    "\n",
    "    \n",
    "#     label_train = dataloaders['train'].dataset.label\n",
    "#     label_val = dataloaders['val'].dataset.label\n",
    "    \n",
    "#     model = model.fit(feature_train, label_train)\n",
    "#     label_est_train = model.predict(feature_train)\n",
    "#     label_est_val = model.predict(feature_val)\n",
    "    \n",
    "#     label_train = label_train.squeeze()\n",
    "#     label_val = label_val.squeeze()\n",
    "#     label_est_train = label_est_train.squeeze()\n",
    "#     label_est_val = label_est_val.squeeze()\n",
    "    \n",
    "# #     sys.exit()\n",
    "#     if 'perc' in training_params['output_names'][0]:\n",
    "#         i_meta = training_params['meta_names'].index('EEavg_est')\n",
    "#         meta_train = dataloaders['train'].dataset.meta[:, i_meta]\n",
    "#         meta_val = dataloaders['val'].dataset.meta[:, i_meta]\n",
    "    \n",
    "#         label_train = label_train*meta_train\n",
    "#         label_val = label_val*meta_val\n",
    "#         label_est_train = label_est_train*meta_train\n",
    "#         label_est_val = label_est_val*meta_val\n",
    "#     elif 'weighted' in training_params['output_names'][0]:\n",
    "# #         print('hi')\n",
    "#         i_meta = training_params['meta_names'].index('weight')\n",
    "#         meta_train = dataloaders['train'].dataset.meta[:, i_meta]\n",
    "#         meta_val = dataloaders['val'].dataset.meta[:, i_meta]\n",
    "    \n",
    "#         label_train = label_train*meta_train\n",
    "#         label_val = label_val*meta_val\n",
    "#         label_est_train = label_est_train*meta_train\n",
    "#         label_est_val = label_est_val*meta_val\n",
    "    \n",
    "# #     sys.exit()\n",
    "    \n",
    "# #     sys.exit()\n",
    "    \n",
    "#     # get performance df for training and testing dataset\n",
    "#     df_performance_train = df_performance_train.append( get_df_performance(label_train, label_est_train, subject_id, task), ignore_index=True )\n",
    "#     df_performance_train.to_csv(outputdir_numeric+'df_performance_train.csv', index=False)\n",
    "\n",
    "#     df_outputlabel_train = df_outputlabel_train.append(\n",
    "#         pd.DataFrame( {\n",
    "#         'label_est': label_est_train,\n",
    "#         'label': label_train,\n",
    "#         'CV': [subject_id]*label_train.shape[0],\n",
    "#         'task': [task]*label_train.shape[0],\n",
    "#         }), ignore_index=True )\n",
    "\n",
    "#     df_outputlabel_train.to_csv(outputdir_numeric+'df_outputlabel_train.csv', index=False)\n",
    "\n",
    "#     df_performance_val = df_performance_val.append( get_df_performance(label_val, label_est_val, subject_id, task), ignore_index=True )\n",
    "#     df_performance_val.to_csv(outputdir_numeric+'df_performance_val.csv', index=False)\n",
    "\n",
    "#     df_outputlabel_val = df_outputlabel_val.append(\n",
    "#         pd.DataFrame( {\n",
    "#         'label_est': label_est_val,\n",
    "#         'label': label_val,\n",
    "#         'CV': [subject_id]*label_val.shape[0],\n",
    "#         'task': [task]*label_val.shape[0]\n",
    "#         }), ignore_index=True )\n",
    "\n",
    "#     df_outputlabel_val.to_csv(outputdir_numeric+'df_outputlabel_val.csv', index=False)\n",
    "    \n",
    "#     if training_params['model_name']=='XGBRegressor':\n",
    "#         plot_feature_importances(training_params['feature_names'], model.feature_importances_, fig_name='feature_importance_'+str(subject_id), outputdir=outputdir_featureimportance, show_plot=False)\n",
    "\n",
    "\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['CV_config']['subject_id'] = 101\n",
    "# dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders['train'].dataset.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "\n",
    "\n",
    "\n",
    "# model = XGBRegressor(learning_rate=0.05, max_depth=10, subsample=0.6, colsample_bytree=0.7, n_estimators=1, min_child_weight=2, gamma=0.001, verbosity=0, seed=training_params['i_rep'], importance_type='weight')\n",
    "\n",
    "# feature_train = dataloaders['train'].dataset.feature\n",
    "# feature_val = dataloaders['val'].dataset.feature\n",
    "\n",
    "# meta_train = dataloaders['train'].dataset.meta\n",
    "# meta_val = dataloaders['val'].dataset.meta\n",
    "\n",
    "# print(feature_train.shape, feature_val.shape)\n",
    "\n",
    "\n",
    "# label_train = dataloaders['train'].dataset.label\n",
    "# label_val = dataloaders['val'].dataset.label\n",
    "\n",
    "# model = model.fit(feature_train, label_train)\n",
    "# label_est_train = model.predict(feature_train)\n",
    "# label_est_val = model.predict(feature_val)\n",
    "\n",
    "# label_train = label_train.squeeze()\n",
    "# label_val = label_val.squeeze()\n",
    "# label_est_train = label_est_train.squeeze()\n",
    "# label_est_val = label_est_val.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,2))\n",
    "# plt.plot(training_params['feature_names'], model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_master(training_params):\n",
    "\n",
    "    # training_params = get_regressor_names(training_params)\n",
    "    training_params = get_outputdirs(training_params) # could be tricky since it changes several keys\n",
    "\n",
    "    print(training_params['outputdir_sweep'])\n",
    "    df_performance_train = pd.DataFrame()\n",
    "    df_performance_val = pd.DataFrame()\n",
    "\n",
    "    df_outputlabel_train = pd.DataFrame()\n",
    "    df_outputlabel_val = pd.DataFrame()\n",
    "\n",
    "\n",
    "    # training_params['output_names'] = ['EE_cosmed']\n",
    "\n",
    "    for subject_id in training_params['subject_ids']:\n",
    "\n",
    "        if subject_id in training_params['CV_config']['reject_subject_id']:\n",
    "            continue\n",
    "\n",
    "    #     if subject_id!=117:\n",
    "    #         continue\n",
    "        print(subject_id)\n",
    "        training_params['CV_config']['subject_id'] = subject_id\n",
    "\n",
    "        dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "\n",
    "#         try:\n",
    "#             dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "#         except:\n",
    "#             print('An exception occurred for subject:', subject_id)\n",
    "#             continue\n",
    "\n",
    "\n",
    "    #     i_feature = training_params['feature_names'].index('HR_patch')\n",
    "    #     i_label = training_params['output_names'].index('EE_cosmed')\n",
    "\n",
    "\n",
    "        if training_params['model_name']=='LinearRegression':\n",
    "            model = LinearRegression()\n",
    "        elif training_params['model_name']=='XGBRegressor':\n",
    "    #         model = XGBRegressor(learning_rate=0.05, max_depth=10, subsample=0.6, colsample_bytree=0.7, n_estimators=100, min_child_weight=2, gamma=0.3)\n",
    "            model = XGBRegressor(learning_rate=0.05, max_depth=50, subsample=0.6, colsample_bytree=0.7, n_estimators=100, min_child_weight=2, gamma=0.001, verbosity=0, seed=training_params['i_rep'])\n",
    "        elif training_params['model_name']=='MLPRegressor':\n",
    "            # model = MLPRegressor(random_state=1, max_iter=1000)\n",
    "            hidden_layer_sizes =tuple()\n",
    "            training_params['hidden_dim'] = len(training_params['feature_names'])\n",
    "            for i in range(training_params['n_layers']):\n",
    "                hidden_layer_sizes = hidden_layer_sizes + (training_params['hidden_dim'],)\n",
    "            \n",
    "            model = MLPRegressor(max_iter=25, hidden_layer_sizes=hidden_layer_sizes, batch_size=64, random_state=training_params['i_rep'])\n",
    "\n",
    "\n",
    "        feature_train = dataloaders['train'].dataset.feature\n",
    "        feature_val = dataloaders['val'].dataset.feature\n",
    "        \n",
    "        meta_train = dataloaders['train'].dataset.meta\n",
    "        meta_val = dataloaders['val'].dataset.meta\n",
    "        \n",
    "        print(feature_train.shape, feature_val.shape)\n",
    "\n",
    "    #     sys.exit()\n",
    "\n",
    "        # zero mean unit variance\n",
    "    #     feature_mean = np.mean(feature_train, axis=0)\n",
    "    #     feature_std = np.std(feature_train, axis=0)\n",
    "\n",
    "    #     feature_train = (feature_train-feature_mean)/feature_std\n",
    "    #     feature_val = (feature_val-feature_mean)/feature_std\n",
    "\n",
    "\n",
    "        label_train = dataloaders['train'].dataset.label\n",
    "        label_val = dataloaders['val'].dataset.label\n",
    "\n",
    "        model = model.fit(feature_train, label_train)\n",
    "        label_est_train = model.predict(feature_train)\n",
    "        label_est_val = model.predict(feature_val)\n",
    "        \n",
    "        label_train = label_train.squeeze()\n",
    "        label_val = label_val.squeeze()\n",
    "        label_est_train = label_est_train.squeeze()\n",
    "        label_est_val = label_est_val.squeeze()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "#         if 'perc' in training_params['output_names'][0]:\n",
    "#             i_meta = training_params['meta_names'].index('EEavg_est')\n",
    "#             meta_train = dataloaders['train'].dataset.meta[:, i_meta]\n",
    "#             meta_val = dataloaders['val'].dataset.meta[:, i_meta]\n",
    "\n",
    "#             label_train = label_train*meta_train\n",
    "#             label_val = label_val*meta_val\n",
    "#             label_est_train = label_est_train*meta_train\n",
    "#             label_est_val = label_est_val*meta_val\n",
    "#         elif 'weighted' in training_params['output_names'][0]:\n",
    "#             i_meta = training_params['meta_names'].index('weight')\n",
    "#             meta_train = dataloaders['train'].dataset.meta[:, i_meta]\n",
    "#             meta_val = dataloaders['val'].dataset.meta[:, i_meta]\n",
    "\n",
    "#             label_train = label_train*meta_train\n",
    "#             label_val = label_val*meta_val\n",
    "#             label_est_train = label_est_train*meta_train\n",
    "#             label_est_val = label_est_val*meta_val\n",
    "\n",
    "    #     sys.exit()\n",
    "        task = training_params['output_names'][0]\n",
    "        task_name = task.split('_')[0]\n",
    "    #     sys.exit()\n",
    "\n",
    "        # get performance df for training and testing dataset\n",
    "        df_performance_train = df_performance_train.append( get_df_performance(label_train, label_est_train, subject_id, task), ignore_index=True )\n",
    "        df_performance_train.to_csv(training_params['outputdir_numeric']+'df_performance_train.csv', index=False)\n",
    "\n",
    "        df_outputlabel_train = df_outputlabel_train.append(\n",
    "            pd.DataFrame( {\n",
    "            'label_est': label_est_train,\n",
    "            'label': label_train,\n",
    "            'CV': [subject_id]*label_train.shape[0],\n",
    "            'task': [task]*label_train.shape[0],\n",
    "            'activity': meta_train[:,1],\n",
    "            'weight': meta_train[:,0],\n",
    "            'height': meta_train[:,1],\n",
    "            'VT_cosmed': meta_train[:,2],\n",
    "            }), ignore_index=True )\n",
    "\n",
    "        df_outputlabel_train.to_csv(training_params['outputdir_numeric']+'df_outputlabel_train.csv', index=False)\n",
    "\n",
    "        df_performance_val = df_performance_val.append( get_df_performance(label_val, label_est_val, subject_id, task), ignore_index=True )\n",
    "        df_performance_val.to_csv(training_params['outputdir_numeric']+'df_performance_val.csv', index=False)\n",
    "\n",
    "        df_outputlabel_val = df_outputlabel_val.append(\n",
    "            pd.DataFrame( {\n",
    "            'label_est': label_est_val,\n",
    "            'label': label_val,\n",
    "            'CV': [subject_id]*label_val.shape[0],\n",
    "            'task': [task]*label_val.shape[0],\n",
    "            'activity': meta_val[:,1],\n",
    "            'weight': meta_val[:,0],\n",
    "            'height': meta_val[:,1],\n",
    "            'VT_cosmed': meta_val[:,2],\n",
    "            }), ignore_index=True )\n",
    "\n",
    "        df_outputlabel_val.to_csv(training_params['outputdir_numeric']+'df_outputlabel_val.csv', index=False)\n",
    "\n",
    "        if training_params['model_name']=='XGBRegressor':\n",
    "            plot_feature_importances(training_params['feature_names'], model.feature_importances_, fig_name='feature_importance_'+str(subject_id), outputdir=training_params['outputdir_featureimportance'], show_plot=False, log_wandb=training_params['wandb'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # plot performance training and testing dataset\n",
    "#         plot_BA(df_outputlabel_train, task, fig_name='BA_train', show_plot=False, outputdir=outputdir_modelout, log_wandb=training_params['wandb'])\n",
    "\n",
    "        plot_BA(df_outputlabel_val, task_name=task_name, fig_name='BA_val', show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "        # plot_regression(df_outputlabel_val, df_performance_val, task, fig_name='regression_val', show_plot=False, outputdir=outputdir_modelout, log_wandb=training_params['wandb'])\n",
    "        plot_regression(df_outputlabel_train, training_params, task_name=task_name, fig_name='regression_train', show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "        plot_regression(df_outputlabel_val,  training_params, task_name=task_name, fig_name='regression_val', show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    plot_output(df_outputlabel_val, task_name=task_name, fig_name = 'outputINtime_val_',  show_plot=False, outputdir=training_params['outputdir_modelout'])\n",
    "\n",
    "    # plot_regression_all_agg(df_outputlabel_val, df_performance_val, fig_name='LinearR_agg_val', outputdir=outputdir_modelout, show_plot=False, log_wandb=training_params['wandb'])\n",
    "    # plot_regression_all_agg(df_outputlabel_train, df_performance_val, fig_name='LinearR_agg_train', outputdir=outputdir_modelout, show_plot=False, log_wandb=training_params['wandb'])\n",
    "\n",
    "\n",
    "    plot_regression_all_agg(df_outputlabel_val, training_params, task_name=task_name, fig_name='LinearR_agg_val', outputdir=training_params['outputdir_modelout'], show_plot=False, log_wandb=training_params['wandb'])\n",
    "    plot_regression_all_agg(df_outputlabel_train, training_params, task_name=task_name, fig_name='LinearR_agg_train', outputdir=training_params['outputdir_modelout'], show_plot=False, log_wandb=training_params['wandb'])\n",
    "\n",
    "\n",
    "    # log metrices on wnadb\n",
    "    if training_params['wandb']==True:\n",
    "\n",
    "        # W&B\n",
    "        label = df_outputlabel_val['label'].values\n",
    "        label_est = df_outputlabel_val['label_est'].values\n",
    "\n",
    "        PCC = get_PCC(label, label_est)\n",
    "        Rsquared = get_CoeffDeterm(label, label_est)\n",
    "        MAE, _ = get_MAE(label, label_est)\n",
    "        RMSE = get_RMSE(label, label_est)\n",
    "        MAPE, _ = get_MAPE(label, label_est)\n",
    "        \n",
    "        print(MAE)\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                'val_MAE': MAE,\n",
    "                'val_RMSE': RMSE,\n",
    "                'val_MAPE': MAPE,\n",
    "                'val_PCC': PCC,\n",
    "                'val_Rsquared': Rsquared,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "def train_sweep(config=None):   \n",
    "#     with wandb.init(config=config, entity='inanlab', project=\"[TL] stage2_cnn\", reinit=True, dir=outputdir):\n",
    "    with wandb.init(config=config, reinit=True, dir=outputdir):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        \n",
    "        print(config)\n",
    "                \n",
    "        for key in config.keys():\n",
    "            training_params[key] = config[key]\n",
    "            \n",
    "            \n",
    "        try: \n",
    "            train_master(training_params)\n",
    "        except Exception:\n",
    "            print(traceback.print_exc(), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_params['wandb']:\n",
    "    print('sweeping for:', sweep_name)\n",
    "    sweep_config = training_params['sweep_config']    \n",
    "#     with wandb.init(config=config, entity='inanlab', project=\"[TL] stage2_cnn\", reinit=True, dir=outputdir):\n",
    "    sweep_id = wandb.sweep(sweep_config, entity='inanlab', project='[VO2] stage4_'+training_params['sweep_name'])\n",
    "\n",
    "#     sweep_id = wandb.sweep(sweep_config, project=sweep_name)\n",
    "    wandb.agent(sweep_id, train_sweep)\n",
    "    \n",
    "else:\n",
    "    train_master(training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_val = pd.read_csv('../../../data/stage4/ML_regression/TEST/rep0/LinearRegression-3feat/numeric_results/df_performance_val.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_val['rmse'].mean(), df_performance_val['rmse'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(label_est_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(label_est_train)\n",
    "# plt.plot(label_train)\n",
    "# # meta_train\n",
    "# # plt.plot(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dataloaders['train'].dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dataloaders['val'].dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(label_est_train)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLPRegressor(random_state=1, max_iter=3)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_train = dataloaders['train'].dataset.feature\n",
    "\n",
    "\n",
    "# feature_mean = np.mean(feature_train, axis=0)\n",
    "# feature_std = np.std(feature_train, axis=0)\n",
    "# # plt.plot(feature_std)\n",
    "# plt.plot(feature_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot( dataloaders['train'].dataset.label[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(dataloaders['val'].dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_train.shape, label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot performance training and testing dataset\n",
    "# plot_regression(df_outputlabel_train[task], df_performance_train[task], task, fig_name='regression_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "# plot_BA(df_outputlabel_train[task], task, fig_name='BA_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "\n",
    "# plot_regression(df_outputlabel_val[task], df_performance_val[task], task, fig_name='regression_val_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "# plot_BA(df_outputlabel_val[task], task, fig_name='BA_val_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "\n",
    "# plot_output(df_outputlabel_train[task], fig_name = 'outputINtime_train_', show_plot=True, outputdir=outputdir+'model_output/')\n",
    "# plot_output(df_outputlabel_val[task], fig_name = 'outputINtime_val_',  show_plot=True, outputdir=outputdir+'model_output/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot performance training and testing dataset\n",
    "# # plot_regression(df_outputlabel_train, df_performance_train, task, fig_name='regression_train', show_plot=False, outputdir=outputdir)\n",
    "# plot_BA(df_outputlabel_train, task, fig_name='BA_train', show_plot=False, outputdir=outputdir_modelout)\n",
    "# # plot_output(df_outputlabel_train, task, fig_name = 'outputINtime_train_', show_plot=False, outputdir=outputdir_modelout)\n",
    "\n",
    "# # plot_regression(df_outputlabel_val, df_performance_val, task, fig_name='regression_val', show_plot=False, outputdir=outputdir)\n",
    "# plot_BA(df_outputlabel_val, task, fig_name='BA_val', show_plot=False, outputdir=outputdir_modelout)\n",
    "# plot_output(df_outputlabel_val, task, fig_name = 'outputINtime_val_',  show_plot=False, outputdir=outputdir_modelout)\n",
    "\n",
    "# plot_regression_all_agg(df_outputlabel_val, df_performance_val, fig_name='LinearR_agg_val', outputdir=outputdir_modelout, show_plot=False, log_wandb=training_params['wandb'])\n",
    "# plot_regression_all_agg(df_outputlabel_train, df_performance_val, fig_name='LinearR_agg_train', outputdir=outputdir_modelout, show_plot=False, log_wandb=training_params['wandb'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = task.split('_')[0]\n",
    "\n",
    "label_range = [my_floor(df_outputlabel_val['label'].values.min()), my_ceil(df_outputlabel_val['label'].values.max())]\n",
    "\n",
    "N_sub = len(df_outputlabel_val['CV'].unique())\n",
    "N_samples = df_outputlabel_val.shape[0]\n",
    "t_dur = N_samples*3/60\n",
    "\n",
    "\n",
    "PCC = get_PCC(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "Rsquared = get_CoeffDeterm(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "MAE, MAE_std = get_MAE(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "RMSE = get_RMSE(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "MAPE, MAPE_std = get_MAPE(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "\n",
    "title_str = '{} range: {:.1f}-{:.1f} {}'.format(task.split('_')[0], label_range[0], label_range[1], unit_dict[task_name])\n",
    "textstr = 'RMSE={:.2f} {}\\nMAE={:.2f} {}\\nMAPE={:.2f} {}\\nPCC={:.2f}\\nR2={:.2f}\\nN_sub={}\\nN_samples={}\\nduration={:.2f} min'.format(\n",
    "    RMSE, unit_dict[task_name], MAE, unit_dict[task_name],MAPE*100, '%',\n",
    "    PCC, Rsquared,\n",
    "    N_sub, N_samples, t_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver(training_params, 'training_params', outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for task in training_params['tasks']:\n",
    "#         label_est_val = CV_dict['performance_dict_val']['out_dict'][task]\n",
    "#         label_val = CV_dict['performance_dict_val']['label_dict'][task]\n",
    "\n",
    "#         label_est_train = CV_dict['performance_dict_train']['out_dict'][task]\n",
    "#         label_train = CV_dict['performance_dict_train']['label_dict'][task]\n",
    "        \n",
    "#         # get performance df for training and testing dataset\n",
    "#         df_performance_train = df_performance_train.append( get_df_performance(label_train, label_est_train, subject_id, task), ignore_index=True )\n",
    "#         df_performance_train.to_csv(outputdir+'df_performance_train.csv', index=False)\n",
    "\n",
    "#         df_outputlabel_train = df_outputlabel_train.append(\n",
    "#             pd.DataFrame( {\n",
    "#             'label_est': label_est_train,\n",
    "#             'label': label_train,\n",
    "#             'CV': [subject_id]*label_train.shape[0],\n",
    "#             'task': [task]*label_train.shape[0]\n",
    "#             }), ignore_index=True )\n",
    "        \n",
    "#         df_outputlabel_train.to_csv(outputdir+'df_outputlabel_train.csv', index=False)\n",
    "\n",
    "#         df_performance_val = df_performance_val.append( get_df_performance(label_val, label_est_val, subject_id, task), ignore_index=True )\n",
    "#         df_performance_val.to_csv(outputdir+'df_performance_val.csv', index=False)\n",
    "        \n",
    "#         df_outputlabel_val = df_outputlabel_val.append(\n",
    "#             pd.DataFrame( {\n",
    "#             'label_est': label_est_val,\n",
    "#             'label': label_val,\n",
    "#             'CV': [subject_id]*label_val.shape[0],\n",
    "#             'task': [task]*label_val.shape[0]\n",
    "#             }), ignore_index=True )\n",
    "        \n",
    "#         df_outputlabel_val.to_csv(outputdir+'df_outputlabel_val.csv', index=False)\n",
    "\n",
    "#         # plot performance training and testing dataset\n",
    "#         plot_regression(df_outputlabel_train, df_performance_train, task, fig_name='regression_train', show_plot=False, outputdir=outputdir)\n",
    "#         plot_BA(df_outputlabel_train, task, fig_name='BA_train', show_plot=False, outputdir=outputdir)\n",
    "        \n",
    "#         plot_regression(df_outputlabel_val, df_performance_val, task, fig_name='regression_val', show_plot=False, outputdir=outputdir)\n",
    "#         plot_BA(df_outputlabel_val, task, fig_name='BA_val', show_plot=False, outputdir=outputdir)\n",
    "\n",
    "# #     sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_regression(df_outputlabel_val, df_performance_val, task, show_plot=True, outputdir=outputdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_BA(df_outputlabel_val, task, show_plot=True, outputdir=outputdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mienv",
   "language": "python",
   "name": "mienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
