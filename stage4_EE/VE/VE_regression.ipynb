{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression ultimate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import math\n",
    "from math import sin\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "torch.manual_seed(0)\n",
    "\n",
    "i_seed = 0\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../PatchWand/') # add this line so Data and data are visible in this file\n",
    "\n",
    "# from PatchWand import *\n",
    "from plotting_tools import *\n",
    "from setting import *\n",
    "from models import *\n",
    "from models_CNN import *\n",
    "from evaluate import *\n",
    "\n",
    "from stage3_preprocess import *\n",
    "from training_util import *\n",
    "from dataset_util import *\n",
    "from dataIO import *\n",
    "from stage4_regression import *\n",
    "\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(input_folder='../../data/stage3/', output_folder='../../data/stage4/VE_regression/', training_params_file='training_params_ML.json')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='SpO2_estimate')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--training_params_file', metavar='training_params_file', help='training_params_file',\n",
    "                    default='training_params_list.json')\n",
    "\n",
    "\n",
    "# checklist 3: comment first line, uncomment second line\n",
    "args = parser.parse_args(['--input_folder', '../../data/stage3/', \n",
    "#                           '--output_folder', '../../data/stage4/ML_regression/',\n",
    "                          '--output_folder', '../../data/stage4/VE_regression/',\n",
    "                          '--training_params_file', 'training_params_ML.json',\n",
    "#                           '--training_params_file', 'training_params_baseline.json',\n",
    "                         ])\n",
    "# args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir = args.input_folder\n",
    "outputdir = args.output_folder\n",
    "training_params_file = args.training_params_file\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get training params and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['list_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage3_dict['list_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VE_cosmed', 'HR_patch', 'HR_patchnormed', '0.00Hz', '3.91Hz', '7.81Hz', '11.72Hz', '15.62Hz', '19.53Hz', '23.44Hz', 'weight', 'height', 'gender', 'age', 'BMR', 'BMI']\n",
      "data dimensions are: (559, 3, 6000)\n"
     ]
    }
   ],
   "source": [
    "with open(training_params_file) as json_file:\n",
    "    training_params_list = json.load(json_file)\n",
    "\n",
    "for training_params in training_params_list:\n",
    "    # include device in training_params\n",
    "#     device = torch.device('cuda:{}'.format(int(training_params['cuda_i'])) if torch.cuda.is_available() else 'cpu')\n",
    "#     training_params['device'] = device\n",
    "\n",
    "\n",
    "    training_params['CV_config'] = {\n",
    "        'subject_id': 101,\n",
    "        'task_id': 1,\n",
    "    }\n",
    "    stage3_dict = data_loader('stage3_dict', inputdir).item()\n",
    "    training_params['list_signal'] = stage3_dict['list_signal']\n",
    "    training_params['list_feature'] = stage3_dict['list_feature']\n",
    "    print( training_params['list_feature'] )\n",
    "    training_params['list_output'] = stage3_dict['list_output']\n",
    "    training_params['list_meta'] = stage3_dict['list_meta']\n",
    "    training_params['FS_RESAMPLE_DL'] = stage3_dict['FS_RESAMPLE_DL']\n",
    "    training_params['subject_ids'] = stage3_dict['subject_ids']\n",
    "    training_params['task_ids'] = stage3_dict['task_ids']\n",
    "    \n",
    "#     input_CV = '../../data/stage3/113/CV2/'\n",
    "#     dataloaders, dataset_sizes = get_loaders(input_CV, training_params)\n",
    "    dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "    print('data dimensions are:', dataloaders['train'].dataset.data.shape)\n",
    "\n",
    "    data_dimensions = dataloaders['train'].dataset.__getitem__(0)[0].size()\n",
    "    training_params['data_dimensions'] = list(data_dimensions)\n",
    "    \n",
    "    sweep_name = training_params['sweep_name'] \n",
    "    \n",
    "\n",
    "training_params = training_params_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params['feature_names'] = ['VE_cosmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['feature_names']  = ['HR_patch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HP from Mobashir's paper\n",
    "- learning rate = 0.05, \n",
    "- max_depth=10, \n",
    "- subsample=0.6, \n",
    "- colsample_bytree = 0.7, \n",
    "- n_estimators = 100, \n",
    "- min_child_weight = 2, \n",
    "- gamma = 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# feature_train.shape\n",
    "# sig = feature_train[0,0,:]\n",
    "# t_sig = np.arange(sig.shape[0])/training_params['FS_RESAMPLE_DL']\n",
    "\n",
    "# # arange(sig.shape[0])\n",
    "\n",
    "# plt.plot(t_sig, sig)\n",
    "# sig_smoothed = get_smooth(sig, N=int(training_params['FS_RESAMPLE_DL']*20))\n",
    "# plt.plot(t_sig, sig_smoothed)\n",
    "\n",
    "\n",
    "# downsample_factor = training_params['FS_RESAMPLE_DL']*10 # take a sample every 10 sec (6 datapoints)\n",
    "# plt.scatter(t_sig[downsample_factor//2:][::downsample_factor], sig_smoothed[downsample_factor//2:][::downsample_factor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir_numeric = outputdir + 'numeric_results/'\n",
    "if outputdir_numeric is not None:\n",
    "    if not os.path.exists(outputdir_numeric):\n",
    "        os.makedirs(outputdir_numeric)\n",
    "    \n",
    "outputdir_modelout = outputdir + 'model_output/'\n",
    "if outputdir_modelout is not None:\n",
    "    if not os.path.exists(outputdir_modelout):\n",
    "        os.makedirs(outputdir_modelout)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_train = pd.DataFrame()\n",
    "df_performance_val = pd.DataFrame()\n",
    "\n",
    "df_outputlabel_train = pd.DataFrame()\n",
    "df_outputlabel_val = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# training_params['feature_names'] = ['HR_patch']\n",
    "# training_params['feature_names'] = ['HR_patch', 'weight', 'height', 'gender']\n",
    "# training_params['feature_names'] = ['VE_cosmed', 'weight']\n",
    "# training_params['feature_names'] = ['VE_cosmed']\n",
    "training_params['output_names'] = ['EE_cosmed']\n",
    "\n",
    "for subject_id in training_params['subject_ids']:\n",
    "\n",
    "    training_params['CV_config']['subject_id'] = subject_id\n",
    "\n",
    "    dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "    \n",
    "#     i_feature = training_params['feature_names'].index('HR_patch')\n",
    "#     i_label = training_params['output_names'].index('EE_cosmed')\n",
    "\n",
    "    \n",
    "    if training_params['model_name']=='LinearRegression':\n",
    "        model = LinearRegression()\n",
    "    elif training_params['model_name']=='XGBRegressor':\n",
    "        model = XGBRegressor(learning_rate=0.05, max_depth=10, subsample=0.6, colsample_bytree=0.7, n_estimators=100, min_child_weight=2, gamma=0.3)\n",
    "    \n",
    "    feature_train = dataloaders['train'].dataset.feature[:,:,0]\n",
    "    feature_val = dataloaders['val'].dataset.feature[:,:,0]\n",
    "    \n",
    "    # zero mean unit variance\n",
    "    feature_mean = np.mean(feature_train, axis=0)\n",
    "    feature_std = np.std(feature_train, axis=0)\n",
    "\n",
    "    feature_train = (feature_train-feature_mean)/feature_std\n",
    "    feature_val = (feature_val-feature_mean)/feature_std\n",
    "\n",
    "    \n",
    "    label_train = dataloaders['train'].dataset.label.squeeze()\n",
    "    label_val = dataloaders['val'].dataset.label.squeeze()\n",
    "    \n",
    "    model = model.fit(feature_train, label_train)\n",
    "    label_est_train = model.predict(feature_train)\n",
    "    label_est_val = model.predict(feature_val)\n",
    "    \n",
    "    label_train = label_train.squeeze()\n",
    "    label_val = label_val.squeeze()\n",
    "    label_est_train = label_est_train.squeeze()\n",
    "    label_est_val = label_est_val.squeeze()\n",
    "    \n",
    "    \n",
    "    # get performance df for training and testing dataset\n",
    "    df_performance_train = df_performance_train.append( get_df_performance(label_train, label_est_train, subject_id, training_params['output_names'][0]), ignore_index=True )\n",
    "    df_performance_train.to_csv(outputdir_numeric+'df_performance_train.csv', index=False)\n",
    "\n",
    "    df_outputlabel_train = df_outputlabel_train.append(\n",
    "        pd.DataFrame( {\n",
    "        'label_est': label_est_train,\n",
    "        'label': label_train,\n",
    "        'CV': [subject_id]*label_train.shape[0],\n",
    "        'task': [training_params['output_names'][0]]*label_train.shape[0]\n",
    "        }), ignore_index=True )\n",
    "\n",
    "    df_outputlabel_train.to_csv(outputdir_numeric+'df_outputlabel_train.csv', index=False)\n",
    "\n",
    "    df_performance_val = df_performance_val.append( get_df_performance(label_val, label_est_val, subject_id, training_params['output_names'][0]), ignore_index=True )\n",
    "    df_performance_val.to_csv(outputdir_numeric+'df_performance_val.csv', index=False)\n",
    "\n",
    "    df_outputlabel_val = df_outputlabel_val.append(\n",
    "        pd.DataFrame( {\n",
    "        'label_est': label_est_val,\n",
    "        'label': label_val,\n",
    "        'CV': [subject_id]*label_val.shape[0],\n",
    "        'task': [training_params['output_names'][0]]*label_val.shape[0]\n",
    "        }), ignore_index=True )\n",
    "\n",
    "    df_outputlabel_val.to_csv(outputdir_numeric+'df_outputlabel_val.csv', index=False)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot performance training and testing dataset\n",
    "# plot_regression(df_outputlabel_train[task], df_performance_train[task], task, fig_name='regression_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "# plot_BA(df_outputlabel_train[task], task, fig_name='BA_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "\n",
    "# plot_regression(df_outputlabel_val[task], df_performance_val[task], task, fig_name='regression_val_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "# plot_BA(df_outputlabel_val[task], task, fig_name='BA_val_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "\n",
    "# plot_output(df_outputlabel_train[task], fig_name = 'outputINtime_train_', show_plot=True, outputdir=outputdir+'model_output/')\n",
    "# plot_output(df_outputlabel_val[task], fig_name = 'outputINtime_val_',  show_plot=True, outputdir=outputdir+'model_output/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance training and testing dataset\n",
    "task = training_params['output_names'][0]\n",
    "plot_regression(df_outputlabel_train, df_performance_train, task, fig_name='regression_train', show_plot=False, outputdir=outputdir_modelout)\n",
    "plot_BA(df_outputlabel_train, task, fig_name='BA_train', show_plot=False, outputdir=outputdir_modelout)\n",
    "plot_output(df_outputlabel_train, task, fig_name = 'outputINtime_train_', show_plot=False, outputdir=outputdir_modelout)\n",
    "\n",
    "plot_regression(df_outputlabel_val, df_performance_val, task, fig_name='regression_val', show_plot=False, outputdir=outputdir_modelout)\n",
    "plot_BA(df_outputlabel_val, task, fig_name='BA_val', show_plot=False, outputdir=outputdir_modelout)\n",
    "plot_output(df_outputlabel_val, task, fig_name = 'outputINtime_val_',  show_plot=False, outputdir=outputdir_modelout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = task.split('_')[0]\n",
    "\n",
    "label_range = [my_floor(df_outputlabel_val['label'].values.min()), my_ceil(df_outputlabel_val['label'].values.max())]\n",
    "\n",
    "N_sub = len(df_outputlabel_val['CV'].unique())\n",
    "N_samples = df_outputlabel_val.shape[0]\n",
    "t_dur = N_samples*3/60\n",
    "\n",
    "\n",
    "PCC = get_PCC(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "Rsquared = get_CoeffDeterm(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "MAE, MAE_std = get_MAE(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "RMSE = get_RMSE(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "MAPE, MAPE_std = get_MAPE(df_outputlabel_val['label'].values, df_outputlabel_val['label_est'].values)\n",
    "\n",
    "title_str = '{} range: {:.1f}-{:.1f} {}'.format(task.split('_')[0], label_range[0], label_range[1], unit_dict[task_name])\n",
    "textstr = 'RMSE={:.2f} {}\\nMAE={:.2f} {}\\nMAPE={:.2f} {}\\nPCC={:.2f}\\nR2={:.2f}\\nN_sub={}\\nN_samples={}\\nduration={:.2f} min'.format(\n",
    "    RMSE, unit_dict[task_name], MAE, unit_dict[task_name],MAPE*100, '%',\n",
    "    PCC, Rsquared,\n",
    "    N_sub, N_samples, t_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=0.49 kcals/min\n",
      "MAE=0.38 kcals/min\n",
      "MAPE=20.00 %\n",
      "PCC=0.91\n",
      "R2=0.82\n",
      "N_sub=15\n",
      "N_samples=599\n",
      "duration=29.95 min\n"
     ]
    }
   ],
   "source": [
    "print(textstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver(training_params, 'training_params', outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     for task in training_params['tasks']:\n",
    "#         label_est_val = CV_dict['performance_dict_val']['out_dict'][task]\n",
    "#         label_val = CV_dict['performance_dict_val']['label_dict'][task]\n",
    "\n",
    "#         label_est_train = CV_dict['performance_dict_train']['out_dict'][task]\n",
    "#         label_train = CV_dict['performance_dict_train']['label_dict'][task]\n",
    "        \n",
    "#         # get performance df for training and testing dataset\n",
    "#         df_performance_train = df_performance_train.append( get_df_performance(label_train, label_est_train, subject_id, task), ignore_index=True )\n",
    "#         df_performance_train.to_csv(outputdir+'df_performance_train.csv', index=False)\n",
    "\n",
    "#         df_outputlabel_train = df_outputlabel_train.append(\n",
    "#             pd.DataFrame( {\n",
    "#             'label_est': label_est_train,\n",
    "#             'label': label_train,\n",
    "#             'CV': [subject_id]*label_train.shape[0],\n",
    "#             'task': [task]*label_train.shape[0]\n",
    "#             }), ignore_index=True )\n",
    "        \n",
    "#         df_outputlabel_train.to_csv(outputdir+'df_outputlabel_train.csv', index=False)\n",
    "\n",
    "#         df_performance_val = df_performance_val.append( get_df_performance(label_val, label_est_val, subject_id, task), ignore_index=True )\n",
    "#         df_performance_val.to_csv(outputdir+'df_performance_val.csv', index=False)\n",
    "        \n",
    "#         df_outputlabel_val = df_outputlabel_val.append(\n",
    "#             pd.DataFrame( {\n",
    "#             'label_est': label_est_val,\n",
    "#             'label': label_val,\n",
    "#             'CV': [subject_id]*label_val.shape[0],\n",
    "#             'task': [task]*label_val.shape[0]\n",
    "#             }), ignore_index=True )\n",
    "        \n",
    "#         df_outputlabel_val.to_csv(outputdir+'df_outputlabel_val.csv', index=False)\n",
    "\n",
    "#         # plot performance training and testing dataset\n",
    "#         plot_regression(df_outputlabel_train, df_performance_train, task, fig_name='regression_train', show_plot=False, outputdir=outputdir)\n",
    "#         plot_BA(df_outputlabel_train, task, fig_name='BA_train', show_plot=False, outputdir=outputdir)\n",
    "        \n",
    "#         plot_regression(df_outputlabel_val, df_performance_val, task, fig_name='regression_val', show_plot=False, outputdir=outputdir)\n",
    "#         plot_BA(df_outputlabel_val, task, fig_name='BA_val', show_plot=False, outputdir=outputdir)\n",
    "\n",
    "# #     sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_regression(df_outputlabel_val, df_performance_val, task, show_plot=True, outputdir=outputdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_BA(df_outputlabel_val, task, show_plot=True, outputdir=outputdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mienv",
   "language": "python",
   "name": "mienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
