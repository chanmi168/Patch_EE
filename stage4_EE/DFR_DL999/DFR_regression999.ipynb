{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0) \n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import math\n",
    "from math import sin\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "i_seed = 0\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../../PatchWand/') # add this line so Data and data are visible in this file\n",
    "\n",
    "# from PatchWand import *\n",
    "from plotting_tools import *\n",
    "from setting import *\n",
    "\n",
    "# from EE_extension.dataset_util import *\n",
    "\n",
    "from VO2_extension999.models import *\n",
    "from VO2_extension999.models_CNNlight import *\n",
    "# from models_CNN import *\n",
    "# from models_CNN2 import *\n",
    "# from VO2_extension.models_resnet import *\n",
    "from VO2_extension999.dataset_util import *\n",
    "from VO2_extension999.training_util import *\n",
    "from VO2_extension999.evaluation_util import *\n",
    "\n",
    "from evaluate import *\n",
    "\n",
    "from stage3_preprocess import *\n",
    "from stage4_regression import *\n",
    "from dataIO import *\n",
    "\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaa = torch.rand(10,5, 33)\n",
    "\n",
    "# m =  nn.AdaptiveMaxPool1d(1)\n",
    "# m(aaa).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='SpO2_estimate')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--subject_id', metavar='subject_id', help='subject_id',\n",
    "                    default='101')\n",
    "parser.add_argument('--training_params_file', metavar='training_params_file', help='training_params_file',\n",
    "                    default='training_params_list.json')\n",
    "\n",
    "\n",
    "# checklist 3: comment first line, uncomment second line\n",
    "args = parser.parse_args(['--input_folder', '../../../data/stage3/win60_overlap90/', \n",
    "                          '--output_folder', '../../../data/stage4/DFR_DL999/TEST/',\n",
    "                          '--training_params_file', 'training_params_baseline.json',\n",
    "                          # '--training_params_file', 'training_params_dummy.json',\n",
    "                         ])\n",
    "# args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tz_NY = pytz.timezone('America/New_York') \n",
    "datetime_start = datetime.now(tz_NY)\n",
    "print(\"start time:\", datetime_start.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_regressor_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir = args.input_folder\n",
    "outputdir = args.output_folder\n",
    "training_params_file = args.training_params_file\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get training params and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_range_dict['HR_DL'] = [40, 190]\n",
    "\n",
    "def update_freq_meta(training_params, organ='HR', n_block=None):\n",
    "    \n",
    "    if n_block is None:\n",
    "        n_block = training_params['n_block']\n",
    "        \n",
    "    # change the FS_Extracted at the last layer of conv net based on n_block\n",
    "    FS_Extracted = training_params['FS_RESAMPLE_DL'] / (training_params['stride']**n_block)\n",
    "    # training_params['FS_Extracted'] = FS_Extracted\n",
    "    \n",
    "    # compute last layer dimension based on n_block\n",
    "    last_layer_dim = training_params['ecg_dimensions'][-1]\n",
    "    \n",
    "    \n",
    "    for n in range(n_block):\n",
    "        last_layer_dim = round(last_layer_dim/training_params['stride'])\n",
    "\n",
    "    # training_params['last_layer_dim'] = last_layer_dim\n",
    "\n",
    "    # compute xf based on FS_Extracted and a mask + xf_masked using xf and label_range_dict['HR_DL']\n",
    "    xf = np.linspace(0.0, 1.0/2.0*FS_Extracted , last_layer_dim//2)*60    \n",
    "    \n",
    "    \n",
    "    if organ=='HR':\n",
    "        freq_range = label_range_dict['HR_DL']\n",
    "    elif organ=='RR':\n",
    "        freq_range = label_range_dict['RR']\n",
    "\n",
    "    mask = (xf>=freq_range[0]) & (xf<=freq_range[1])\n",
    "\n",
    "    \n",
    "\n",
    "    xf_raw = np.linspace(0.0, 1.0/2.0*training_params['FS_RESAMPLE_DL'] , training_params['ecg_dimensions'][-1]//2)*60    \n",
    "    raw_mask = (xf_raw>=freq_range[0]) & (xf_raw<=freq_range[1])\n",
    "\n",
    "    xf_dict = {\n",
    "        'xf': xf,\n",
    "        'xf_masked': xf[mask],\n",
    "        'mask': mask,\n",
    "        'raw_mask': raw_mask,\n",
    "        'FS_Extracted': FS_Extracted,\n",
    "        'last_layer_dim': last_layer_dim,\n",
    "        'freq_range': freq_range\n",
    "    }\n",
    "    # training_params['xf'] = xf\n",
    "    # training_params['xf_masked'] = xf[mask]\n",
    "    # training_params['mask'] = mask\n",
    "    \n",
    "    return xf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_signals(training_params, dataloaders):\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(training_params['ecg_dimensions'][0],1, figsize=(50,3), dpi=80)\n",
    "    ax.plot(dataloaders['train'].dataset.ecg[0,0,:])\n",
    "\n",
    "    fig, axes = plt.subplots(training_params['scg_dimensions'][0],1, figsize=(50,3*training_params['scg_dimensions'][0]), dpi=80)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(dataloaders['train'].dataset.scg[0,i,:])\n",
    "\n",
    "    fig, axes = plt.subplots(training_params['ppg_dimensions'][0],1, figsize=(50,3*training_params['ppg_dimensions'][0]), dpi=80)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(dataloaders['train'].dataset.ppg[0,i,:])\n",
    "\n",
    "    for ax in axes:\n",
    "        ax_no_top_right(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_params_file) as json_file:\n",
    "    training_params_list = json.load(json_file)\n",
    "\n",
    "for training_params in [training_params_list[0]]:\n",
    "    # include device in training_params\n",
    "    \n",
    "    if training_params['cuda_i']==-1:\n",
    "        device = torch.device('cpu')\n",
    "    else:\n",
    "        device = torch.device('cuda:{}'.format(int(training_params['cuda_i'])) if torch.cuda.is_available() else 'cpu')\n",
    "    training_params['device'] = device\n",
    "    \n",
    "    if 'training_mode' in training_params:\n",
    "        training_mode = training_params['training_mode']\n",
    "    else:\n",
    "        training_params = 'subject_ind'\n",
    "\n",
    "    task_id = [0, 1, 2, 3, 4, 5]\n",
    "    # task_id = [0]\n",
    "    # task_id = [1, 2]\n",
    "\n",
    "    training_params['CV_config'] = {\n",
    "        'subject_id': 113,\n",
    "        'task_ids': task_id,\n",
    "        # 'reject_subject_id': [101, 102, 103, 104, 105, 109]\n",
    "        # 'reject_subject_id': [101, 102, 103, 105, 109, 115]\n",
    "        'reject_subject_id': [101, 102, 103, 109]\n",
    "        # 'reject_subject_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,112,114, 115]\n",
    "\n",
    "        # 'task_id': 5,\n",
    "    }\n",
    "    \n",
    "    training_params['ordered_subject_ids'] = [105, 115, 107, 117, 106, 104, 113, 114, 116,  119, 108, 110, 111, 118, 120, 121, 212]\n",
    "    # training_params['ordered_subject_ids'] = [107, 117, 106]\n",
    "    \n",
    "    training_params['output_names'] = training_params['main_task'] + training_params['auxillary_tasks']\n",
    "    \n",
    "    \n",
    "    # sys.exit()\n",
    "    \n",
    "    training_params['regression_names'] = get_regression_names(training_params)\n",
    "\n",
    "    stage3_dict = data_loader('stage3_dict', inputdir).item()\n",
    "    training_params['list_signal'] = stage3_dict['list_signal']\n",
    "    training_params['list_feature'] = stage3_dict['list_feature']\n",
    "    training_params['list_output'] = stage3_dict['list_output']\n",
    "    training_params['list_meta'] = stage3_dict['list_meta']\n",
    "    training_params['FS_RESAMPLE_DL'] = stage3_dict['FS_RESAMPLE_DL']\n",
    "    training_params['subject_ids'] = stage3_dict['subject_ids']\n",
    "    training_params['task_ids'] = stage3_dict['task_ids']\n",
    "    training_params['sequence'] = stage3_dict['sequence']\n",
    "    \n",
    "    dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "    print('ecg dimensions are:', dataloaders['train'].dataset.ecg.shape)\n",
    "    print('scg dimensions are:', dataloaders['train'].dataset.scg.shape)\n",
    "    print('ppg dimensions are:', dataloaders['train'].dataset.ppg.shape)\n",
    "    print('feature dimensions are:', dataloaders['train'].dataset.feature.shape)\n",
    "    print('label dimensions are:', dataloaders['train'].dataset.label.shape)\n",
    "    print('meta dimensions are:', dataloaders['train'].dataset.meta.shape)\n",
    "\n",
    "    ecg_dimensions = dataloaders['train'].dataset.__getitem__(0)[0].size()\n",
    "    training_params['ecg_dimensions'] = list(ecg_dimensions)\n",
    "    scg_dimensions = dataloaders['train'].dataset.__getitem__(0)[1].size()\n",
    "    training_params['scg_dimensions'] = list(scg_dimensions)\n",
    "    ppg_dimensions = dataloaders['train'].dataset.__getitem__(0)[2].size()\n",
    "    training_params['ppg_dimensions'] = list(ppg_dimensions)\n",
    "\n",
    "    training_params['data_dimensions'] = training_params['ecg_dimensions']\n",
    "    \n",
    "    \n",
    "    inspect_signals(training_params, dataloaders)\n",
    "\n",
    "    \n",
    "    sweep_name = training_params['sweep_name'] \n",
    "    \n",
    "    if training_params['model_name'] == 'FeatureExtractor_CNN':\n",
    "        training_params['featrue_extractor'] = FeatureExtractor_CNN\n",
    "    elif training_params['model_name'] == 'ResNet1D':\n",
    "        training_params['featrue_extractor'] = ResNet1D\n",
    "    elif training_params['model_name'] == 'FeatureExtractor_CNN2':\n",
    "        training_params['featrue_extractor'] = FeatureExtractor_CNN2\n",
    "    elif 'CNNlight' in training_params['model_name']: # designed for HR estimation\n",
    "        training_params['feature_extractor'] = FeatureExtractor_CNNlight\n",
    "\n",
    "\n",
    "    # get the right regressor\n",
    "    if training_params['regressor_type'] == 'DominantFreqRegression':\n",
    "        training_params['regressor'] = DominantFreqRegression\n",
    "    elif training_params['regressor_type'] == 'FFTRegression':\n",
    "        training_params['regressor'] = FFTRegression\n",
    "    elif training_params['regressor_type'] == 'CardioRespRegression':\n",
    "        training_params['regressor'] = CardioRespRegression       \n",
    "    elif training_params['regressor_type'] == 'vanilla_regression':\n",
    "        training_params['regressor'] = vanilla_regression\n",
    "    elif training_params['regressor_type'] == 'CardioRespXGBRegression':\n",
    "        training_params['regressor'] = CardioRespRegression   \n",
    "    \n",
    "\n",
    "\n",
    "    if training_params['auxillary_regressor_type'] == 'DominantFreqRegression':\n",
    "        training_params['auxillary_regressor'] = DominantFreqRegression\n",
    "\n",
    "    # order subject so we can see the worst subjects first\n",
    "    if 'ordered_subject_ids' in training_params:\n",
    "        training_params['ordered_subject_ids'] = np.asarray(training_params['ordered_subject_ids'])\n",
    "    else:\n",
    "        training_params['ordered_subject_ids'] = training_params['subject_ids']\n",
    "    \n",
    "    training_params['inputdir'] = inputdir\n",
    "    training_params['outputdir'] = outputdir\n",
    "    \n",
    "    # training_params['regression_names'] = get_regression_names(training_params)\n",
    "\n",
    "    if 'LSTM' in training_params['model_name']:\n",
    "        training_params = change_output_dim(training_params)\n",
    "\n",
    "    training_params['HR_xf_dict'] = update_freq_meta(training_params, 'HR', n_block=3)\n",
    "    training_params['RR_xf_dict'] = update_freq_meta(training_params, 'RR', n_block=4)\n",
    "\n",
    "    del dataloaders\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['list_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define trainer, evaler, preder functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = train_mtlnet\n",
    "evaler = eval_mtlnet\n",
    "preder = pred_mtlnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: need to fix summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_test(training_params):\n",
    "    print('using model ', training_params['model_name'])\n",
    "\n",
    "    device = training_params['device']\n",
    "    # prepare model\n",
    "    model = cardioresp_multiverse(training_params=training_params)\n",
    "    model = model.to(device).float()\n",
    "\n",
    "    # prepare data\n",
    "    dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "\n",
    "    ecg = dataloaders['val'].dataset.ecg[:5,:,:]\n",
    "    ecg = torch.from_numpy(ecg)\n",
    "    scg = dataloaders['val'].dataset.scg[:5,:,:]\n",
    "    scg = torch.from_numpy(scg)\n",
    "    ppg = dataloaders['val'].dataset.ppg[:5,:,:]\n",
    "    ppg = torch.from_numpy(ppg)\n",
    "\n",
    "    feature = dataloaders['val'].dataset.feature[:5,:]\n",
    "    feature = torch.from_numpy(feature)\n",
    "\n",
    "    label = dataloaders['val'].dataset.label[:5,:]\n",
    "    label = torch.from_numpy(label)\n",
    "\n",
    "    ecg = ecg.to(device=device, dtype=torch.float)\n",
    "    scg = scg.to(device=device, dtype=torch.float)\n",
    "    ppg = ppg.to(device=device, dtype=torch.float)\n",
    "    feature = feature.to(device=device, dtype=torch.float)\n",
    "    label = label.to(device=device, dtype=torch.float)\n",
    "\n",
    "    # model inference\n",
    "    # output, deep_feature, concat_feature = model(ecg, scg, ppg, feature)\n",
    "    out, deep_feature, concat_feature, attention_dict = model(ecg, scg, ppg, feature)\n",
    "\n",
    "    print('out')\n",
    "    for key in out:\n",
    "        print(key, out[key].size())\n",
    "\n",
    "    print('deep_feature')\n",
    "    for key in deep_feature:\n",
    "        print(key, deep_feature[key].size())\n",
    "        \n",
    "    print('concat_feature', concat_feature.size())\n",
    "\n",
    "    # print(concat_feature.size())\n",
    "    # print(label.size())\n",
    "\n",
    "    # compute loss\n",
    "    criterion = MultiTaskLoss(training_params)\n",
    "    losses = criterion(out, label)\n",
    "\n",
    "    # check losses\n",
    "    # print(losses)\n",
    "    # print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(training_params):\n",
    "\n",
    "    print('using model ', training_params['model_name'])\n",
    "    training_params_copy = copy.deepcopy(training_params)\n",
    "    training_params_copy['device'] = torch.device('cpu')\n",
    "\n",
    "    model = cardioresp_multiverse(training_params=training_params_copy)\n",
    "    summary(model, input_size=[tuple(training_params['ecg_dimensions']),tuple(training_params['scg_dimensions']),tuple(training_params['ppg_dimensions']), (model.N_features,1)], device='cpu')\n",
    "    print(model)\n",
    "    del model\n",
    "\n",
    "\n",
    "debug_model = True\n",
    "if debug_model==True:\n",
    "    # if 'LSTM' not in training_params['model_name']:\n",
    "    #     test_model(training_params)\n",
    "    # else:\n",
    "    ma_test(training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['regression_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = cardioresp_multiverse(training_params=training_params)\n",
    "# model = model.to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define training, validating, and evaluating funcitons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, val, eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_params['wandb']:\n",
    "    os.environ[\"WANDB_DIR\"] = os.path.abspath(outputdir)\n",
    "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = 'DL_regression'\n",
    "    wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sweep_folder(training_params):\n",
    "    n_block = training_params['n_block']\n",
    "    inputs_combined = '+'.join([ i_name.split('_')[0] for i_name in training_params['input_names']])\n",
    "    # main_weight = training_params['loss_weights']['main_task']\n",
    "    # auxillary_weight = training_params['loss_weights']['auxillary_task']\n",
    "    main_weight = training_params['main_loss_weight']\n",
    "    auxillary_weight = training_params['auxillary_loss_weight']\n",
    "    \n",
    "    \n",
    "    \n",
    "    channel_n = training_params['channel_n']\n",
    "    \n",
    "    # auxillary_task = training_params['auxillary_tasks'][0]\n",
    "    auxillary_tasks = '+'.join(training_params['auxillary_tasks'])\n",
    "    \n",
    "    adaptive_loss_name = training_params['adaptive_loss_name']\n",
    "    \n",
    "    n_feat = len(training_params['feature_names'])\n",
    "    \n",
    "    i_rep = training_params['i_rep']\n",
    "    \n",
    "    \n",
    "    # use_atten = training_params['use_spectral_atn']\n",
    "    \n",
    "    use_atten='ch={}|spec={}'.format(1*training_params['use_spectral_atn'], 1*training_params['use_channel_atn'])\n",
    "    \n",
    "    # sweep_folder = '{}blocks-{}-weight{}+{}-{}ch-act{}-{}'.format(n_block, inputs_combined, auxillary_weight, adversarial_weight, channel_n, list_act, training_params['regressor_type'])\n",
    "    # sweep_folder = '{}blocks-{}-weight{}+{}-{}'.format(n_block, inputs_combined, main_weight, auxillary_weight, auxillary_task)\n",
    "    # sweep_folder = '{}-auxweight{}-{}-{}feat-{}'.format(inputs_combined, auxillary_weight, adaptive_loss_name, n_feat, auxillary_tasks)\n",
    "    sweep_folder = 'rep{}/auxweight{}-{}-{}feat-{}-{}-{}'.format(i_rep, auxillary_weight, adaptive_loss_name, n_feat, auxillary_tasks, training_params['regressor_type'], use_atten)\n",
    "\n",
    "    return sweep_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaa = torch.empty(0)\n",
    "# bbb = torch.rand(5,13)\n",
    "# torch.cat([aaa,bbb])-bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputdirs(training_params):\n",
    "\n",
    "    outputdir = training_params['outputdir']\n",
    "    sweep_folder = get_sweep_folder(training_params)\n",
    "    outputdir_sweep = outputdir+'{}/'.format(sweep_folder)\n",
    "\n",
    "    outputdir_numeric = outputdir_sweep + 'numeric_results/'\n",
    "    if outputdir_numeric is not None:\n",
    "        if not os.path.exists(outputdir_numeric):\n",
    "            os.makedirs(outputdir_numeric)\n",
    "\n",
    "    outputdir_modelout = outputdir_sweep + 'model_output/'\n",
    "    if outputdir_modelout is not None:\n",
    "        if not os.path.exists(outputdir_modelout):\n",
    "            os.makedirs(outputdir_modelout)\n",
    "            \n",
    "    outputdir_activation = outputdir_sweep + 'activation_layers/'\n",
    "    if outputdir_activation is not None:\n",
    "        if not os.path.exists(outputdir_activation):\n",
    "            os.makedirs(outputdir_activation)\n",
    "            \n",
    "    outputdir_attention = outputdir_sweep + 'attention_diag/'\n",
    "    if outputdir_attention is not None:\n",
    "        if not os.path.exists(outputdir_attention):\n",
    "            os.makedirs(outputdir_attention)\n",
    "            \n",
    "    outputdir_featureimportance = outputdir_sweep + 'feature_importance/'\n",
    "    if outputdir_modelout is not None:\n",
    "        if not os.path.exists(outputdir_featureimportance):\n",
    "            os.makedirs(outputdir_featureimportance)\n",
    "\n",
    "    training_params['outputdir_sweep'] = outputdir_sweep\n",
    "    training_params['outputdir_numeric'] = outputdir_numeric\n",
    "    training_params['outputdir_modelout'] = outputdir_modelout\n",
    "    training_params['outputdir_activation'] = outputdir_activation\n",
    "    training_params['outputdir_attention'] = outputdir_attention\n",
    "    training_params['outputdir_featureimportance'] = outputdir_featureimportance\n",
    "    # training_params['outputdir_feature'] = outputdir_feature\n",
    "\n",
    "    return training_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['CV_config']['subject_id'] = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['outputdir_attention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params = get_outputdirs(training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['outputdir_sweep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(training_params['HR_xf_dict']['xf_masked'], attention_dicts['fused_fft_HR'][i_sample,0,:], '.-', color='gray', alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['adaptive_loss_name']=='awl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = MultiTaskLoss(training_params)\n",
    "# loss_weights_dict  = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaa = {'merged-HR_patch2': 1.0, 'merged-RR_cosmed2': 1.0, 'VO2_cosmed2': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbb = merge_dict(loss_weights_dict, aaa)\n",
    "# bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# criterion = MultiTaskLoss(training_params)\n",
    "# output_names = list(criterion.criterions.keys())\n",
    "# output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_auxillary = False\n",
    "\n",
    "def train_master(training_params):\n",
    "    \n",
    "    training_params['regression_names'] = get_regression_names(training_params)\n",
    "    training_params = get_outputdirs(training_params) # could be tricky since it changes several keys\n",
    "    # training_params['xf_dict'] = update_freq_meta(training_params)\n",
    "    torch.manual_seed(training_params['i_rep'])\n",
    "    \n",
    "    pprint.pprint(training_params)\n",
    "    \n",
    "\n",
    "    criterion = MultiTaskLoss(training_params)\n",
    "    output_names = list(criterion.criterions.keys())\n",
    "    \n",
    "    df_performance_train = {}\n",
    "    df_performance_val = {}\n",
    "\n",
    "    df_outputlabel_train = {}\n",
    "    df_outputlabel_val = {}\n",
    "\n",
    "    for task in output_names:\n",
    "        df_performance_train[task] = pd.DataFrame()\n",
    "        df_performance_val[task] = pd.DataFrame()\n",
    "\n",
    "        df_outputlabel_train[task] = pd.DataFrame()\n",
    "        df_outputlabel_val[task] = pd.DataFrame()\n",
    "\n",
    "\n",
    "    ordered_subject_ids = training_params['ordered_subject_ids']\n",
    "    # main_task = training_params['output_names'][0].split('-')[0]\n",
    "    main_task = training_params['main_task'][0] # VO2_cosmed\n",
    "\n",
    "    # for subject_id in training_params['subject_ids']:\n",
    "    for i_CV, subject_id in enumerate(ordered_subject_ids):\n",
    "        \n",
    "        if 'CV_max' in training_params:\n",
    "            if i_CV >= training_params['CV_max']:\n",
    "                continue\n",
    "                \n",
    "        if subject_id in training_params['CV_config']['reject_subject_id']:\n",
    "            continue\n",
    "\n",
    "        training_params['CV_config']['subject_id'] = subject_id\n",
    "\n",
    "        # device = torch.device('cuda:{}'.format(int(training_params['cuda_i'])) if torch.cuda.is_available() else 'cpu')\n",
    "        print('using device', training_params['device'])\n",
    "        print('using model ', training_params['model_name'])\n",
    "        print('subject id:', subject_id)\n",
    "\n",
    "#         training_params = get_regressor_names(training_params)\n",
    "        model = cardioresp_multiverse(training_params=training_params)\n",
    "#         print(model)\n",
    "        \n",
    "        model = model.to(device).float()\n",
    "        criterion = criterion.to(device).float()\n",
    "        # print('model created')\n",
    "\n",
    "\n",
    "        if training_params['regressor_type']=='CardioRespXGBRegression':\n",
    "            training_params['xgb_regressor'] = XGBRegressor(learning_rate=0.05, max_depth=50, subsample=0.6, colsample_bytree=0.7, n_estimators=100, min_child_weight=2, gamma=0.001, verbosity=0)\n",
    "\n",
    "        \n",
    "        if training_params['adaptive_loss_name']=='awl':\n",
    "            optimizer = torch.optim.Adam([\n",
    "                    {'params': model.parameters(), 'lr':training_params['learning_rate'], 'weight_decay': 0.1},\n",
    "                    {'params': criterion.parameters(), 'lr':training_params['learning_rate'], 'weight_decay': 0.1},\n",
    "                    # {'params': criterion.parameters(), 'weight_decay': 0}\n",
    "                ])\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=training_params['learning_rate'], weight_decay=0.1)\n",
    "\n",
    "        \n",
    "        # if training_params['optimizer_name'] == 'Adam':\n",
    "        #     optimizer = torch.optim.Adam(model.parameters(), lr=training_params['learning_rate'], weight_decay=0.1)\n",
    "        # # optimizer = torch.optim.Adam(model.parameters(), lr=training_params['learning_rate'], weight_decay=0.9)\n",
    "        # elif training_params['optimizer_name'] == 'LBFGS':\n",
    "        #     optimizer =  torch.optim.LBFGS(model.parameters(), history_size=10, max_iter=4)\n",
    "\n",
    "\n",
    "        training_params['criterion'] = criterion\n",
    "        training_params['optimizer'] = optimizer\n",
    "        training_params['inputdir'] = inputdir\n",
    "        \n",
    "\n",
    "\n",
    "        CV_dict = train_model(model, training_params, trainer, evaler, preder)\n",
    "\n",
    "        \n",
    "        # print(CV_dict['performance_dict_val']['concat_feature_arr'].shape)\n",
    "        # sys.exit()\n",
    "\n",
    "        # for task in output_names:\n",
    "        # for task in training_params['regression_names']:\n",
    "        for task in criterion.criterions.keys():\n",
    "            task_name = task.split('-')[-1].split('_')[0]\n",
    "\n",
    "\n",
    "#         for task in training_params['tasks']:\n",
    "\n",
    "#             print( CV_dict['performance_dict_val']['out_dict'].keys(), CV_dict['performance_dict_val']['label_dict'].keys(), task)\n",
    "            label_est_val = CV_dict['performance_dict_val']['out_dict'][task]\n",
    "            label_val = CV_dict['performance_dict_val']['label_dict'][task]\n",
    "\n",
    "            label_est_train = CV_dict['performance_dict_train']['out_dict'][task]\n",
    "            label_train = CV_dict['performance_dict_train']['label_dict'][task]\n",
    "            \n",
    "            activity_train = CV_dict['performance_dict_train']['meta_arr'][:,1]\n",
    "            activity_val = CV_dict['performance_dict_val']['meta_arr'][:,1]\n",
    "            \n",
    "            \n",
    "            # get performance df for training and testing dataset\n",
    "            df_performance_train[task] = df_performance_train[task].append( get_df_performance(label_train, label_est_train, subject_id, task), ignore_index=True )\n",
    "\n",
    "            df_performance_train[task].to_csv(training_params['outputdir_numeric'] + 'df_performance_train_{}.csv'.format(task), index=False)\n",
    "\n",
    "            df_outputlabel_train[task] = df_outputlabel_train[task].append(\n",
    "                pd.DataFrame( {\n",
    "                    'label_est': label_est_train,\n",
    "                    'label': label_train,\n",
    "                    'CV': [subject_id]*label_train.shape[0],\n",
    "                    'task': [task]*label_train.shape[0],\n",
    "                    'activity': activity_train,\n",
    "                    'weight': CV_dict['performance_dict_train']['feature_arr'][:,0],\n",
    "                    'height': CV_dict['performance_dict_train']['feature_arr'][:,1],\n",
    "                    'VT_cosmed': CV_dict['performance_dict_train']['meta_arr'][:,2],\n",
    "                }), ignore_index=True )\n",
    "\n",
    "            df_outputlabel_train[task].to_csv(training_params['outputdir_numeric'] + 'df_outputlabel_train_{}.csv'.format(task), index=False)\n",
    "\n",
    "            df_performance_val[task] = df_performance_val[task].append( get_df_performance(label_val, label_est_val, subject_id, task), ignore_index=True )\n",
    "            df_performance_val[task].to_csv(training_params['outputdir_numeric'] + 'df_performance_val_{}.csv'.format(task), index=False)\n",
    "\n",
    "            df_outputlabel_val[task] = df_outputlabel_val[task].append(\n",
    "                pd.DataFrame( {\n",
    "                    'label_est': label_est_val,\n",
    "                    'label': label_val,\n",
    "                    'CV': [subject_id]*label_val.shape[0],\n",
    "                    'task': [task]*label_val.shape[0],\n",
    "                    'activity': activity_val,\n",
    "                    'weight': CV_dict['performance_dict_val']['feature_arr'][:,0],\n",
    "                    'height': CV_dict['performance_dict_val']['feature_arr'][:,1],\n",
    "                    'VT_cosmed': CV_dict['performance_dict_val']['meta_arr'][:,2],\n",
    "                }), ignore_index=True )\n",
    "\n",
    "            df_outputlabel_val[task].to_csv(training_params['outputdir_numeric'] + 'df_outputlabel_val_{}.csv'.format(task), index=False)\n",
    "\n",
    "            # plot performance training and testing dataset\n",
    "            # if (main_task not in task) and (debug_auxillary==False):\n",
    "            #     continue\n",
    "            \n",
    "            if training_params['show_plot']:\n",
    "                plot_regression(df_outputlabel_val[task],  training_params, task_name=task_name, fig_name='regression_val_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "\n",
    "            #     continue\n",
    "#             plot_regression(df_outputlabel_train[task], training_params, task_name=task_name, fig_name='regression_train_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "#             plot_regression(df_outputlabel_val[task],  training_params, task_name=task_name, fig_name='regression_val_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "# #             plot_BA(df_outputlabel_train[task], task, fig_name='BA_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "#             plot_output(df_outputlabel_val[task],  task_name=task_name, fig_name = 'outputINtime_val_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'])\n",
    "        \n",
    "        # check_featuremap(model, training_params, mode='worst', fig_name = 'DL_activation_{}_'.format(subject_id), outputdir=outputdir+'activation_layers_worst/{}/'.format(subject_id), show_plot=False)\n",
    "        # check_featuremap(model, training_params, mode='best', fig_name = 'DL_activation_{}_'.format(subject_id), outputdir=outputdir+'activation_layers_best/{}/'.format(subject_id), show_plot=False)\n",
    "\n",
    "\n",
    "        if training_params['show_plot']:\n",
    "            # continue\n",
    "            \n",
    "            plot_losses(CV_dict, outputdir=training_params['outputdir_sweep'], show_plot=False, fig_name='loss_{}'.format(subject_id))\n",
    "\n",
    "            dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "\n",
    "            if 'CNNlight' in training_params['model_name']:\n",
    "                print('check_featuremap ...')\n",
    "                \n",
    "                if 'VO2' in task:\n",
    "                    check_featuremap(model, training_params, dataloaders, mode='worst', fig_name = 'DL_activation_{}_'.format(subject_id), outputdir=training_params['outputdir_activation']+'worst/{}/'.format(subject_id), show_plot=False)\n",
    "                    check_featuremap(model, training_params, dataloaders, mode='best', fig_name = 'DL_activation_{}_'.format(subject_id), outputdir=training_params['outputdir_activation']+'best/{}/'.format(subject_id), show_plot=False)\n",
    "                    check_featuremap(model, training_params, dataloaders, mode='random', fig_name = 'DL_activation_{}_'.format(subject_id), outputdir=training_params['outputdir_activation']+'random/{}/'.format(subject_id), show_plot=False)\n",
    "\n",
    "                    check_attention(CV_dict, task, training_params, mode='worst', fig_name='attention_{}_{}'.format(subject_id, task_name), outputdir=training_params['outputdir_attention']+'worst/', show_plot=False)\n",
    "                    check_attention(CV_dict, task, training_params, mode='best', fig_name='attention_{}_{}'.format(subject_id, task_name), outputdir=training_params['outputdir_attention']+'best/', show_plot=False)\n",
    "                    check_attention(CV_dict, task, training_params, mode='random', fig_name='attention_{}_{}'.format(subject_id, task_name), outputdir=training_params['outputdir_attention']+'random/', show_plot=False)\n",
    "\n",
    "\n",
    "            if training_params['regressor_type']=='CardioRespXGBRegression':\n",
    "            # if 'xgb_regressor' in training_params:\n",
    "                xgb_feature_names = np.r_[np.arange(model.extracted_dim), np.asarray(training_params['feature_names'])]\n",
    "                plot_feature_importances(xgb_feature_names, training_params['xgb_regressor'].feature_importances_, fig_name='feature_importance_'+str(subject_id), outputdir=training_params['outputdir_featureimportance'], show_plot=False, log_wandb=training_params['wandb'])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    # for task in training_params['regression_names']:\n",
    "    for task in output_names:\n",
    "        if not training_params['show_plot']:\n",
    "            continue\n",
    "            \n",
    "        task_name = task.split('-')[-1].split('_')[0]\n",
    "\n",
    "\n",
    "        plot_regression(df_outputlabel_train[task], training_params, task_name=task_name, fig_name='regression_train_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "        plot_regression(df_outputlabel_val[task],  training_params, task_name=task_name, fig_name='regression_val_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "#             plot_BA(df_outputlabel_train[task], task, fig_name='BA_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "        # plot_output(df_outputlabel_val[task],  task_name=task_name, fig_name = 'outputINtime_val_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'])\n",
    "        \n",
    "        # plot_regression_all_agg(df_outputlabel_train[task], training_params, task_name=task_name, fig_name='LinearR_agg_train_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "        # plot_BA(df_outputlabel_train[task],  training_params=training_params, task_name=task_name, fig_name='BA_train_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "\n",
    "        # plot_regression_all_agg(df_outputlabel_val[task], training_params, task_name=task_name, fig_name='LinearR_agg_val_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "        # plot_BA(df_outputlabel_val[task],  training_params=training_params, task_name=task_name, fig_name='BA_val_{}'.format(task), show_plot=False, outputdir=training_params['outputdir_modelout'], log_wandb=training_params['wandb'])\n",
    "\n",
    "        plot_output(df_outputlabel_val[task],  task_name=task_name, fig_name = 'outputINtime_val_{}'.format(task),  show_plot=False, outputdir=training_params['outputdir_modelout'])\n",
    "\n",
    "    # plot_BA(df_outputlabel_val[main_task], main_task, fig_name='BA_val_{}'.format(main_task), show_plot=False, outputdir=outputdir+'model_output/', log_wandb=training_params['wandb'])\n",
    "    # plot_regression_all_agg(df_outputlabel_val[main_task], df_performance_val[main_task], outputdir=outputdir+'model_output/', show_plot=False, log_wandb=training_params['wandb'])\n",
    "\n",
    "    # log metrices on wnadb\n",
    "    if training_params['wandb']==True:\n",
    "        task = training_params['regression_names'][-1]\n",
    "        # W&B\n",
    "        label = df_outputlabel_val[task]['label'].values\n",
    "        label_est = df_outputlabel_val[task]['label_est'].values\n",
    "#         print(label.shape, label)\n",
    "#         print(label_est.shape, label_est)\n",
    "    \n",
    "        PCC = get_PCC(label, label_est)\n",
    "        Rsquared = get_CoeffDeterm(label, label_est)\n",
    "        MAE, _ = get_MAE(label, label_est)\n",
    "        RMSE = get_RMSE(label, label_est)\n",
    "        MAPE, _ = get_MAPE(label, label_est)\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                'val_MAE': MAE,\n",
    "                'val_RMSE': RMSE,\n",
    "                'val_MAPE': MAPE,\n",
    "                'val_PCC': PCC,\n",
    "                'val_Rsquared': Rsquared,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = MultiTaskLoss(training_params)\n",
    "# criterion.criterions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['loss_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = np.arange(100)\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize=(5, 50), dpi=100)\n",
    "# fontsize = 12\n",
    "# ax.barh(feature_names, feature_names)\n",
    "# ax.tick_params(axis='both', labelsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import sys\n",
    "\n",
    "# def exc_handler(exc_type, exc, tb):\n",
    "#     print(\"EXCEPTION\")\n",
    "#     traceback.print_exception(exc_type, exc, tb)\n",
    "\n",
    "# sys.excepthook = exc_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "def train_sweep(config=None):   \n",
    "#     with wandb.init(config=config, entity='inanlab', project=\"[TL] stage2_cnn\", reinit=True, dir=outputdir):\n",
    "    with wandb.init(config=config, reinit=True, dir=outputdir):\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        \n",
    "        print(config)\n",
    "                \n",
    "        for key in config.keys():\n",
    "            training_params[key] = config[key]\n",
    "            \n",
    "            \n",
    "        try: \n",
    "            train_master(training_params)\n",
    "        except Exception:\n",
    "            print(traceback.print_exc(), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: use training_params['regressor_names'] for looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if training_params['wandb']:\n",
    "    print('sweeping for:', sweep_name)\n",
    "    sweep_config = training_params['sweep_config']    \n",
    "#     with wandb.init(config=config, entity='inanlab', project=\"[TL] stage2_cnn\", reinit=True, dir=outputdir):\n",
    "    sweep_id = wandb.sweep(sweep_config, entity='inanlab', project='[VO2] stage4_'+training_params['sweep_name'])\n",
    "\n",
    "    wandb.agent(sweep_id, train_sweep)\n",
    "\n",
    "else:\n",
    "    train_master(training_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features  = np.random.rand(20)\n",
    "# features*features\n",
    "# # x_arr = np.arange(features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,1, figsize=(10, 3))\n",
    " \n",
    "# # creating the bar plot\n",
    "# ax.bar(x_arr, features, color ='maroon',\n",
    "#         width = 0.4)\n",
    " \n",
    "# ax.set_xlabel(\"Courses offered\")\n",
    "# ax.set_ylabel(\"No. of students enrolled\")\n",
    "# ax_no_top_right(ax)\n",
    "# # ax.title(\"Students enrolled in different courses\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = np.random.rand(125, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = StandardScaler().fit_transform(features) # normalizing the features\n",
    "print('show standardize mean and std:', np.mean(features),np.std(features))\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(features)\n",
    "\n",
    "df_embedding = {\n",
    "    'UMAP0': embedding[:, 0],\n",
    "    'UMAP1': embedding[:, 1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'bias'\n",
    "\n",
    "dim1_name = 'UMAP0'\n",
    "dim2_name = 'UMAP0'\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6), dpi=120)\n",
    "\n",
    "ax.set_xlabel(dim1_name,fontsize=12)\n",
    "ax.set_ylabel(dim2_name,fontsize=12)\n",
    "# ax.set_title('{}\\n(explained_var: {:.2f}%)'.format(feature_names, explained_var),fontsize=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "\n",
    "# race_color_dict = {\n",
    "#     'Caucasian or White': 'firebrick',\n",
    "#     'African American  or Black': 'steelblue',\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pt_label = ['']\n",
    "\n",
    "marker = 'o'\n",
    "# colors = 'r'\n",
    "alpha = 0.3\n",
    "fontsize = 15\n",
    "\n",
    "# mask_White = df_demographic_processed['White']==True\n",
    "# mask_Black = df_demographic_processed['Black']==True\n",
    "\n",
    "markers = {\"Caucasian or White\": \"o\", \"African American  or Black\": \"X\"}\n",
    "# sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", style=\"time\", markers=markers)\n",
    "\n",
    "\n",
    "\n",
    "# g = sns.scatterplot(data=df_embedding, x=dim1_name, y=dim2_name, hue=metric, style=\"Race String\", ax=ax, palette='viridis', markers=markers,alpha=alpha)\n",
    "# sns.rugplot(data=df_embedding, x=dim1_name, y=dim2_name, hue=metric, ax=ax)\n",
    "# g.legend_.remove()\n",
    "\n",
    "\n",
    "# # title_str = '[{}]\\n{} range: {:.1f}-{:.1f} {}'.format(subject_id, task.split('_')[0], label_range_sub[0], label_range_sub[1], unit_dict[task_name])\n",
    "\n",
    "# textstr = get_regression_stats(df_demographic_processed, verbose=False)\n",
    "# props = dict(boxstyle='round,pad=0.7', facecolor='white', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# # place a text box in bottom right in axes coords\n",
    "# ax.text(0.6, 0.77, textstr, transform=ax.transAxes, fontsize=fontsize-5,\n",
    "#         verticalalignment='bottom', horizontalalignment='left', bbox=props)\n",
    "\n",
    "\n",
    "# #Colormap for comparison\n",
    "# cmap = plt.get_cmap(\"viridis\")\n",
    "# norm = plt.Normalize(df_demographic_processed[metric].min(), df_demographic_processed[metric].max())\n",
    "# sm =  ScalarMappable(norm=norm, cmap=cmap)\n",
    "# sm.set_array([])\n",
    "# cbar = fig.colorbar(sm, ax=ax)\n",
    "\n",
    "\n",
    "\n",
    "# # handles, labels  =  ax.get_legend_handles_labels()\n",
    "# # ax.legend(handles=handles[-3:], labels=labels[-3:])\n",
    "# # ax.legend(bbox_to_anchor= (.01, 1.05), prop={'size': fontsize-5})\n",
    "\n",
    "# ax_no_top_right(ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 20\n",
    "\n",
    "j_handle = sns.jointplot(\n",
    "    data=df_demographic_processed,\n",
    "    x=dim1_name, y=dim2_name, hue='Race String',\n",
    "    palette=race_color_dict,\n",
    "    shade=True, shade_lowest=False, \n",
    "    alpha=0.5,\n",
    "    kind=\"kde\",\n",
    "    \n",
    "    height=7,\n",
    "    marginal_ticks=True\n",
    ")\n",
    "\n",
    "# JointGrid has a convenience function\n",
    "j_handle.set_axis_labels(dim1_name, dim2_name, fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['regression_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xf, yf = get_psd(aaa, training_params['FS_Extracted'])\n",
    "# mask = training_params['xf_dict']['mask']\n",
    "# xf, yf = xf[mask], yf[mask]\n",
    "\n",
    "# yf = yf / np.sum(yf)\n",
    "\n",
    "# plt.plot(xf, yf, color='r')\n",
    "\n",
    "\n",
    "# yf = get_smooth(yf, N=5)\n",
    "# yf = yf / np.sum(yf)\n",
    "\n",
    "# plt.plot(xf, yf, color='g')\n",
    "# thre = np.mean(yf)\n",
    "# yf = yf > thre\n",
    "\n",
    "# plt.axhline(y=thre, color = 'black', linestyle = '-')\n",
    "\n",
    "\n",
    "\n",
    "# #         # attention dim: (N_batch, 1, N_spectral)\n",
    "# #         attention = attention / torch.sum(attention, axis=-1)[:,None]\n",
    "        \n",
    "# #         attention = attention > torch.mean(attention, axis=-1, keepdim=True)\n",
    "        \n",
    "# plt.plot(xf, yf*0.1, color='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf, yf = get_psd(aaa, training_params['FS_Extracted'])\n",
    "mask = training_params['xf_dict']['mask']\n",
    "xf, yf = xf[mask], yf[mask]\n",
    "\n",
    "yf = yf / np.sum(yf)\n",
    "\n",
    "plt.plot(xf, yf, color='r')\n",
    "\n",
    "\n",
    "freq_smooth_dur = 5/60 # Hz\n",
    "freq_smooth_win = round(freq_smooth_dur / np.mean(np.diff(xf)))\n",
    "m = MyAvgPool1dPadSame(kernel_size=freq_smooth_win, stride=1)\n",
    "yf = m(torch.tensor(yf)[None,None,:]).data.numpy().squeeze()\n",
    "yf = yf / np.sum(yf)\n",
    "\n",
    "plt.plot(xf, yf, color='g')\n",
    "\n",
    "thre = np.mean(yf)\n",
    "yf = yf > thre\n",
    "\n",
    "plt.axhline(y=thre, color = 'black', linestyle = '-')\n",
    "\n",
    "\n",
    "\n",
    "#         # attention dim: (N_batch, 1, N_spectral)\n",
    "#         attention = attention / torch.sum(attention, axis=-1)[:,None]\n",
    "        \n",
    "#         attention = attention > torch.mean(attention, axis=-1, keepdim=True)\n",
    "        \n",
    "plt.plot(xf, yf*0.1, color='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.diff(xf).mean()*5*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datetime_end = datetime.now(tz_NY)\n",
    "print(\"end time:\", datetime_end.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
    "\n",
    "duration = datetime_end-datetime_start\n",
    "duration_in_s = duration.total_seconds()\n",
    "days    = divmod(duration_in_s, 86400)        # Get days (without [0]!)\n",
    "hours   = divmod(days[1], 3600)               # Use remainder of days to calc hours\n",
    "minutes = divmod(hours[1], 60)                # Use remainder of hours to calc minutes\n",
    "seconds = divmod(minutes[1], 1)               # Use remainder of minutes to calc seconds\n",
    "print(\"Time between dates: %d days, %d hours, %d minutes and %d seconds\" % (days[0], hours[0], minutes[0], seconds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_activation(name):\n",
    "# #     activation = {}\n",
    "# #     def hook(model, input, output):\n",
    "# #         activation[name] = output.detach()\n",
    "# #     return hook\n",
    "    \n",
    "# def model_hooking(model, training_params, get_activation):\n",
    "\n",
    "#     model_name = training_params['model_name']\n",
    "    \n",
    "#     if model_name=='FeatureExtractor_CNN2':\n",
    "#         key = list(model.feature_extractors.keys())[0]\n",
    "#         model.feature_extractors[key].layer1.register_forward_hook(get_activation('layer1'))\n",
    "#         model.feature_extractors[key].layer2.register_forward_hook(get_activation('layer2'))\n",
    "#         model.feature_extractors[key].layer3.register_forward_hook(get_activation('layer3'))\n",
    "#         model.feature_extractors[key].layer4.register_forward_hook(get_activation('layer4'))\n",
    "#         model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "#         model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n",
    "        \n",
    "# #         layer_names = ['layer1', ]\n",
    "        \n",
    "#     elif model_name=='FeatureExtractor_CNN':\n",
    "#         key = list(model.feature_extractors.keys())[0]\n",
    "#         model.feature_extractors[key].layer1.register_forward_hook(get_activation('layer1'))\n",
    "#         model.feature_extractors[key].layer2.register_forward_hook(get_activation('layer2'))\n",
    "#         model.feature_extractors[key].layer3.register_forward_hook(get_activation('layer3'))\n",
    "#         model.feature_extractors[key].layer4.register_forward_hook(get_activation('layer4'))\n",
    "#         model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "#         model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n",
    "#     if model_name=='ResNet1D':\n",
    "#         pass\n",
    "# #         key = list(model.feature_extractors.keys())[0]\n",
    "# #         model.feature_extractors[key].layer1.register_forward_hook(get_activation('layer1'))\n",
    "# #         model.feature_extractors[key].layer2.register_forward_hook(get_activation('layer2'))\n",
    "# #         model.feature_extractors[key].layer3.register_forward_hook(get_activation('layer3'))\n",
    "# #         model.feature_extractors[key].layer4.register_forward_hook(get_activation('layer4'))\n",
    "# #         model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "# #         model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: improve this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict_train = preder(model, dataloaders['train'], training_params)\n",
    "performance_dict_val = preder(model, dataloaders['val'], training_params)\n",
    "\n",
    "unit = unit_dict[task.split('_')[0]]\n",
    "\n",
    "for task in training_params['tasks']:\n",
    "    \n",
    "    \n",
    "    print('evaluating task:', task)\n",
    "    MAE, std_AE = get_MAE(performance_dict_train['out_dict'][task], performance_dict_train['label_dict'][task])\n",
    "    print('\\ttrainin: {:.2f}±{:.2f} {}'.format(MAE, std_AE, unit))\n",
    "\n",
    "    MAE, std_AE = get_MAE(performance_dict_val['out_dict'][task], performance_dict_val['label_dict'][task])\n",
    "    print('\\tval: {:.2f}±{:.2f} {}'.format(MAE, std_AE, unit))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# produce output figures\n",
    "# TODO: implement the plotting functions below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO!!!!\n",
    "\n",
    "# for task in tasks\n",
    "#     plot_loss vs epoch (train and val)\n",
    "#     plot_MAE, RMSE, vs epoch (train and val)\n",
    "#     plot scatter plots (show PCC, BD, std, ect.) (just val)\n",
    "#     plot output vs. label (just val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = training_params['output_names'][0].split('_')[0]\n",
    "unit_dict[output_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kcalpmin2watt = 69.7333333\n",
    "\n",
    "# sub_weight = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance_dict_train['label_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params['tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in training_params['tasks']:\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5), dpi=100)\n",
    "    fontsize = 15\n",
    "    data_min = np.min(np.r_[performance_dict_train['out_dict'][task], performance_dict_train['label_dict'][task]])\n",
    "    data_max = np.max(np.r_[performance_dict_train['out_dict'][task], performance_dict_train['label_dict'][task]])\n",
    "    ax1.scatter(performance_dict_train['out_dict'][task], performance_dict_train['label_dict'][task], alpha=0.3)\n",
    "    ax1.set_xlim(data_min, data_max)\n",
    "    ax1.set_ylim(data_min, data_max)\n",
    "    ax1.plot( [data_min, data_max],[data_min, data_max], '--', color='gray', alpha=0.8)\n",
    "\n",
    "    ax1.set_xlabel('estimated {} ({})'.format(task.split('_')[0], unit_dict[task.split('_')[0]]), fontsize=fontsize)\n",
    "    ax1.set_ylabel('true {} ({})'.format(task.split('_')[0], unit_dict[task.split('_')[0]]), fontsize=fontsize)\n",
    "#     ax.set_xlabel('estimated {} ({})'.format(output_name, 'W'), fontsize=fontsize)\n",
    "#     ax.set_ylabel('true {} ({})'.format(output_name, 'W'), fontsize=fontsize)\n",
    "\n",
    "    ax1.set_title('training', fontsize=fontsize)\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(5,5))\n",
    "#     fontsize = 15\n",
    "    data_min = np.min(np.r_[performance_dict_val['out_dict'][task], performance_dict_val['label_dict'][task]])\n",
    "    data_max = np.max(np.r_[performance_dict_val['out_dict'][task], performance_dict_val['label_dict'][task]])\n",
    "    ax2.scatter(performance_dict_val['out_dict'][task], performance_dict_val['label_dict'][task], alpha=0.3)\n",
    "    ax2.set_xlim(data_min, data_max)\n",
    "    ax2.set_ylim(data_min, data_max)\n",
    "    ax2.plot( [data_min, data_max],[data_min, data_max], '--', color='gray', alpha=0.8)\n",
    "\n",
    "    ax2.set_xlabel('estimated {} ({})'.format(task.split('_')[0], unit_dict[task.split('_')[0]]), fontsize=fontsize)\n",
    "    ax2.set_ylabel('true {} ({})'.format(task.split('_')[0], unit_dict[task.split('_')[0]]), fontsize=fontsize)\n",
    "    \n",
    "    ax2.set_title('testing', fontsize=fontsize)\n",
    "\n",
    "#     ax.set_xlabel('estimated {} ({})'.format(output_name, 'W'), fontsize=fontsize)\n",
    "#     ax.set_ylabel('true {} ({})'.format(output_name, 'W'), fontsize=fontsize)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mienv",
   "language": "python",
   "name": "mienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
