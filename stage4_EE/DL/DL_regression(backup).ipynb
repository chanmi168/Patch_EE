{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this notebook parse patch data\n",
    "# TODO: meet with Venu to confirm the changes I made\n",
    "# TODO: figure out the units in COSMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0) \n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import math\n",
    "from math import sin\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchsummary import summary\n",
    "torch.manual_seed(0)\n",
    "\n",
    "i_seed = 0\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../PatchWand/') # add this line so Data and data are visible in this file\n",
    "\n",
    "# from PatchWand import *\n",
    "from plotting_tools import *\n",
    "from setting import *\n",
    "from models import *\n",
    "from models_CNN import *\n",
    "from models_CNN2 import *\n",
    "from models_resnet import *\n",
    "from evaluate import *\n",
    "\n",
    "from stage3_preprocess import *\n",
    "from stage4_regression import *\n",
    "from training_util import *\n",
    "from dataset_util import *\n",
    "from dataIO import *\n",
    "\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(input_folder='../../data/stage3/', output_folder='../../data/stage4/', subject_id='101', training_params_file='training_params_dummy.json')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='SpO2_estimate')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--subject_id', metavar='subject_id', help='subject_id',\n",
    "                    default='101')\n",
    "parser.add_argument('--training_params_file', metavar='training_params_file', help='training_params_file',\n",
    "                    default='training_params_list.json')\n",
    "\n",
    "\n",
    "# checklist 3: comment first line, uncomment second line\n",
    "args = parser.parse_args(['--input_folder', '../../data/stage3/', \n",
    "                          '--output_folder', '../../data/stage4/',\n",
    "#                           '--training_params_file', 'training_params_baseline.json',\n",
    "                          '--training_params_file', 'training_params_dummy.json',\n",
    "                         ])\n",
    "# args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-Mar-15 23:47:39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tz_NY = pytz.timezone('America/New_York') \n",
    "datetime_start = datetime.now(tz_NY)\n",
    "print(\"start time:\", datetime_start.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdir = args.input_folder\n",
    "outputdir = args.output_folder\n",
    "training_params_file = args.training_params_file\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get training params and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions are: (1909, 3, 6000)\n"
     ]
    }
   ],
   "source": [
    "with open(training_params_file) as json_file:\n",
    "    training_params_list = json.load(json_file)\n",
    "\n",
    "for training_params in [training_params_list[0]]:\n",
    "    # include device in training_params\n",
    "    device = torch.device('cuda:{}'.format(int(training_params['cuda_i'])) if torch.cuda.is_available() else 'cpu')\n",
    "    training_params['device'] = device\n",
    "\n",
    "\n",
    "    training_params['CV_config'] = {\n",
    "        'subject_id': 113,\n",
    "        'task_id': 5,\n",
    "    }\n",
    "    stage3_dict = data_loader('stage3_dict', inputdir).item()\n",
    "    training_params['list_signal'] = stage3_dict['list_signal']\n",
    "    training_params['list_feature'] = stage3_dict['list_feature']\n",
    "    training_params['list_output'] = stage3_dict['list_output']\n",
    "    training_params['list_meta'] = stage3_dict['list_meta']\n",
    "    training_params['FS_RESAMPLE_DL'] = stage3_dict['FS_RESAMPLE_DL']\n",
    "    training_params['subject_ids'] = stage3_dict['subject_ids']\n",
    "    training_params['task_ids'] = stage3_dict['task_ids']\n",
    "    \n",
    "    dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "    print('data dimensions are:', dataloaders['train'].dataset.data.shape)\n",
    "\n",
    "    data_dimensions = dataloaders['train'].dataset.__getitem__(0)[0].size()\n",
    "    training_params['data_dimensions'] = list(data_dimensions)\n",
    "    \n",
    "    sweep_name = training_params['sweep_name'] \n",
    "    \n",
    "    if training_params['model_name'] == 'FeatureExtractor_CNN':\n",
    "        training_params['featrue_extractor'] = FeatureExtractor_CNN\n",
    "    elif training_params['model_name'] == 'ResNet1D':\n",
    "        training_params['featrue_extractor'] = ResNet1D\n",
    "    elif training_params['model_name'] == 'FeatureExtractor_CNN2':\n",
    "        training_params['featrue_extractor'] = FeatureExtractor_CNN2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training_params = training_params_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = outputdir+training_params['model_name']+'/'\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ResNet1D',\n",
       " 'sweep_name': 'baseline',\n",
       " 'kernel_size': [5],\n",
       " 'channel_n': 4,\n",
       " 'num_epochs': 5,\n",
       " 'batch_size': 64,\n",
       " 'learning_rate': 0.001,\n",
       " 'cuda_i': 1,\n",
       " 'use_sc': True,\n",
       " 'fusion_type': 'late',\n",
       " 'pooling_type': 'avg_pooling',\n",
       " 'stride': [2],\n",
       " 'groups': [1],\n",
       " 'downsample_gap': [2],\n",
       " 'n_block_macro': [2],\n",
       " 'wandb': True,\n",
       " 'input_names': ['ECG', 'accelZ', 'ppg_g_1'],\n",
       " 'feature_names': ['weight', 'height', 'gender'],\n",
       " 'output_names': ['EE_cosmed', 'RR_cosmed'],\n",
       " 'loss_weights': {'EE_cosmed': 1, 'RR_cosmed': 0.5},\n",
       " 'meta_names': ['subject_id', 'task'],\n",
       " 'device': device(type='cuda', index=1),\n",
       " 'CV_config': {'subject_id': 113, 'task_id': 5},\n",
       " 'list_signal': ['ECG', 'accelZ', 'ppg_g_1'],\n",
       " 'list_feature': ['VE_cosmed',\n",
       "  'HR_patch',\n",
       "  'weight',\n",
       "  'height',\n",
       "  'gender',\n",
       "  'age',\n",
       "  'BMR'],\n",
       " 'list_output': ['RR_cosmed',\n",
       "  'VT_cosmed',\n",
       "  'EE_cosmed',\n",
       "  'SPO2_cosmed',\n",
       "  'HR_cosmed',\n",
       "  'VO2_cosmed',\n",
       "  'resp_cosmed'],\n",
       " 'list_meta': ['subject_id', 'task'],\n",
       " 'FS_RESAMPLE_DL': 100,\n",
       " 'subject_ids': array([101, 102, 103, 104, 106, 107, 110, 111, 113, 114, 115, 116, 118,\n",
       "        119, 120, 121, 212]),\n",
       " 'task_ids': array([0, 1, 2, 3, 4, 5]),\n",
       " 'data_dimensions': [3, 6000],\n",
       " 'featrue_extractor': models_resnet.ResNet1D}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmchan81\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# training_params['wandb'] = True\n",
    "\n",
    "if training_params['wandb']:\n",
    "    wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep(config=None):\n",
    "\n",
    "#     with wandb.init(config=config, entity='inanlab', project=\"[TL] stage2_cnn\", reinit=True, dir=outputdir):\n",
    "    with wandb.init(config=config, reinit=True, dir=outputdir):\n",
    "\n",
    "        # If called by wandb.agent, as below,\n",
    "        # this config will be set by Sweep Controller\n",
    "        config = wandb.config\n",
    "        \n",
    "        print(config)\n",
    "#         print(training_params)\n",
    "        sys.exit()\n",
    "        \n",
    "        # init the model\n",
    "        \n",
    "        training_params['kernel_size'] = config['kernel_size']\n",
    "        training_params['kernel_size'] = config['kernel_size']\n",
    "        \n",
    "        model = resp_multiverse(training_params=training_params)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        ordered_subject_ids = np.asarray([115, 107, 113, 110, 101, 104, 106, 121, 212, 102, 103, 111, 114, 116, 118, 119, 120])\n",
    "\n",
    "\n",
    "\n",
    "        # for subject_id in training_params['subject_ids']:\n",
    "        for subject_id in ordered_subject_ids:\n",
    "\n",
    "            config['CV_config']['subject_id'] = subject_id\n",
    "\n",
    "            device = torch.device('cuda:{}'.format(int(training_params['cuda_i'])) if torch.cuda.is_available() else 'cpu')\n",
    "            print('using device', device)\n",
    "\n",
    "\n",
    "            print('using model ', training_params['model_name'])\n",
    "\n",
    "            model = resp_multiverse(training_params=training_params)\n",
    "\n",
    "            model = model.to(device).float()\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=training_params['learning_rate'], weight_decay=0.01)\n",
    "\n",
    "            training_params['criterion'] = criterion\n",
    "            training_params['optimizer'] = optimizer\n",
    "            training_params['inputdir'] = inputdir\n",
    "\n",
    "            CV_dict = train_model(model, training_params, trainer, evaler, preder)\n",
    "#             plot_losses(CV_dict, outputdir=outputdir, show_plot=False)\n",
    "\n",
    "#             for task in training_params['tasks']:\n",
    "#                 label_est_val = CV_dict['performance_dict_val']['out_dict'][task]\n",
    "#                 label_val = CV_dict['performance_dict_val']['label_dict'][task]\n",
    "\n",
    "#                 label_est_train = CV_dict['performance_dict_train']['out_dict'][task]\n",
    "#                 label_train = CV_dict['performance_dict_train']['label_dict'][task]\n",
    "\n",
    "#                 # get performance df for training and testing dataset\n",
    "#                 df_performance_train[task] = df_performance_train[task].append( get_df_performance(label_train, label_est_train, subject_id, task), ignore_index=True )\n",
    "#                 df_performance_train[task].to_csv(outputdir+'df_performance_train_{}.csv'.format(task), index=False)\n",
    "\n",
    "#                 df_outputlabel_train[task] = df_outputlabel_train[task].append(\n",
    "#                     pd.DataFrame( {\n",
    "#                     'label_est': label_est_train,\n",
    "#                     'label': label_train,\n",
    "#                     'CV': [subject_id]*label_train.shape[0],\n",
    "#                     'task': [task]*label_train.shape[0]\n",
    "#                     }), ignore_index=True )\n",
    "\n",
    "#                 df_outputlabel_train[task].to_csv(outputdir+'df_outputlabel_train_{}.csv'.format(task), index=False)\n",
    "\n",
    "#                 df_performance_val[task] = df_performance_val[task].append( get_df_performance(label_val, label_est_val, subject_id, task), ignore_index=True )\n",
    "#                 df_performance_val[task].to_csv(outputdir+'df_performance_val_{}.csv'.format(task), index=False)\n",
    "\n",
    "#                 df_outputlabel_val[task] = df_outputlabel_val[task].append(\n",
    "#                     pd.DataFrame( {\n",
    "#                     'label_est': label_est_val,\n",
    "#                     'label': label_val,\n",
    "#                     'CV': [subject_id]*label_val.shape[0],\n",
    "#                     'task': [task]*label_val.shape[0]\n",
    "#                     }), ignore_index=True )\n",
    "\n",
    "#                 df_outputlabel_val[task].to_csv(outputdir+'df_outputlabel_val_{}.csv'.format(task), index=False)\n",
    "\n",
    "#                 # plot performance training and testing dataset\n",
    "#                 plot_regression(df_outputlabel_train[task], df_performance_train[task], task, fig_name='regression_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "#                 plot_BA(df_outputlabel_train[task], task, fig_name='BA_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "\n",
    "#                 plot_regression(df_outputlabel_val[task], df_performance_val[task], task, fig_name='regression_val_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "#                 plot_BA(df_outputlabel_val[task], task, fig_name='BA_val_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "\n",
    "#                 plot_output(df_outputlabel_train[task], task, fig_name = 'outputINtime_train_', show_plot=True, outputdir=outputdir+'model_output/')\n",
    "#                 plot_output(df_outputlabel_val[task], task, fig_name = 'outputINtime_val_',  show_plot=True, outputdir=outputdir+'model_output/')\n",
    "\n",
    "\n",
    "#                 check_featuremap(model, dataloaders['val'], training_params, fig_name = 'DL_activation_{}_'.format(subject_id), outputdir=outputdir+'activation_layers/', show_plot=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                 print('rmse={:.2f}, mae={:.2f}, PCC={:.2f}'.format(df_performance_val['EE_cosmed']['rmse'].mean(), df_performance_val['EE_cosmed']['mae'].mean(), df_performance_val['EE_cosmed']['PCC'].mean()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#     #         model = train_model(model, dataloaders, config)\n",
    "#         model, performance_dict_train, performance_dict_val = train_model(model, dataloaders, config,  trainer, evaler, preder)\n",
    "    \n",
    "\n",
    "        \n",
    "# #         wandb.log({'model_out_train': wandb.Image(plot_model_output(performance_dict_train))})\n",
    "#         wandb.log({'model_out_train': plot_model_output(performance_dict_train, 'model_output_train')})\n",
    "#         wandb.log({'model_out_val': plot_model_output(performance_dict_val, 'model_output_val')})\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "#         title_str = 'confusion matrxi for classifier {}\\n'.format('resnet (train)')\n",
    "#         PIL_train = aggregate_performance_dict(performance_dict_train, config, title_str)\n",
    "#         wandb.log({'cm_train': wandb.Image(PIL_train)})\n",
    "\n",
    "#         fig_roc_train = plot_ROC(performance_dict_train)\n",
    "#         wandb.log({'roc_train': wandb.Image(fig_roc_train)})\n",
    "    \n",
    "    \n",
    "#         title_str = 'confusion matrxi for classifier {}\\n'.format('resnet (val)')\n",
    "#         PIL_val = aggregate_performance_dict(performance_dict_val, config, title_str)\n",
    "#         wandb.log({'cm_val': wandb.Image(PIL_val)})\n",
    "        \n",
    "#         fig_roc_val = plot_ROC(performance_dict_val)\n",
    "#         wandb.log({'roc_val': wandb.Image(fig_roc_val)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "#     'program': '{}.py'.format(training_params['arch']),\n",
    "    'program': 'resnet.py',\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'goal': 'maximize',\n",
    "        'name': 'val_acc',},\n",
    "    \"parameters\" : {\n",
    "        \"epochs\" : {\n",
    "            \"values\" : [10, 20, 50]\n",
    "        },\n",
    "        \"learning_rate\" :{\n",
    "            \"min\": 0.0001,\n",
    "            \"max\": 0.1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(a):\n",
    "    # will be True also for 'NaN'\n",
    "    try:\n",
    "        number = float(a)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet1D\n",
      "baseline\n",
      "[5]\n",
      "4\n",
      "5\n",
      "64\n",
      "0.001\n",
      "1\n",
      "True\n",
      "late\n",
      "avg_pooling\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "[2]\n",
      "True\n",
      "['ECG', 'accelZ', 'ppg_g_1']\n",
      "['weight', 'height', 'gender']\n",
      "['EE_cosmed', 'RR_cosmed']\n",
      "{'EE_cosmed': 1, 'RR_cosmed': 0.5}\n",
      "['subject_id', 'task']\n",
      "cuda:1\n",
      "{'subject_id': 113, 'task_id': 5}\n",
      "['ECG', 'accelZ', 'ppg_g_1']\n",
      "['VE_cosmed', 'HR_patch', 'weight', 'height', 'gender', 'age', 'BMR']\n",
      "['RR_cosmed', 'VT_cosmed', 'EE_cosmed', 'SPO2_cosmed', 'HR_cosmed', 'VO2_cosmed', 'resp_cosmed']\n",
      "['subject_id', 'task']\n",
      "100\n",
      "[101 102 103 104 106 107 110 111 113 114 115 116 118 119 120 121 212]\n",
      "[0 1 2 3 4 5]\n",
      "[3, 6000]\n",
      "<class 'models_resnet.ResNet1D'>\n"
     ]
    }
   ],
   "source": [
    "# should be numbers or boolean\n",
    "parameters_dict = {}\n",
    "\n",
    "for key, value in training_params.items():\n",
    "    print(value)\n",
    "    parameters_dict[key] = {\n",
    "         'values': value\n",
    "    }\n",
    "#     if key in ['device', 'data_dimensions', 'sweep_name', 'arch']:\n",
    "#         continue\n",
    "#         parameters_dict[key] = {\n",
    "#             'value': value\n",
    "#         }\n",
    "#     else:\n",
    "#     if is_number(value):\n",
    "#         parameters_dict[key] = {\n",
    "#             'value': value\n",
    "#         }\n",
    "#     else:\n",
    "#         parameters_dict[key] = {\n",
    "#             'values': value\n",
    "#         }\n",
    "\n",
    "\n",
    "# sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweeping for: baseline\n",
      "Create sweep with ID: bn3hs43o\n",
      "Sweep URL: https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/sweeps/bn3hs43o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7zy8lfzu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0861497266574595\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">charmed-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/sweeps/bn3hs43o\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/sweeps/bn3hs43o</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/7zy8lfzu\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/7zy8lfzu</a><br/>\n",
       "                Run data is saved locally in <code>../../data/stage4/ResNet1D/wandb/run-20220316_002044-7zy8lfzu</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 20, 'learning_rate': 0.0861497266574595}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13187<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>../../data/stage4/ResNet1D/wandb/run-20220316_002044-7zy8lfzu/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>../../data/stage4/ResNet1D/wandb/run-20220316_002044-7zy8lfzu/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">charmed-sweep-1</strong>: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/7zy8lfzu\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/7zy8lfzu</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: prv3bmml with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06763614398903549\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">effortless-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/sweeps/bn3hs43o\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/sweeps/bn3hs43o</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/prv3bmml\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/prv3bmml</a><br/>\n",
       "                Run data is saved locally in <code>../../data/stage4/ResNet1D/wandb/run-20220316_002052-prv3bmml</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 10, 'learning_rate': 0.06763614398903549}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13231<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>../../data/stage4/ResNet1D/wandb/run-20220316_002052-prv3bmml/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>../../data/stage4/ResNet1D/wandb/run-20220316_002052-prv3bmml/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">effortless-sweep-2</strong>: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/prv3bmml\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/prv3bmml</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mywoza2z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.004307631342029089\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">logical-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline</a><br/>\n",
       "                Sweep page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/sweeps/bn3hs43o\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/sweeps/bn3hs43o</a><br/>\n",
       "Run page: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/mywoza2z\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/mywoza2z</a><br/>\n",
       "                Run data is saved locally in <code>../../data/stage4/ResNet1D/wandb/run-20220316_002103-mywoza2z</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 50, 'learning_rate': 0.004307631342029089}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 13290<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>../../data/stage4/ResNet1D/wandb/run-20220316_002103-mywoza2z/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>../../data/stage4/ResNet1D/wandb/run-20220316_002103-mywoza2z/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">logical-sweep-3</strong>: <a href=\"https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/mywoza2z\" target=\"_blank\">https://wandb.ai/inanlab/%5BEE%5D%20stage4_baseline/runs/mywoza2z</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yfdjxwxu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08748504655852164\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: <ipython-input-25-544eb4338fb6> 4 train_sweep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mchan/miniconda3/envs/mienv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 762, in init\n",
      "    run = wi.init()\n",
      "  File \"/home/mchan/miniconda3/envs/mienv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 533, in init\n",
      "    _ = backend.interface.communicate_run_start(run_obj)\n",
      "  File \"/home/mchan/miniconda3/envs/mienv/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 806, in communicate_run_start\n",
      "    result = self._communicate(rec)\n",
      "  File \"/home/mchan/miniconda3/envs/mienv/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 544, in _communicate\n",
      "    return self._communicate_async(rec, local=local).get(timeout=timeout)\n",
      "  File \"/home/mchan/miniconda3/envs/mienv/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 82, in get\n",
      "    is_set = self._object_ready.wait(timeout)\n",
      "  File \"/home/mchan/miniconda3/envs/mienv/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/mchan/miniconda3/envs/mienv/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "Exception\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    }
   ],
   "source": [
    "if training_params['wandb']:\n",
    "    print('sweeping for:', sweep_name)\n",
    "    \n",
    "#     with wandb.init(config=config, entity='inanlab', project=\"[TL] stage2_cnn\", reinit=True, dir=outputdir):\n",
    "    sweep_id = wandb.sweep(sweep_config, entity='inanlab', project='[EE] stage4_'+training_params['sweep_name'])\n",
    "\n",
    "#     sweep_id = wandb.sweep(sweep_config, project=sweep_name)\n",
    "    wandb.agent(sweep_id, train_sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_params['sweep_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EE_cosmed': 1, 'RR_cosmed': 0.5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define multi-task loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params['tasks'] = training_params['output_names']\n",
    "\n",
    "training_params['criterions'] = {}\n",
    "# training_params['loss_weights'] = {}\n",
    "\n",
    "for task in training_params['tasks']:\n",
    "    training_params['criterions'][task] =  torch.nn.MSELoss()\n",
    "    \n",
    "#     if task == 'EE_cosmed':\n",
    "#         training_params['loss_weights'][task] =  1\n",
    "#     else:\n",
    "#         training_params['loss_weights'][task] =  0.1\n",
    "\n",
    "criterion = MultiTaskLoss(training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some random param\n",
    "## kernel_size = 5 ~ 16*100/300 (16 for 300 Hz sampling rate, 5 for 100 sampling rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['downsample_gap']\n",
    "\n",
    "# # n_block = training_params['n_block_macro'][0] * training_params['downsample_gap'][0]\n",
    "# # downsample_gap = training_params['downsample_gap'][0]\n",
    "# # base_filters = training_params['base_filters'][0]\n",
    "# # use_sc =  training_params['use_sc']\n",
    "# # increasefilter_gap = downsample_gap * 2\n",
    "# # kernel_size = training_params['kernel_size']\n",
    "# # groups = training_params['base_filters'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_params['model_name'] == 'ResNet1D':\n",
    "# reference: https://github.com/hsd1503/resnet1d/blob/master/test_physionet.py\n",
    "    training_params['n_block'] = [training_params['n_block_macro'][0] * training_params['downsample_gap'][0]]\n",
    "    training_params['base_filters'] = [training_params['channel_n']] # [64] \n",
    "    training_params['in_channels'] = training_params['data_dimensions'][0]\n",
    "#     training_params['increasefilter_gap'] = [training_params['downsample_gap'][0] * 2]\n",
    "    training_params['increasefilter_gap'] = [training_params['downsample_gap'][0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kernel_size = 10 # ~ 16*100/300 (16 for 300 Hz sampling rate, 5 for 100 sampling rate)\n",
    "\n",
    "# training_params['stride'] = 2\n",
    "# # stride = 2\n",
    "# # increasefilter_gap = 12\n",
    "# # base_filters = 32\n",
    "# training_params['n_classes'] = 1\n",
    "# # n_classes = 1 # regression\n",
    "# training_params['groups'] = 32\n",
    "# # groups = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6000]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_params['data_dimensions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: need to fix summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model  ResNet1D\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 4, 6000]              24\n",
      "   MyConv1dPadSame-2              [-1, 4, 6000]               0\n",
      "       BatchNorm1d-3              [-1, 4, 6000]               8\n",
      "              ReLU-4              [-1, 4, 6000]               0\n",
      "            Conv1d-5              [-1, 4, 6000]              84\n",
      "   MyConv1dPadSame-6              [-1, 4, 6000]               0\n",
      "       BatchNorm1d-7              [-1, 4, 6000]               8\n",
      "              ReLU-8              [-1, 4, 6000]               0\n",
      "           Dropout-9              [-1, 4, 6000]               0\n",
      "           Conv1d-10              [-1, 4, 6000]              84\n",
      "  MyConv1dPadSame-11              [-1, 4, 6000]               0\n",
      "       BasicBlock-12              [-1, 4, 6000]               0\n",
      "      BatchNorm1d-13              [-1, 4, 6000]               8\n",
      "             ReLU-14              [-1, 4, 6000]               0\n",
      "          Dropout-15              [-1, 4, 6000]               0\n",
      "           Conv1d-16              [-1, 4, 3000]              84\n",
      "  MyConv1dPadSame-17              [-1, 4, 3000]               0\n",
      "      BatchNorm1d-18              [-1, 4, 3000]               8\n",
      "             ReLU-19              [-1, 4, 3000]               0\n",
      "          Dropout-20              [-1, 4, 3000]               0\n",
      "           Conv1d-21              [-1, 4, 3000]              84\n",
      "  MyConv1dPadSame-22              [-1, 4, 3000]               0\n",
      "        AvgPool1d-23              [-1, 4, 3000]               0\n",
      "MyAvgPool1dPadSame-24              [-1, 4, 3000]               0\n",
      "       BasicBlock-25              [-1, 4, 3000]               0\n",
      "      BatchNorm1d-26              [-1, 4, 3000]               8\n",
      "             ReLU-27              [-1, 4, 3000]               0\n",
      "          Dropout-28              [-1, 4, 3000]               0\n",
      "           Conv1d-29              [-1, 8, 3000]             168\n",
      "  MyConv1dPadSame-30              [-1, 8, 3000]               0\n",
      "      BatchNorm1d-31              [-1, 8, 3000]              16\n",
      "             ReLU-32              [-1, 8, 3000]               0\n",
      "          Dropout-33              [-1, 8, 3000]               0\n",
      "           Conv1d-34              [-1, 8, 3000]             328\n",
      "  MyConv1dPadSame-35              [-1, 8, 3000]               0\n",
      "       BasicBlock-36              [-1, 8, 3000]               0\n",
      "      BatchNorm1d-37              [-1, 8, 3000]              16\n",
      "             ReLU-38              [-1, 8, 3000]               0\n",
      "          Dropout-39              [-1, 8, 3000]               0\n",
      "           Conv1d-40              [-1, 8, 1500]             328\n",
      "  MyConv1dPadSame-41              [-1, 8, 1500]               0\n",
      "      BatchNorm1d-42              [-1, 8, 1500]              16\n",
      "             ReLU-43              [-1, 8, 1500]               0\n",
      "          Dropout-44              [-1, 8, 1500]               0\n",
      "           Conv1d-45              [-1, 8, 1500]             328\n",
      "  MyConv1dPadSame-46              [-1, 8, 1500]               0\n",
      "        AvgPool1d-47              [-1, 8, 1500]               0\n",
      "MyAvgPool1dPadSame-48              [-1, 8, 1500]               0\n",
      "       BasicBlock-49              [-1, 8, 1500]               0\n",
      "      BatchNorm1d-50              [-1, 8, 1500]              16\n",
      "             ReLU-51              [-1, 8, 1500]               0\n",
      "         ResNet1D-52                [-1, 12000]               0\n",
      "           Conv1d-53              [-1, 4, 6000]              24\n",
      "  MyConv1dPadSame-54              [-1, 4, 6000]               0\n",
      "      BatchNorm1d-55              [-1, 4, 6000]               8\n",
      "             ReLU-56              [-1, 4, 6000]               0\n",
      "           Conv1d-57              [-1, 4, 6000]              84\n",
      "  MyConv1dPadSame-58              [-1, 4, 6000]               0\n",
      "      BatchNorm1d-59              [-1, 4, 6000]               8\n",
      "             ReLU-60              [-1, 4, 6000]               0\n",
      "          Dropout-61              [-1, 4, 6000]               0\n",
      "           Conv1d-62              [-1, 4, 6000]              84\n",
      "  MyConv1dPadSame-63              [-1, 4, 6000]               0\n",
      "       BasicBlock-64              [-1, 4, 6000]               0\n",
      "      BatchNorm1d-65              [-1, 4, 6000]               8\n",
      "             ReLU-66              [-1, 4, 6000]               0\n",
      "          Dropout-67              [-1, 4, 6000]               0\n",
      "           Conv1d-68              [-1, 4, 3000]              84\n",
      "  MyConv1dPadSame-69              [-1, 4, 3000]               0\n",
      "      BatchNorm1d-70              [-1, 4, 3000]               8\n",
      "             ReLU-71              [-1, 4, 3000]               0\n",
      "          Dropout-72              [-1, 4, 3000]               0\n",
      "           Conv1d-73              [-1, 4, 3000]              84\n",
      "  MyConv1dPadSame-74              [-1, 4, 3000]               0\n",
      "        AvgPool1d-75              [-1, 4, 3000]               0\n",
      "MyAvgPool1dPadSame-76              [-1, 4, 3000]               0\n",
      "       BasicBlock-77              [-1, 4, 3000]               0\n",
      "      BatchNorm1d-78              [-1, 4, 3000]               8\n",
      "             ReLU-79              [-1, 4, 3000]               0\n",
      "          Dropout-80              [-1, 4, 3000]               0\n",
      "           Conv1d-81              [-1, 8, 3000]             168\n",
      "  MyConv1dPadSame-82              [-1, 8, 3000]               0\n",
      "      BatchNorm1d-83              [-1, 8, 3000]              16\n",
      "             ReLU-84              [-1, 8, 3000]               0\n",
      "          Dropout-85              [-1, 8, 3000]               0\n",
      "           Conv1d-86              [-1, 8, 3000]             328\n",
      "  MyConv1dPadSame-87              [-1, 8, 3000]               0\n",
      "       BasicBlock-88              [-1, 8, 3000]               0\n",
      "      BatchNorm1d-89              [-1, 8, 3000]              16\n",
      "             ReLU-90              [-1, 8, 3000]               0\n",
      "          Dropout-91              [-1, 8, 3000]               0\n",
      "           Conv1d-92              [-1, 8, 1500]             328\n",
      "  MyConv1dPadSame-93              [-1, 8, 1500]               0\n",
      "      BatchNorm1d-94              [-1, 8, 1500]              16\n",
      "             ReLU-95              [-1, 8, 1500]               0\n",
      "          Dropout-96              [-1, 8, 1500]               0\n",
      "           Conv1d-97              [-1, 8, 1500]             328\n",
      "  MyConv1dPadSame-98              [-1, 8, 1500]               0\n",
      "        AvgPool1d-99              [-1, 8, 1500]               0\n",
      "MyAvgPool1dPadSame-100              [-1, 8, 1500]               0\n",
      "      BasicBlock-101              [-1, 8, 1500]               0\n",
      "     BatchNorm1d-102              [-1, 8, 1500]              16\n",
      "            ReLU-103              [-1, 8, 1500]               0\n",
      "        ResNet1D-104                [-1, 12000]               0\n",
      "          Conv1d-105              [-1, 4, 6000]              24\n",
      " MyConv1dPadSame-106              [-1, 4, 6000]               0\n",
      "     BatchNorm1d-107              [-1, 4, 6000]               8\n",
      "            ReLU-108              [-1, 4, 6000]               0\n",
      "          Conv1d-109              [-1, 4, 6000]              84\n",
      " MyConv1dPadSame-110              [-1, 4, 6000]               0\n",
      "     BatchNorm1d-111              [-1, 4, 6000]               8\n",
      "            ReLU-112              [-1, 4, 6000]               0\n",
      "         Dropout-113              [-1, 4, 6000]               0\n",
      "          Conv1d-114              [-1, 4, 6000]              84\n",
      " MyConv1dPadSame-115              [-1, 4, 6000]               0\n",
      "      BasicBlock-116              [-1, 4, 6000]               0\n",
      "     BatchNorm1d-117              [-1, 4, 6000]               8\n",
      "            ReLU-118              [-1, 4, 6000]               0\n",
      "         Dropout-119              [-1, 4, 6000]               0\n",
      "          Conv1d-120              [-1, 4, 3000]              84\n",
      " MyConv1dPadSame-121              [-1, 4, 3000]               0\n",
      "     BatchNorm1d-122              [-1, 4, 3000]               8\n",
      "            ReLU-123              [-1, 4, 3000]               0\n",
      "         Dropout-124              [-1, 4, 3000]               0\n",
      "          Conv1d-125              [-1, 4, 3000]              84\n",
      " MyConv1dPadSame-126              [-1, 4, 3000]               0\n",
      "       AvgPool1d-127              [-1, 4, 3000]               0\n",
      "MyAvgPool1dPadSame-128              [-1, 4, 3000]               0\n",
      "      BasicBlock-129              [-1, 4, 3000]               0\n",
      "     BatchNorm1d-130              [-1, 4, 3000]               8\n",
      "            ReLU-131              [-1, 4, 3000]               0\n",
      "         Dropout-132              [-1, 4, 3000]               0\n",
      "          Conv1d-133              [-1, 8, 3000]             168\n",
      " MyConv1dPadSame-134              [-1, 8, 3000]               0\n",
      "     BatchNorm1d-135              [-1, 8, 3000]              16\n",
      "            ReLU-136              [-1, 8, 3000]               0\n",
      "         Dropout-137              [-1, 8, 3000]               0\n",
      "          Conv1d-138              [-1, 8, 3000]             328\n",
      " MyConv1dPadSame-139              [-1, 8, 3000]               0\n",
      "      BasicBlock-140              [-1, 8, 3000]               0\n",
      "     BatchNorm1d-141              [-1, 8, 3000]              16\n",
      "            ReLU-142              [-1, 8, 3000]               0\n",
      "         Dropout-143              [-1, 8, 3000]               0\n",
      "          Conv1d-144              [-1, 8, 1500]             328\n",
      " MyConv1dPadSame-145              [-1, 8, 1500]               0\n",
      "     BatchNorm1d-146              [-1, 8, 1500]              16\n",
      "            ReLU-147              [-1, 8, 1500]               0\n",
      "         Dropout-148              [-1, 8, 1500]               0\n",
      "          Conv1d-149              [-1, 8, 1500]             328\n",
      " MyConv1dPadSame-150              [-1, 8, 1500]               0\n",
      "       AvgPool1d-151              [-1, 8, 1500]               0\n",
      "MyAvgPool1dPadSame-152              [-1, 8, 1500]               0\n",
      "      BasicBlock-153              [-1, 8, 1500]               0\n",
      "     BatchNorm1d-154              [-1, 8, 1500]              16\n",
      "            ReLU-155              [-1, 8, 1500]               0\n",
      "        ResNet1D-156                [-1, 12000]               0\n",
      "     BatchNorm1d-157                [-1, 36001]          72,002\n",
      "            ReLU-158                [-1, 36001]               0\n",
      "          Linear-159                   [-1, 50]       1,800,100\n",
      "          Linear-160                    [-1, 1]              51\n",
      "RespiratoryRegression-161                    [-1, 1]               0\n",
      "     BatchNorm1d-162                [-1, 36001]          72,002\n",
      "            ReLU-163                [-1, 36001]               0\n",
      "          Linear-164                   [-1, 50]       1,800,100\n",
      "          Linear-165                    [-1, 1]              51\n",
      "RespiratoryRegression-166                    [-1, 1]               0\n",
      "     BatchNorm1d-167                [-1, 36001]          72,002\n",
      "            ReLU-168                [-1, 36001]               0\n",
      "          Linear-169                   [-1, 50]       1,800,100\n",
      "          Linear-170                    [-1, 1]              51\n",
      "RespiratoryRegression-171                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 5,621,307\n",
      "Trainable params: 5,621,307\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 23.07\n",
      "Params size (MB): 21.44\n",
      "Estimated Total Size (MB): 44.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_model(training_params):\n",
    "\n",
    "    print('using model ', training_params['model_name'])\n",
    "\n",
    "    model = resp_multiverse(training_params=training_params)\n",
    "    summary(model, input_size=[tuple(training_params['data_dimensions']), (model.N_features,1)], device='cpu')\n",
    "    del model\n",
    "\n",
    "\n",
    "debug_model = True\n",
    "if debug_model==True:\n",
    "    test_model(training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define training, validating, and evaluating funcitons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = train_resnet\n",
    "evaler = eval_resnet\n",
    "preder = pred_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the input signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 90\n",
    "\n",
    "# plt.plot(dataloaders['train'].dataset.data[k,0,:])\n",
    "# plt.plot(dataloaders['train'].dataset.data[k,1,:])\n",
    "# plt.plot(dataloaders['train'].dataset.data[k,2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, training_params, trainer, evaler, preder):\n",
    "\n",
    "#     inputdir = training_params['inputdir']\n",
    "    \n",
    "#     dataloaders, dataset_sizes = get_loaders(inputdir, training_params)\n",
    "\n",
    "#     total_loss_train = np.zeros(training_params['num_epochs'])\n",
    "#     total_loss_val = np.zeros(training_params['num_epochs'])\n",
    "\n",
    "#     print('\\t start training.....')\n",
    "\n",
    "#     for epoch in range(training_params['num_epochs']):\n",
    "#         if epoch%10==1:\n",
    "#             print(epoch)\n",
    "#         training_params['epoch'] = epoch\n",
    "\n",
    "#         ##### model training mode ####\n",
    "#         performance_dict_train = trainer(model, dataloaders['train'], training_params)\n",
    "#         total_loss_train[epoch] = performance_dict_train['total_loss']\n",
    "\n",
    "#         performance_dict_val = evaler(model, dataloaders['val'], training_params)\n",
    "#         total_loss_val[epoch] = performance_dict_val['total_loss']\n",
    "\n",
    "#     print('\\t done with training.....')\n",
    "\n",
    "#     performance_dict_train = preder(model, dataloaders['train'], training_params)\n",
    "#     performance_dict_val = preder(model, dataloaders['val'], training_params)\n",
    "\n",
    "    \n",
    "#     CV_dict = {\n",
    "#         'performance_dict_train': performance_dict_train,\n",
    "#         'total_loss_train': total_loss_train,\n",
    "#         'performance_dict_val': performance_dict_val,\n",
    "#         'total_loss_val': total_loss_val,\n",
    "#         'model': model,\n",
    "#         'subject_id_val': training_params['CV_config']['subject_id'], \n",
    "#     }\n",
    "    \n",
    "#     return CV_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CV_config': {'subject_id': 113, 'task_id': 5},\n",
      " 'FS_RESAMPLE_DL': 100,\n",
      " 'batch_size': 64,\n",
      " 'channel_n': 4,\n",
      " 'criterions': {'EE_cosmed': MSELoss(), 'RR_cosmed': MSELoss()},\n",
      " 'cuda_i': 1,\n",
      " 'data_dimensions': [3, 6000],\n",
      " 'device': device(type='cuda', index=1),\n",
      " 'downsample_gap': [2],\n",
      " 'featrue_extractor': <class 'models_resnet.ResNet1D'>,\n",
      " 'feature_names': ['weight', 'height', 'gender'],\n",
      " 'fusion_type': 'late',\n",
      " 'groups': [1],\n",
      " 'input_names': ['ECG', 'accelZ', 'ppg_g_1'],\n",
      " 'kernel_size': [5],\n",
      " 'learning_rate': 0.001,\n",
      " 'list_feature': ['VE_cosmed',\n",
      "                  'HR_patch',\n",
      "                  'weight',\n",
      "                  'height',\n",
      "                  'gender',\n",
      "                  'age',\n",
      "                  'BMR'],\n",
      " 'list_meta': ['subject_id', 'task'],\n",
      " 'list_output': ['RR_cosmed',\n",
      "                 'VT_cosmed',\n",
      "                 'EE_cosmed',\n",
      "                 'SPO2_cosmed',\n",
      "                 'HR_cosmed',\n",
      "                 'VO2_cosmed',\n",
      "                 'resp_cosmed'],\n",
      " 'list_signal': ['ECG', 'accelZ', 'ppg_g_1'],\n",
      " 'loss_weights': {'EE_cosmed': 1, 'RR_cosmed': 0.5},\n",
      " 'meta_names': ['subject_id', 'task'],\n",
      " 'model_name': 'ResNet1D',\n",
      " 'n_block_macro': [2],\n",
      " 'num_epochs': 5,\n",
      " 'output_names': ['EE_cosmed', 'RR_cosmed'],\n",
      " 'pooling_type': 'avg_pooling',\n",
      " 'stride': [2],\n",
      " 'subject_ids': array([101, 102, 103, 104, 106, 107, 110, 111, 113, 114, 115, 116, 118,\n",
      "       119, 120, 121, 212]),\n",
      " 'sweep_name': 'baseline',\n",
      " 'task_ids': array([0, 1, 2, 3, 4, 5]),\n",
      " 'tasks': ['EE_cosmed', 'RR_cosmed'],\n",
      " 'use_sc': True,\n",
      " 'wandb': True}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_featuremap(model, dataloader, training_params, fig_name=None, show_plot=False, outputdir=None):\n",
    "\n",
    "    # 1. set up the hook\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    data = torch.from_numpy(dataloader.dataset.data)\n",
    "    feature = torch.from_numpy(dataloader.dataset.feature)\n",
    "    data = data.to(device).float()\n",
    "    feature = feature.to(device).float()\n",
    "\n",
    "    # 2. check one sample only\n",
    "    N_samples = dataloader.dataset.data.shape[0]\n",
    "    np.random.seed(0)\n",
    "    i_sample = np.random.randint(N_samples)\n",
    "\n",
    "    #     model_hooking(model, training_params)\n",
    "\n",
    "    model_name = training_params['model_name']\n",
    "\n",
    "    # 3. define the layers that I want to look at\n",
    "    if model_name=='FeatureExtractor_CNN2':\n",
    "        key = list(model.feature_extractors.keys())[0]\n",
    "        model.feature_extractors[key].layer1.register_forward_hook(get_activation('layer1'))\n",
    "        model.feature_extractors[key].layer2.register_forward_hook(get_activation('layer2'))\n",
    "        model.feature_extractors[key].layer3.register_forward_hook(get_activation('layer3'))\n",
    "        model.feature_extractors[key].layer4.register_forward_hook(get_activation('layer4'))\n",
    "        model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "        model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n",
    "\n",
    "        layer_names = ['layer1', 'layer2', 'layer3', 'layer4', 'fc1', 'fc2']\n",
    "\n",
    "    elif model_name=='FeatureExtractor_CNN':\n",
    "        key = list(model.feature_extractors.keys())[0]\n",
    "        model.feature_extractors[key].layer1.register_forward_hook(get_activation('layer1'))\n",
    "        model.feature_extractors[key].layer2.register_forward_hook(get_activation('layer2'))\n",
    "        model.feature_extractors[key].layer3.register_forward_hook(get_activation('layer3'))\n",
    "        model.feature_extractors[key].layer4.register_forward_hook(get_activation('layer4'))\n",
    "        model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "        model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n",
    "        layer_names = ['layer1', 'layer2', 'layer3', 'layer4', 'fc1', 'fc2']\n",
    "\n",
    "    if model_name=='ResNet1D':\n",
    "        \n",
    "        \n",
    "        model.feature_extractors.ECG.basicblock_list[-1].register_forward_hook(get_activation('ecg_layer_last'))\n",
    "#         model.feature_extractors.ECG.basicblock_list[4].register_forward_hook(get_activation('ecg_layer5'))\n",
    "#         model.feature_extractors.ECG.basicblock_list[8].register_forward_hook(get_activation('ecg_layer3'))\n",
    "#         model.feature_extractors.ECG.basicblock_list[12].register_forward_hook(get_activation('ecg_layer13'))\n",
    "        model.feature_extractors.accelZ.basicblock_list[-1].register_forward_hook(get_activation('scg_layer_last'))\n",
    "#         model.feature_extractors.accelZ.basicblock_list[4].register_forward_hook(get_activation('scg_layer5'))\n",
    "#         model.feature_extractors.accelZ.basicblock_list[8].register_forward_hook(get_activation('scg_layer3'))\n",
    "#         model.feature_extractors.accelZ.basicblock_list[12].register_forward_hook(get_activation('scg_layer13'))\n",
    "        model.feature_extractors.ppg_g_1.basicblock_list[-1].register_forward_hook(get_activation('ppg_layer_last'))\n",
    "#         model.feature_extractors.ppg_g_1.basicblock_list[4].register_forward_hook(get_activation('ppg_layer5'))\n",
    "#         model.feature_extractors.ppg_g_1.basicblock_list[8].register_forward_hook(get_activation('ppg_layer3'))\n",
    "#         model.feature_extractors.ppg_g_1.basicblock_list[12].register_forward_hook(get_activation('ppg_layer13'))\n",
    "    \n",
    "\n",
    "#         model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "#         model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n",
    "        \n",
    "        \n",
    "#         layer_names = ['ecg_layer1', 'ecg_layer5', 'ecg_layer13', 'scg_layer1', 'scg_layer5', 'scg_layer13', 'pcg_layer1', 'ppg_layer5', 'ppg_layer13', 'fc1', 'fc2']\n",
    "        layer_names = ['ecg_layer_last', 'scg_layer_last', 'ppg_layer_last']\n",
    "\n",
    "    # 4. pass the data to the model and the hook will take care of the rest (output stored in activation)\n",
    "#     output = model(data, feature)\n",
    "    _ = model(data, feature)\n",
    "\n",
    "    data = data.cpu().detach().numpy()\n",
    "\n",
    "    # 5. organize these activation layers\n",
    "    data_layers = {}\n",
    "    for layer_name in layer_names:\n",
    "        data_layers[layer_name] = activation[layer_name].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    for layer_name in layer_names:\n",
    "        \n",
    "        data_layer = data_layers[layer_name]\n",
    "#         print(data_layer.shape)\n",
    "\n",
    "        N_sigs = len(training_params['input_names'])\n",
    "\n",
    "        fig, axes = plt.subplots(data_layer.shape[1]+1,1, figsize=(15, data_layer.shape[1]), dpi=80, gridspec_kw = {'wspace':0, 'hspace':0}, facecolor='white')\n",
    "        fontsize = 13\n",
    "\n",
    "        FS_RESAMPLE_DL = training_params['FS_RESAMPLE_DL']\n",
    "        t_arr = np.arange(data.shape[-1])/FS_RESAMPLE_DL\n",
    "\n",
    "#         for i, input_name in enumerate(training_params['input_names']):\n",
    "\n",
    "        # 1. plot one physio sig at the top column\n",
    "        ax = axes[0]\n",
    "\n",
    "        if 'ecg' in layer_name:\n",
    "            unit = unit_dict['ecg']\n",
    "            i_sig = training_params['input_names'].index('ECG')\n",
    "        elif 'scg' in layer_name:\n",
    "            unit = unit_dict['accel']\n",
    "            i_sig = training_params['input_names'].index('accelZ')\n",
    "        elif 'ppg' in layer_name:\n",
    "            unit = unit_dict['ppg']\n",
    "            i_sig = training_params['input_names'].index('ppg_g_1')\n",
    "\n",
    "        sig_name = training_params['input_names'][i_sig]\n",
    "        ax.plot(t_arr, data[i_sample,i_sig,:])\n",
    "        ax.set_xlim(t_arr.min(), t_arr.max()) # remove the weird white space at the beg and end of the plot\n",
    "        ax.set_ylabel('{}\\n[{}]'.format(sig_name, unit), fontsize=fontsize,rotation = 0,  va='center', ha='center',  labelpad=100)\n",
    "\n",
    "        # 2. next, plot the feature map\n",
    "        t_arr = np.arange(data_layer.shape[-1]) / FS_RESAMPLE_DL / (2**(training_params['n_block_macro'][0]))\n",
    "        for j_filter, ax in enumerate(axes[1:]):\n",
    "\n",
    "            if j_filter!=len(axes[1:])-1:\n",
    "                ax.set_xticklabels([])\n",
    "\n",
    "            ax.plot(t_arr, data_layer[i_sample, j_filter, :].T, alpha=1)\n",
    "\n",
    "            ax.set_xlim(t_arr.min(), t_arr.max()) # remove the weird white space at the beg and end of the plot\n",
    "\n",
    "            # remove some borders (top and right)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            if j_filter==0:\n",
    "                ax.spines['top'].set_visible(False)\n",
    "\n",
    "            ax.set_ylabel('filter {}'.format(j_filter), fontsize=fontsize,rotation = 0,  va='center', ha='center',  labelpad=100)\n",
    "            # set tick font size\n",
    "            ax.tick_params(axis='both', which='major', labelsize=fontsize*0.8)\n",
    "\n",
    "            ax.set_xlabel('time (sec)', fontsize=fontsize)\n",
    "            fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        if fig_name is None:\n",
    "            fig_name = 'DL_activation_'\n",
    "#             print('hihi', sig_name)\n",
    "#         fig_name = 'DL_activation_'+sig_name\n",
    "\n",
    "#         print(fig_name)\n",
    "\n",
    "        if outputdir is not None:\n",
    "            if not os.path.exists(outputdir):\n",
    "                os.makedirs(outputdir)\n",
    "            fig.savefig(outputdir + fig_name+sig_name + '.png', facecolor=fig.get_facecolor())\n",
    "\n",
    "        if show_plot == False:\n",
    "            plt.close(fig)\n",
    "            pyplot.close(fig)\n",
    "            plt.close('all')\n",
    "            \n",
    "        \n",
    "\n",
    "#     fig, ax_last = plt.subplots(1,1, figsize=(20, 3), dpi=80)\n",
    "#     ax_last.plot(data_fc1[i_sample, :], alpha=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_train = {}\n",
    "df_performance_val = {}\n",
    "\n",
    "df_outputlabel_train = {}\n",
    "df_outputlabel_val = {}\n",
    "\n",
    "for task in training_params['tasks']:\n",
    "\n",
    "    df_performance_train[task] = pd.DataFrame()\n",
    "    df_performance_val[task] = pd.DataFrame()\n",
    "\n",
    "    df_outputlabel_train[task] = pd.DataFrame()\n",
    "    df_outputlabel_val[task] = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda:1\n",
      "using model  ResNet1D\n",
      "\t start training.....\n",
      "1\n",
      "\t done with training.....\n",
      "using device cuda:1\n",
      "using model  ResNet1D\n",
      "\t start training.....\n",
      "1\n",
      "\t done with training.....\n",
      "using device cuda:1\n",
      "using model  ResNet1D\n",
      "\t start training.....\n",
      "1\n",
      "\t done with training.....\n",
      "using device cuda:1\n",
      "using model  ResNet1D\n",
      "\t start training.....\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b84c7df7aef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtraining_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputdir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mCV_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Estimation_EE/repo/PatchWand/training_util.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, training_params, trainer, evaler, preder)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m##### model training mode ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mperformance_dict_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mtotal_loss_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance_dict_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Estimation_EE/repo/PatchWand/training_util.py\u001b[0m in \u001b[0;36mtrain_resnet\u001b[0;34m(model, dataloader, training_params)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#         print(out, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#         sys.exit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mienv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Estimation_EE/repo/PatchWand/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, label)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m#         print(output, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Estimation_EE/repo/PatchWand/models.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m#         print(output, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "ordered_subject_ids = np.asarray([115, 107, 113, 110, 101, 104, 106, 121, 212, 102, 103, 111, 114, 116, 118, 119, 120])\n",
    "\n",
    "\n",
    "\n",
    "# for subject_id in training_params['subject_ids']:\n",
    "for subject_id in ordered_subject_ids:\n",
    "\n",
    "    training_params['CV_config']['subject_id'] = subject_id\n",
    "\n",
    "    device = torch.device('cuda:{}'.format(int(training_params['cuda_i'])) if torch.cuda.is_available() else 'cpu')\n",
    "    print('using device', device)\n",
    "\n",
    "    \n",
    "    print('using model ', training_params['model_name'])\n",
    "\n",
    "    model = resp_multiverse(training_params=training_params)\n",
    "\n",
    "    model = model.to(device).float()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=training_params['learning_rate'], weight_decay=0.01)\n",
    "\n",
    "    training_params['criterion'] = criterion\n",
    "    training_params['optimizer'] = optimizer\n",
    "    training_params['inputdir'] = inputdir\n",
    "\n",
    "    CV_dict = train_model(model, training_params, trainer, evaler, preder)\n",
    "    plot_losses(CV_dict, outputdir=outputdir, show_plot=False)\n",
    "\n",
    "    for task in training_params['tasks']:\n",
    "        label_est_val = CV_dict['performance_dict_val']['out_dict'][task]\n",
    "        label_val = CV_dict['performance_dict_val']['label_dict'][task]\n",
    "\n",
    "        label_est_train = CV_dict['performance_dict_train']['out_dict'][task]\n",
    "        label_train = CV_dict['performance_dict_train']['label_dict'][task]\n",
    "        \n",
    "        # get performance df for training and testing dataset\n",
    "        df_performance_train[task] = df_performance_train[task].append( get_df_performance(label_train, label_est_train, subject_id, task), ignore_index=True )\n",
    "        df_performance_train[task].to_csv(outputdir+'df_performance_train_{}.csv'.format(task), index=False)\n",
    "\n",
    "        df_outputlabel_train[task] = df_outputlabel_train[task].append(\n",
    "            pd.DataFrame( {\n",
    "            'label_est': label_est_train,\n",
    "            'label': label_train,\n",
    "            'CV': [subject_id]*label_train.shape[0],\n",
    "            'task': [task]*label_train.shape[0]\n",
    "            }), ignore_index=True )\n",
    "        \n",
    "        df_outputlabel_train[task].to_csv(outputdir+'df_outputlabel_train_{}.csv'.format(task), index=False)\n",
    "\n",
    "        df_performance_val[task] = df_performance_val[task].append( get_df_performance(label_val, label_est_val, subject_id, task), ignore_index=True )\n",
    "        df_performance_val[task].to_csv(outputdir+'df_performance_val_{}.csv'.format(task), index=False)\n",
    "        \n",
    "        df_outputlabel_val[task] = df_outputlabel_val[task].append(\n",
    "            pd.DataFrame( {\n",
    "            'label_est': label_est_val,\n",
    "            'label': label_val,\n",
    "            'CV': [subject_id]*label_val.shape[0],\n",
    "            'task': [task]*label_val.shape[0]\n",
    "            }), ignore_index=True )\n",
    "        \n",
    "        df_outputlabel_val[task].to_csv(outputdir+'df_outputlabel_val_{}.csv'.format(task), index=False)\n",
    "\n",
    "        # plot performance training and testing dataset\n",
    "        plot_regression(df_outputlabel_train[task], df_performance_train[task], task, fig_name='regression_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "        plot_BA(df_outputlabel_train[task], task, fig_name='BA_train_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "        \n",
    "        plot_regression(df_outputlabel_val[task], df_performance_val[task], task, fig_name='regression_val_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "        plot_BA(df_outputlabel_val[task], task, fig_name='BA_val_{}'.format(task), show_plot=False, outputdir=outputdir+'model_output/')\n",
    "\n",
    "        plot_output(df_outputlabel_train[task], task, fig_name = 'outputINtime_train_', show_plot=True, outputdir=outputdir+'model_output/')\n",
    "        plot_output(df_outputlabel_val[task], task, fig_name = 'outputINtime_val_',  show_plot=True, outputdir=outputdir+'model_output/')\n",
    "\n",
    "        \n",
    "    check_featuremap(model, dataloaders['val'], training_params, fig_name = 'DL_activation_{}_'.format(subject_id), outputdir=outputdir+'activation_layers/', show_plot=False)\n",
    "\n",
    "\n",
    "#     sys.exit()\n",
    "    del model\n",
    "\n",
    "print('rmse={:.2f}, mae={:.2f}, PCC={:.2f}'.format(df_performance_val['EE_cosmed']['rmse'].mean(), df_performance_val['EE_cosmed']['mae'].mean(), df_performance_val['EE_cosmed']['PCC'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8480c3732c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatetime_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz_NY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"end time:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%b-%d %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime_end\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdatetime_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mduration_in_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "datetime_end = datetime.now(tz_NY)\n",
    "print(\"end time:\", datetime_end.strftime(\"%Y-%b-%d %H:%M:%S\"))\n",
    "\n",
    "duration = datetime_end-datetime_start\n",
    "duration_in_s = duration.total_seconds()\n",
    "days    = divmod(duration_in_s, 86400)        # Get days (without [0]!)\n",
    "hours   = divmod(days[1], 3600)               # Use remainder of days to calc hours\n",
    "minutes = divmod(hours[1], 60)                # Use remainder of hours to calc minutes\n",
    "seconds = divmod(minutes[1], 1)               # Use remainder of minutes to calc seconds\n",
    "print(\"Time between dates: %d days, %d hours, %d minutes and %d seconds\" % (days[0], hours[0], minutes[0], seconds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def get_activation(name):\n",
    "# #     activation = {}\n",
    "# #     def hook(model, input, output):\n",
    "# #         activation[name] = output.detach()\n",
    "# #     return hook\n",
    "    \n",
    "# def model_hooking(model, training_params, get_activation):\n",
    "\n",
    "#     model_name = training_params['model_name']\n",
    "    \n",
    "#     if model_name=='FeatureExtractor_CNN2':\n",
    "#         key = list(model.feature_extractors.keys())[0]\n",
    "#         model.feature_extractors[key].layer1.register_forward_hook(get_activation('layer1'))\n",
    "#         model.feature_extractors[key].layer2.register_forward_hook(get_activation('layer2'))\n",
    "#         model.feature_extractors[key].layer3.register_forward_hook(get_activation('layer3'))\n",
    "#         model.feature_extractors[key].layer4.register_forward_hook(get_activation('layer4'))\n",
    "#         model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "#         model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n",
    "        \n",
    "# #         layer_names = ['layer1', ]\n",
    "        \n",
    "#     elif model_name=='FeatureExtractor_CNN':\n",
    "#         key = list(model.feature_extractors.keys())[0]\n",
    "#         model.feature_extractors[key].layer1.register_forward_hook(get_activation('layer1'))\n",
    "#         model.feature_extractors[key].layer2.register_forward_hook(get_activation('layer2'))\n",
    "#         model.feature_extractors[key].layer3.register_forward_hook(get_activation('layer3'))\n",
    "#         model.feature_extractors[key].layer4.register_forward_hook(get_activation('layer4'))\n",
    "#         model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "#         model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n",
    "#     if model_name=='ResNet1D':\n",
    "#         pass\n",
    "# #         key = list(model.feature_extractors.keys())[0]\n",
    "# #         model.feature_extractors[key].layer1.register_forward_hook(get_activation('layer1'))\n",
    "# #         model.feature_extractors[key].layer2.register_forward_hook(get_activation('layer2'))\n",
    "# #         model.feature_extractors[key].layer3.register_forward_hook(get_activation('layer3'))\n",
    "# #         model.feature_extractors[key].layer4.register_forward_hook(get_activation('layer4'))\n",
    "# #         model.regressors.EE_cosmed.fc1.register_forward_hook(get_activation('fc1'))\n",
    "# #         model.regressors.EE_cosmed.fc2.register_forward_hook(get_activation('fc2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: improve this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict_train = preder(model, dataloaders['train'], training_params)\n",
    "performance_dict_val = preder(model, dataloaders['val'], training_params)\n",
    "\n",
    "unit = unit_dict[task.split('_')[0]]\n",
    "\n",
    "for task in training_params['tasks']:\n",
    "    \n",
    "    \n",
    "    print('evaluating task:', task)\n",
    "    MAE, std_AE = get_MAE(performance_dict_train['out_dict'][task], performance_dict_train['label_dict'][task])\n",
    "    print('\\ttrainin: {:.2f}±{:.2f} {}'.format(MAE, std_AE, unit))\n",
    "\n",
    "    MAE, std_AE = get_MAE(performance_dict_val['out_dict'][task], performance_dict_val['label_dict'][task])\n",
    "    print('\\tval: {:.2f}±{:.2f} {}'.format(MAE, std_AE, unit))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# produce output figures\n",
    "# TODO: implement the plotting functions below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO!!!!\n",
    "\n",
    "# for task in tasks\n",
    "#     plot_loss vs epoch (train and val)\n",
    "#     plot_MAE, RMSE, vs epoch (train and val)\n",
    "#     plot scatter plots (show PCC, BD, std, ect.) (just val)\n",
    "#     plot output vs. label (just val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = training_params['output_names'][0].split('_')[0]\n",
    "unit_dict[output_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kcalpmin2watt = 69.7333333\n",
    "\n",
    "# sub_weight = 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance_dict_train['label_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params['tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in training_params['tasks']:\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5), dpi=100)\n",
    "    fontsize = 15\n",
    "    data_min = np.min(np.r_[performance_dict_train['out_dict'][task], performance_dict_train['label_dict'][task]])\n",
    "    data_max = np.max(np.r_[performance_dict_train['out_dict'][task], performance_dict_train['label_dict'][task]])\n",
    "    ax1.scatter(performance_dict_train['out_dict'][task], performance_dict_train['label_dict'][task], alpha=0.3)\n",
    "    ax1.set_xlim(data_min, data_max)\n",
    "    ax1.set_ylim(data_min, data_max)\n",
    "    ax1.plot( [data_min, data_max],[data_min, data_max], '--', color='gray', alpha=0.8)\n",
    "\n",
    "    ax1.set_xlabel('estimated {} ({})'.format(task.split('_')[0], unit_dict[task.split('_')[0]]), fontsize=fontsize)\n",
    "    ax1.set_ylabel('true {} ({})'.format(task.split('_')[0], unit_dict[task.split('_')[0]]), fontsize=fontsize)\n",
    "#     ax.set_xlabel('estimated {} ({})'.format(output_name, 'W'), fontsize=fontsize)\n",
    "#     ax.set_ylabel('true {} ({})'.format(output_name, 'W'), fontsize=fontsize)\n",
    "\n",
    "    ax1.set_title('training', fontsize=fontsize)\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(5,5))\n",
    "#     fontsize = 15\n",
    "    data_min = np.min(np.r_[performance_dict_val['out_dict'][task], performance_dict_val['label_dict'][task]])\n",
    "    data_max = np.max(np.r_[performance_dict_val['out_dict'][task], performance_dict_val['label_dict'][task]])\n",
    "    ax2.scatter(performance_dict_val['out_dict'][task], performance_dict_val['label_dict'][task], alpha=0.3)\n",
    "    ax2.set_xlim(data_min, data_max)\n",
    "    ax2.set_ylim(data_min, data_max)\n",
    "    ax2.plot( [data_min, data_max],[data_min, data_max], '--', color='gray', alpha=0.8)\n",
    "\n",
    "    ax2.set_xlabel('estimated {} ({})'.format(task.split('_')[0], unit_dict[task.split('_')[0]]), fontsize=fontsize)\n",
    "    ax2.set_ylabel('true {} ({})'.format(task.split('_')[0], unit_dict[task.split('_')[0]]), fontsize=fontsize)\n",
    "    \n",
    "    ax2.set_title('testing', fontsize=fontsize)\n",
    "\n",
    "#     ax.set_xlabel('estimated {} ({})'.format(output_name, 'W'), fontsize=fontsize)\n",
    "#     ax.set_ylabel('true {} ({})'.format(output_name, 'W'), fontsize=fontsize)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mienv",
   "language": "python",
   "name": "mienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
