{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: convert this to .py and write shell script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "\n",
    "import math\n",
    "from math import sin\n",
    "\n",
    "# plt.style.use('dark_background')\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft, ifft\n",
    "from scipy.signal import hilbert, chirp\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import pywt\n",
    "from pywt import scale2frequency\n",
    "\n",
    "import emd\n",
    "\n",
    "i_seed = 0\n",
    "\n",
    "    \n",
    "import sys\n",
    "sys.path.append('../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../../') # add this line so Data and data are visible in this file\n",
    "sys.path.append('../PatchWand/') # add this line so Data and data are visible in this file\n",
    "\n",
    "from plotting_tools import *\n",
    "from preprocessing import *\n",
    "# from data_pulling import *\n",
    "from setting import *\n",
    "from surrogate_extraction import *\n",
    "from dataIO import *\n",
    "from filters import *\n",
    "from spectral_module import *\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "# checklist 1: uncomment matplotlib.use('Agg')\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "matplotlib.rc( 'savefig', facecolor = 'white' )\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# checklist 2: comment out all magic command\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# please design this HP carefully, use inspect_TF_rep to find optimal value\n",
    "# length_medfilt = 55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(input_folder='../../data/stage3/resp/', modalities='ECG_AM', output_folder='../../data/stage3-1_windowing/CDC_dataset/', script_id='?', windowing_params='windowing_params.json')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='RR_estimate')\n",
    "parser.add_argument('--input_folder', metavar='input_folder', help='input_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--output_folder', metavar='output_folder', help='output_folder',\n",
    "                    default='../')\n",
    "parser.add_argument('--windowing_params', metavar='windowing_params', help='windowing_params',\n",
    "                    default='windowing_params.json')\n",
    "\n",
    "parser.add_argument('--modalities', metavar='modalities', help='modalities',\n",
    "                    default='ECG_AM')\n",
    "\n",
    "parser.add_argument('--script_id', metavar='script_id', help='script_id',\n",
    "                    default='?')\n",
    "\n",
    "\n",
    "# checklist 3: comment first line, uncomment second line\n",
    "args = parser.parse_args(['--input_folder', '../../data/stage3/resp/', \n",
    "                          '--output_folder', '../../data/stage3-1_windowing/CDC_dataset/',\n",
    "                          '--windowing_params', 'windowing_params.json'])\n",
    "\n",
    "# args = parser.parse_args(['--input_folder', '/home/mchan/Estimation_RR/covid/results/stage2/', \n",
    "#                           '--output_folder', '../../data/stage3-1_windowing/GT_dataset/',\n",
    "#                           '--windowing_params', 'windowing_params.json'])\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will export data to ../../data/stage3-1_windowing/CDC_dataset/\n"
     ]
    }
   ],
   "source": [
    "inputdir = args.input_folder\n",
    "outputdir = args.output_folder\n",
    "windowing_params = args.windowing_params\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "print('will export data to', outputdir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(windowing_params) as json_file:\n",
    "    windowing_params_list = json.load(json_file)\n",
    "\n",
    "windowing_params = windowing_params_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get items from windowing_params dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if windowing_params.get('remove_outliers'): \n",
    "    clean_str = '_cleaned'\n",
    "else:\n",
    "    clean_str = ''\n",
    "\n",
    "normalization = windowing_params['normalization']\n",
    "\n",
    "if normalization:\n",
    "    norm_str = 'norm'\n",
    "else:\n",
    "    norm_str = ''\n",
    "    \n",
    "if windowing_params.get('debug_TF'): \n",
    "    debug_TF = windowing_params['debug_TF']\n",
    "else:\n",
    "    debug_TF = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will export data to ../../data/stage3-1_windowing/CDC_dataset/win60_overlap95_seq20_norm/\n"
     ]
    }
   ],
   "source": [
    "outputdir = outputdir+'win{}_overlap{}_seq{}_{}{}/'.format(str(windowing_params['window_size']), \\\n",
    "                                                                                int(windowing_params['overlap']*100), \\\n",
    "                                                                                str(windowing_params['seq_len']), \\\n",
    "                                                                                    clean_str,\n",
    "                                                                                    norm_str,\n",
    "                                                                                    )\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "print('will export data to', outputdir)\n",
    "\n",
    "\n",
    "if not os.path.exists(outputdir+'sur_resp/'):\n",
    "    os.makedirs(outputdir+'sur_resp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'GT_dataset' in outputdir:\n",
    "\n",
    "    home = expanduser(\"~\")\n",
    "\n",
    "    filename_subinfo = home+'/'+ 'Estimation_RR/covid/Mobashir_CosmedWearable/Cosmed Wearable Subject Information.xlsx'\n",
    "    df_subinfo = pd.read_excel(filename_subinfo) \n",
    "    df_subinfo\n",
    "\n",
    "    df_subinfo = df_subinfo.rename(columns={'Height in cm': 'Height', 'Weight in Kg': 'Weight', 'Subject ID':'Subject_ID'})\n",
    "\n",
    "    df_subinfo['Subject_ID'] = df_subinfo['Subject_ID'].apply(lambda x: int(x.split('M')[0].split('F')[0].split('CW')[1]))\n",
    "    df_subinfo = df_subinfo[['Subject_ID', 'Age', 'Height', 'Weight', 'Gender']].drop_duplicates().reset_index(drop=True)\n",
    "    df_subinfo['BMI'] = df_subinfo['Weight'].values / (df_subinfo['Height'].values/100)**2\n",
    "    df_subinfo['Fitzpatrick'] = -1\n",
    "    \n",
    "elif 'CDC_dataset' in outputdir:\n",
    "\n",
    "    filename_subinfo = '../../data/raw/FS Subject Information.xlsx'\n",
    "    df_subinfo = pd.read_excel(filename_subinfo, sheet_name='Subject info') \n",
    "\n",
    "    i_sub_last = np.where(df_subinfo['Subject_ID'].isnull()==True)[0][0]\n",
    "    df_subinfo = df_subinfo[:i_sub_last]\n",
    "\n",
    "    df_subinfo = df_subinfo[['Subject_ID', 'Age', 'Height(cm)', 'Weight(Kg)', 'Gender(0=Male,1=Female)', 'Fitzpatrick', '6MWT distance (m)', '6MWT-R distance (m)', 'Fitzpatrick']]\n",
    "    df_subinfo = df_subinfo.rename(columns={'Height(cm)': 'Height', 'Weight(Kg)': 'Weight', 'Gender(0=Male,1=Female)': 'Gender'})\n",
    "    df_subinfo['BMI'] = df_subinfo['Weight'].values / (df_subinfo['Height'].values/100)**2\n",
    "    df_subinfo['Subject_ID'] = df_subinfo['Subject_ID'].astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve signal and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve the data\n",
    "    TODO: include ECG PCA\n",
    "    TODO: go back to stage3 and check SCG AMpt again (value don't seem right)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/stage3-1_windowing/CDC_dataset/win60_overlap95_seq20_norm/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieve signal and labels from CDC or the GT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woring on CDC_datatset\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "show_RR_est = True\n",
    "\n",
    "if 'GT_dataset' in outputdir:\n",
    "    print('woring on GT_datatset')\n",
    "    windowing_params['Fs'] = FS_RESAMPLE_resp\n",
    "    Fs = FS_RESAMPLE_resp\n",
    "\n",
    "\n",
    "\n",
    "    df_resp_subs = pd.DataFrame()\n",
    "\n",
    "    for sub_file in os.listdir(inputdir):\n",
    "        if '.feather' in sub_file and 'error' not in sub_file and 'predictions' not in sub_file:\n",
    "            df = pd.read_feather(inputdir+sub_file) \n",
    "            subject_id = sub_file.split('_')[1].split('.')[0]\n",
    "            df = df.drop(columns=['ECG', 'accelX', 'accelY', 'accelZ', 'br_binary', 'rer', 'vevco2_slope', 'i_R_peaks', 'i_S_peaks'])\n",
    "            df = df.rename(columns={\"br\": \"RR_cosmed\", \"vt\": \"VT_cosmed\", \"heart_rate_cosmed\": \"HR_cosmed\"})\n",
    "#             sys.exit()\n",
    "\n",
    "            \n",
    "            Fs_df = np.median((1/np.diff(df['time'].values)).astype(int))\n",
    "            downsample_factor = int(Fs_df//FS_RESAMPLE_resp)\n",
    "#             downsample_factor = 1\n",
    "    \n",
    "            Fs = Fs_df/downsample_factor\n",
    "            windowing_params['Fs'] = Fs\n",
    "            \n",
    "            df = df[::downsample_factor]\n",
    "\n",
    "            print('working on {}...'.format(subject_id))\n",
    "\n",
    "            # add the task column\n",
    "            df['task'] = 'Recovery Treadmill'\n",
    "            df['task_id'] = 101\n",
    "\n",
    "\n",
    "            df_resp_subs = df_resp_subs.append(df)\n",
    "\n",
    "\n",
    "            print(df.shape[0]/Fs,'sec')\n",
    "            \n",
    "    df_resp_subs['domain'] = 'GT_datatset'\n",
    "    df_resp_subs['subject_id'] = df_resp_subs['subject_id'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "elif 'CDC_dataset' in outputdir:\n",
    "    print('woring on CDC_datatset')\n",
    "    df_resp_subs = pd.read_feather(inputdir+'df_resp_subs.feather')\n",
    "    df_resp_subs['subject_id'] = df_resp_subs['subject_id'].astype(int)\n",
    "    df_resp_subs['domain'] = 'CDC_datatset'\n",
    "    \n",
    "#     df_RR_est = pd.read_feather(inputdir+'sur_resp/df_RR_est.feather') \n",
    "#     df_resp_PCC = pd.read_feather(inputdir+'sur_resp/df_resp_PCC.feather')\n",
    "\n",
    "#     stage3_dict = data_loader('stage3_dict', inputdir).item()\n",
    "    Fs = FS_RESAMPLE_resp\n",
    "\n",
    "    windowing_params['Fs'] = Fs\n",
    "    \n",
    "    \n",
    "df_RR_est = get_df_RR_est(df_resp_subs).reset_index(drop=True)\n",
    "df_resp_PCC = get_df_resp_PCC(df_resp_subs).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "df_RR_est.to_feather(outputdir+'sur_resp/df_RR_est.feather')\n",
    "df_resp_PCC.to_feather(outputdir+'sur_resp/df_resp_PCC.feather')\n",
    "\n",
    "\n",
    "if show_RR_est:\n",
    "    for task_name in df_RR_est['task'].unique():\n",
    "        plot_RR_est_error(df_RR_est[df_RR_est['task']==task_name],fig_name='RR_est_error_'+task_name, outputdir=outputdir+'sur_resp/', show_plot=False)\n",
    "\n",
    "    for task_name in df_RR_est['task'].unique():\n",
    "        plot_HM(df_RR_est[df_RR_est['task']==task_name], 'surrogate_names', 'subject_id', 'RR_mae', fig_name='RR_mae_'+task_name, outputdir=outputdir+'sur_resp/', show_plot=False)\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'ECG_SR', 'ECG_AMr', 'ECG_AMs', 'ECG_AMpt', 'ECG_FM', 'SCG_AM',\n",
       "       'SCGxyz_AMpt', 'SCG_AMpt', 'SCGx_AMpt', 'SCGy_AMpt', 'accelX_resp',\n",
       "       'accelY_resp', 'accelZ_resp', 'ppg_g_1_cardiac_max',\n",
       "       'ppg_g_1_cardiac_min', 'ppg_g_2_cardiac_max', 'ppg_g_2_cardiac_min',\n",
       "       'ppg_r_1_cardiac_max', 'ppg_r_1_cardiac_min', 'ppg_r_2_cardiac_max',\n",
       "       'ppg_r_2_cardiac_min', 'ppg_ir_1_cardiac_max', 'ppg_ir_1_cardiac_min',\n",
       "       'ppg_ir_2_cardiac_max', 'ppg_ir_2_cardiac_min', 'ppg_g_1_resp',\n",
       "       'ppg_g_2_resp', 'ppg_r_1_resp', 'ppg_r_2_resp', 'ppg_ir_1_resp',\n",
       "       'ppg_ir_2_resp', 'RR_cosmed', 'resp_cosmed', 'subject_id', 'task',\n",
       "       'HR_cosmed', 'VT_cosmed', 'br_sim_sig', 'domain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resp_subs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comptue ST windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate_name = surrogate_names[0]\n",
    "# surrogate_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows_signals(ts_Pxx, t_sig, sig, Fs, windowing_params=None):\n",
    "\n",
    "    start_offset = -int(windowing_params['window_size']/2*Fs)\n",
    "    end_offset = int(windowing_params['window_size']/2*Fs)\n",
    "\n",
    "    # identify the center of the Pxx in terms of indices\n",
    "    # t_sig may not start at 0, so need to substract it from t_sig[0] to get the right indices\n",
    "    i_Pxx = ( (ts_Pxx-t_sig[0]) *Fs).astype(int)\n",
    "\n",
    "    # segment the signal\n",
    "    sig_segments, _ = beat_segmentation(sig, i_Pxx, start_offset=start_offset, end_offset=end_offset)\n",
    "    sig_segments = sig_segments.T # dim = # of segments, # of samples in each segment\n",
    "#     print(sig_segments.shape)\n",
    "\n",
    "    # arrange the signal segments into sequence\n",
    "    N_windows_seq = windowing_params['seq_len']\n",
    "\n",
    "    N_windows = sig_segments.shape[0] - (N_windows_seq - 1)\n",
    "    i_starts = np.arange(N_windows)\n",
    "    ts_sig_segments_seq, sig_segments_seq = Pxx_segmentation(ts_Pxx, sig_segments, i_starts, start_offset=0, end_offset=N_windows_seq)\n",
    "\n",
    "#     ts_sig_segments_seq.shape, sig_segments_seq.shape\n",
    "\n",
    "    return ts_sig_segments_seq, sig_segments_seq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resp_sub['task'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for task in df_resp_sub['task'].unique():\n",
    "#     if 'Recovery' not in task:\n",
    "#         if 'Stair' in task:\n",
    "#             continue\n",
    "#     print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windowing_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on subject 101\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchan/miniconda3/envs/mienv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# length_medfilt = 2001\n",
    "norm_param = {\n",
    "    'mode': 'EMD',\n",
    "}\n",
    "norm_param = {\n",
    "    'mode': 'medfilt',\n",
    "#     'length_medfilt': 2001, \n",
    "    'length_medfilt': math.ceil(Fs * 4 / 2.) * 2 + 1,\n",
    "#     'length_medfilt': 21, \n",
    "}\n",
    "\n",
    "windowing_params['norm_param'] = norm_param\n",
    "\n",
    "# show_surrogate_names = ['ECG_SR', 'ECG_AMr', 'ECG_AMs', 'ECG_AMpt', 'ECG_FM', 'SCG_AM',\n",
    "#                         'SCGxyz_AMpt', 'SCG_AMpt', 'SCGx_AMpt', 'SCGy_AMpt',\n",
    "#                         'ppg_g_1_resp', 'ppg_g_2_resp', 'ppg_r_1_resp', 'ppg_r_2_resp',\n",
    "#                         'ppg_ir_1_resp', 'ppg_ir_2_resp']\n",
    "\n",
    "show_surrogate_names = ['ECG_SR',\n",
    "                        'SCGxyz_AMpt', 'SCG_AMpt', 'SCGx_AMpt', 'SCGy_AMpt',\n",
    "                        'accelX_resp', 'accelY_resp', 'accelZ_resp',\n",
    "                        'ppg_g_1_resp', 'ppg_g_2_resp', 'ppg_ir_1_resp', 'ppg_ir_2_resp']\n",
    "\n",
    "surrogate_names = show_surrogate_names\n",
    "\n",
    "inspect_TF = True\n",
    "\n",
    "\n",
    "label_all = []\n",
    "data_all = []\n",
    "raw_all = []\n",
    "meta_all = []\n",
    "ts_all = []\n",
    "hr_all = []\n",
    "Pxx_names = surrogate_names\n",
    "\n",
    "for subject_id in df_resp_subs['subject_id'].unique():\n",
    "    \n",
    "#     if subject_id != 1:\n",
    "#         continue\n",
    "    \n",
    "    print('working on subject', subject_id)\n",
    "    df_resp_sub = df_resp_subs[df_resp_subs['subject_id']==subject_id]\n",
    "\n",
    "    for task_name in df_resp_sub['task'].unique():\n",
    "        \n",
    "#         if task_name=='Stair':\n",
    "        if 'Recovery' not in task_name:\n",
    "            if 'Stair' in task_name:\n",
    "                continue\n",
    "        \n",
    "        df_resp = df_resp_sub[df_resp_sub['task']==task_name]\n",
    "\n",
    "        t_sig = df_resp['time'].values\n",
    "        \n",
    "#         sys.exit()\n",
    "        \n",
    "        resp_sig =  df_resp['br_sim_sig'].values\n",
    "\n",
    "#         surrogate_names = np.asarray(df_resp.columns)\n",
    "#         surrogate_names = surrogate_names[(surrogate_names!='time') & (surrogate_names!='RR_cosmed') & (surrogate_names!='subject_id') & (surrogate_names!='task')]\n",
    "        column_names = df_resp.columns\n",
    "#         surrogate_names = get_surrogate_names(column_names)\n",
    "        surrogate_names = show_surrogate_names\n",
    "#         sys.exit()\n",
    "        \n",
    "        \n",
    "        N_sur = len(surrogate_names)\n",
    "\n",
    "        Pxx_list = []\n",
    "        raw_list = []\n",
    "\n",
    "        for surrogate_name in surrogate_names:\n",
    "            \n",
    "#             if surrogate_name!='ppg_g_2_resp':\n",
    "#                 continue\n",
    "                \n",
    "\n",
    "\n",
    "#             print(task_name, surrogate_name)\n",
    "            \n",
    "#             if surrogate_name!='SCG_AMpt':\n",
    "#                 continue\n",
    "                \n",
    "            sig = df_resp[surrogate_name].values\n",
    "        \n",
    "        \n",
    "        \n",
    "#             sys.exit()\n",
    "\n",
    "        \n",
    "        #     ts_Pxx_seq, Pxx_seq_surrogate, freq = extract_windows(df_resp['time'].values, df_resp[surrogate_name].values, Fs, norm_param)\n",
    "            ts_Pxx_seq, Pxx_seq_surrogate, freq, ts_Pxx, Pxx = extract_windows(t_sig, sig, Fs, windowing_params)\n",
    "            if inspect_TF:\n",
    "                if surrogate_name in show_surrogate_names:\n",
    "                    inspect_TF_rep(df_resp['time'].values, df_resp[surrogate_name].values, resp_sig, windowing_params, task_name=task_name, subject_id=subject_id, sig_name=surrogate_name, outputdir=outputdir+surrogate_name+'/', show_plot=False)\n",
    "#                 sys.exit()\n",
    "            Pxx_list.append(Pxx_seq_surrogate)\n",
    "\n",
    "\n",
    "            ts_sig_segments_seq, sig_segments_seq = extract_windows_signals(ts_Pxx, t_sig, sig, Fs, windowing_params=windowing_params)\n",
    "            raw_list.append(sig_segments_seq)\n",
    "            \n",
    "\n",
    "        Pxx_matrix = np.stack(Pxx_list, axis=3).transpose(0,3,1,2) # dimension (# of sample >100, # of surrogates = 13, # of time steps = 20, # of spectral features = 46)\n",
    "        raw_matrix = np.stack(raw_list, axis=3).transpose(0,3,1,2) # dimension (# of sample >100, # of surrogates = 13, # of time steps = 20, # of temporal samples = 300)\n",
    "\n",
    "\n",
    "\n",
    "        data_all.append(Pxx_matrix)\n",
    "        raw_all.append(raw_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ts_Pxx_seq, Pxx_seq_resp_sig, freq, _, _ = extract_windows(t_sig, resp_sig, Fs, windowing_params)\n",
    "        label_all.append(Pxx_seq_resp_sig)\n",
    "        \n",
    "        \n",
    "        # add meta\n",
    "\n",
    "        _, HR_seq = extract_windows_signals(ts_Pxx, t_sig, df_resp['HR_cosmed'].values, Fs, windowing_params=windowing_params)\n",
    "        HR_seq = HR_seq[:,windowing_params['seq_len']//2,:].mean(axis=1)\n",
    "        \n",
    "        _, VT_seq = extract_windows_signals(ts_Pxx, t_sig, df_resp['VT_cosmed'].values, Fs, windowing_params=windowing_params)\n",
    "        VT_seq = VT_seq[:,windowing_params['seq_len']//2,:].mean(axis=1)\n",
    "        \n",
    "        _, RR_seq = extract_windows_signals(ts_Pxx, t_sig, df_resp['RR_cosmed'].values, Fs, windowing_params=windowing_params)\n",
    "        RR_seq = RR_seq[:,windowing_params['seq_len']//2,:].mean(axis=1)\n",
    "# HR_seq = HR_seq[:,windowing_params['seq_len']//2,:].mean(axis=1)\n",
    "        \n",
    "        \n",
    "#         HR_seq = get_hr_seq(ts_Pxx_seq, t_sig, df_resp['HR_cosmed'].values).mean(axis=1)\n",
    "#         VT_seq = get_hr_seq(ts_Pxx_seq, t_sig, df_resp['VT_cosmed'].values).mean(axis=1)\n",
    "#         RR_seq = get_hr_seq(ts_Pxx_seq, t_sig, df_resp['RR_cosmed'].values).mean(axis=1)\n",
    "        \n",
    "        BMI = df_subinfo.loc[df_subinfo['Subject_ID']==subject_id, 'BMI'].values[0]\n",
    "        \n",
    "        meta_task = np.asarray([[int(subject_id), tasks_dict[task_name], BMI]]*Pxx_seq_resp_sig.shape[0])\n",
    "        meta_task = np.c_[meta_task, HR_seq, VT_seq, RR_seq]\n",
    "        meta_all.append(meta_task)\n",
    "#         meta_all.append(np.asarray([[int(subject_id), tasks_dict[task_name], ]]*Pxx_seq_resp_sig.shape[0]))\n",
    "        ts_all.append(ts_Pxx_seq)\n",
    "\n",
    "\n",
    "print(Pxx_names)\n",
    "print(freq)\n",
    "\n",
    "\n",
    "label_all = np.concatenate(label_all,axis=0)\n",
    "data_all = np.concatenate(data_all,axis=0)\n",
    "raw_all = np.concatenate(raw_all,axis=0)\n",
    "meta_all = np.concatenate(meta_all,axis=0)\n",
    "ts_all = np.concatenate(ts_all,axis=0)\n",
    "# hr_sub = np.concatenate(hr_sub,axis=0)\n",
    "\n",
    "meta_names = ['subject_id', 'task_name', 'BMI', 'HR_cosmed', 'VT_cosmed', 'RR_cosmed']\n",
    "\n",
    "print(label_all.shape, data_all.shape, raw_all.shape, meta_all.shape, ts_all.shape)\n",
    "    \n",
    "data_all =  float2uint8(data_all)\n",
    "label_all =  float2uint8(label_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resp_sub[df_resp_sub['task']=='Run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_get_sur_norm = False\n",
    "\n",
    "if debug_get_sur_norm:\n",
    "\n",
    "    norm_param = {\n",
    "        'mode': 'medfilt',\n",
    "        'length_medfilt': math.ceil(Fs * 4 / 2.) * 2 + 1,\n",
    "    #     'length_medfilt': 51,\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(20,6), dpi=80)\n",
    "\n",
    "#     ax.plot(t_sig, get_sur_norm(t_sig, sig, norm_param, debug=False))\n",
    "#     ax.plot(t_sig, resp_sig+2)\n",
    "#     plt.show()\n",
    "    \n",
    "    length_medfilt = norm_param['length_medfilt']\n",
    "    sig_med = medfilt(sig, length_medfilt)\n",
    "\n",
    "    sig_filt = sig - sig_med\n",
    "    sig_norm = sig_filt/get_envelope(sig_filt)\n",
    "\n",
    "\n",
    "\n",
    "    # hard coded, but it's generally ok\n",
    "    threshold = 1.5\n",
    "    indices = np.where((np.abs(sig_norm)>threshold))[0]\n",
    "    sig_norm[indices] = np.sign(sig_norm[indices])*threshold\n",
    "\n",
    "#     fig, ax = plt.subplots(1,1,figsize=(20,3), dpi=80)\n",
    "\n",
    "    ax.plot(sig)\n",
    "    ax.plot(sig_med+5)\n",
    "    ax.plot(sig_filt+10)\n",
    "    ax.plot(get_envelope(sig_filt)+15)\n",
    "    ax.plot(sig_norm+20)\n",
    "    \n",
    "    \n",
    "    ax.plot(resp_sig-5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store stage dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3_dict = {\n",
    "    'surrogate_names': surrogate_names,\n",
    "    'meta_names': meta_names,\n",
    "#     'list_output': list_output,\n",
    "#     'list_meta': list_meta,\n",
    "#     'list_signal': list_signal,\n",
    "    'Fs': Fs,\n",
    "    'subject_ids': np.unique(meta_all[:,0]),\n",
    "    'task_ids': np.unique(meta_all[:,1]),\n",
    "    'windowing_params': windowing_params,\n",
    "    'freq': freq\n",
    "}\n",
    "\n",
    "data_saver(stage3_dict, 'stage3_dict', outputdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.shape, label_all.shape, meta_all.shape, raw_all.shape, ts_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver(data_all, 'data', outputdir)\n",
    "# data_saver(feature_all, 'feature', outputdir)\n",
    "data_saver(label_all, 'label', outputdir)\n",
    "data_saver(meta_all, 'meta', outputdir)\n",
    "\n",
    "data_saver(raw_all, 'raw', outputdir)\n",
    "data_saver(ts_all, 'ts', outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(meta_all[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowing_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_all.append([int(subject_id), tasks_dict[task_name]])\n",
    "meta_all.append([int(subject_id), tasks_dict[task_name]])\n",
    "meta_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get resp. signal segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(raw_list, axis=3).transpose(0,3,1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(Pxx_list, axis=3).transpose(0,3,1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sig_segments_seq.shape, sig_segments_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, Pxx = get_PSD_beats(sig_segments[0,:], Fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freq, Pxx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aaa[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Pxx_seq_surrogate, freq\n",
    "Pxx_seq_surrogate.shape\n",
    "freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(freq, Pxx_seq_surrogate[0,0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_segmentation(sig, i_peaks, start_offset=-50, end_offset=250):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_all[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(raw_all,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_matrix.shape, df_resp['resp_cosmed'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_list[0].shape\n",
    "\n",
    "data_all.shape, raw_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data_all)\n",
    "# data_all[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pxx_seq_surrogate.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pxx_seq_surrogate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4/14/2022 next, add the above block to the block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sub = []\n",
    "data_sub = []\n",
    "meta_sub = []\n",
    "ts_sub = []\n",
    "hr_sub = []\n",
    "\n",
    "\n",
    "\n",
    "for subject_id in df_subjects_complete.keys():   \n",
    "#     if subject_id!='CW010':\n",
    "#         continue\n",
    "    print('working on subject', subject_id)\n",
    "        \n",
    "    df = df_subjects_complete[subject_id]\n",
    "    \n",
    "    \n",
    "    TASKS = np.unique(df_subjects_complete[subject_id]['task_id'])\n",
    "    for task_id in TASKS:\n",
    "        # 1. get df of a task\n",
    "        df_task = df[df['task_id']==task_id] \n",
    "        \n",
    "        if task_id == task_id_target: # focus on task 6 only\n",
    "#         if task_id == 6: # focus on task 6 only\n",
    "\n",
    "            br_sim_sig = df_task['br_sim_sig'].values\n",
    "            br = df_task['br'].values\n",
    "            t_sig = df_task['time'].values\n",
    "            hr = df_task['heart_rate_cosmed'].values\n",
    "\n",
    "            Pxx_list = []\n",
    "            Pxx_names = []\n",
    "            \n",
    "            # method 1: convert to STFT\n",
    "            for surrogate_name in modalities:\n",
    "\n",
    "                surrogate_sig = df_task[surrogate_name].values\n",
    "                \n",
    "                ts_Pxx_seq, Pxx_seq_surrogate, freq = extract_windows(t_sig, surrogate_sig, Fs, norm_param)\n",
    "                Pxx_list.append(Pxx_seq_surrogate)\n",
    "                Pxx_names.append(surrogate_name)\n",
    "                if debug_TF:\n",
    "                    inspect_TF_rep(t_sig, surrogate_sig, br_sim_sig, norm_param, subject_id=subject_id, sig_name=surrogate_name, outputdir=outputdir)\n",
    "\n",
    "#                 sys.exit()\n",
    "\n",
    "\n",
    "            if windowing_params.get('remove_outliers'): \n",
    "                \n",
    "                sqi_seq, threshold_SQI = extract_windows_sqi(t_sig, ts_Pxx_seq, ECG_SQI)\n",
    "                \n",
    "                # find data with high sqi\n",
    "#                 indices_kept = np.where( (sqi_seq.min(axis=1)>threshold_SQI) & (sqi_seq.min(axis=1)>0.7) )[0]\n",
    "                indices_kept = np.where( sqi_seq.min(axis=1)>0.65 )[0]\n",
    "                print('\\t{:.2f}% outliers removed, threshold={:.2f}'.format((1-indices_kept.shape[0]/sqi_seq.shape[0])*100, threshold_SQI))\n",
    "\n",
    "#                 sys.exit()\n",
    "            else:\n",
    "                indices_kept = np.arange(ts_Pxx_seq.shape[0])\n",
    "                \n",
    "\n",
    "                \n",
    "            # size of Pxx_matrix = (N_seq, N_modality, N_window, N_freq)\n",
    "            Pxx_matrix = np.stack(Pxx_list, axis=3).transpose(0,3,1,2)\n",
    "\n",
    "            ts_Pxx_seq, Pxx_seq_br_sim_sig, freq = extract_windows(t_sig, br_sim_sig, Fs)\n",
    "            hr_seq = get_hr_seq(ts_Pxx_seq, t_sig, hr)\n",
    "\n",
    "            # method 2: use ECG_AM and do min-max normalization on each column\n",
    "\n",
    "            label_sub.append(Pxx_seq_br_sim_sig[indices_kept,:,:])\n",
    "            data_sub.append(Pxx_matrix[indices_kept,:,:])\n",
    "            hr_sub.append(hr_seq[indices_kept,:])\n",
    "\n",
    "            meta_sub.append(np.ones(indices_kept.shape[0])*int(subject_id[-3:]))\n",
    "            ts_sub.append(ts_Pxx_seq[indices_kept,:])\n",
    "\n",
    "print(Pxx_names)\n",
    "print(freq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_saver(Pxx_names, 'Pxx_names', outputdir)\n",
    "data_saver(freq, 'freq', outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# br_sim_sig\n",
    "# t_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_interp = np.arange(t_sig[0]*Fs_new, t_sig[-1]*Fs_new+1)/Fs_new\n",
    "# t_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows_single(t_sig_cosmed, t_sig, surrogate_sig, start_offset, end_offset, NFFT, noverlap):\n",
    "    Pxx_seq = []\n",
    "    ts_Pxx_seq = []\n",
    "    for t in t_sig_cosmed:\n",
    "        t_start = t + start_offset\n",
    "        t_end = t + end_offset\n",
    "\n",
    "        t_mask = (t_sig > t_start) & (t_sig <= t_end)\n",
    "\n",
    "#         print('\\t', t_start, t_end, surrogate_sig.shape, t_sig.shape, t_sig[0], t_sig[-1])\n",
    "        \n",
    "        \n",
    "        sig = surrogate_sig[t_mask].copy()\n",
    "        ts = t_sig[t_mask].copy()\n",
    "\n",
    "        ts_Pxx, Pxx, freq = get_PSD_windows_scipy(ts, sig, Fs, NFFT, noverlap)\n",
    "#         print('\\t\\t', surrogate_sig.shape, t_sig.shape, sig.shape)\n",
    "\n",
    "        Pxx_seq.append(Pxx)\n",
    "        ts_Pxx_seq.append(ts_Pxx)\n",
    "#         print('\\t\\t\\t', surrogate_sig.shape, t_sig.shape)\n",
    "\n",
    "\n",
    "    # Pxx_seq.shape = (276, seq_len, N_feature)\n",
    "    Pxx_seq = np.stack(Pxx_seq)\n",
    "    # ts_Pxx_seq.shape = (276, N_feature, seq_len)\n",
    "    ts_Pxx_seq = np.stack(ts_Pxx_seq)\n",
    "\n",
    "    return ts_Pxx_seq, Pxx_seq, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_vectors(t_sig, surrogate_sig, Fs, sig_padded=60):\n",
    "    \"\"\"Summary or get_padded_vectors\n",
    "\n",
    "    Parameters:\n",
    "    t_sig (np arr): time vector of the signal\n",
    "    surrogate_sig (np arr): value vector of the signal\n",
    "    Fs (np arr): sampling rate\n",
    "    sig_padded (int): duration (in s) of the signal padded at the begining and the end of the signal\n",
    "\n",
    "    Returns:\n",
    "    t_sig_padded: time vector of the padded signal\n",
    "    surrogate_sig_padded: value vector of the padded signal\n",
    "\n",
    "    \"\"\"\n",
    "#         sig_padded = 60\n",
    "    offset = int(sig_padded*Fs) # reversely pad 10 sec to beginning and end of the signal\n",
    "    # t_sig_padded = np.r_[t_sig[0:offset][::-1], t_sig, t_sig[-offset:][::-1]]\n",
    "\n",
    "    t_end_padded = np.arange(offset)/Fs + 1/Fs\n",
    "    t_end_padded = t_end_padded + t_sig[-1]\n",
    "\n",
    "    t_start_padded = np.arange(offset)/Fs-sig_padded\n",
    "    t_start_padded = t_start_padded + t_sig[0]\n",
    "\n",
    "    t_sig_padded = np.r_[t_start_padded, t_sig, t_end_padded]\n",
    "\n",
    "    surrogate_sig_padded = np.r_[surrogate_sig[0:offset][::-1], surrogate_sig, surrogate_sig[-offset:][::-1]]\n",
    "\n",
    "    return t_sig_padded, surrogate_sig_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contruct test dataset\n",
    "## TODO: write comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sub_cosmed = []\n",
    "data_sub_cosmed = []\n",
    "meta_sub_cosmed = []\n",
    "ts_sub_cosmed = []\n",
    "hr_sub_cosmed = []\n",
    "est_temporal_sub_cosmed = []\n",
    "label_temporal_sub_cosmed = []\n",
    "\n",
    "# length_medfilt = 2001\n",
    "norm_param = {\n",
    "    'mode': 'EMD',\n",
    "}\n",
    "norm_param = {\n",
    "    'mode': 'medfilt',\n",
    "    'length_medfilt': 2001,\n",
    "}\n",
    "\n",
    "window_size = windowing_params['window_size']\n",
    "\n",
    "# this is pre-defined\n",
    "start_offset = -window_size/2 - 3*10\n",
    "end_offset = window_size/2 + 3*9\n",
    "\n",
    "PADDING = True\n",
    "\n",
    "NFFT = int(Fs*windowing_params['window_size'])  # 60 sec per window\n",
    "noverlap = int(NFFT*windowing_params['overlap']) # int(60*0.95*Fs) = 57 sec * Fs\n",
    "\n",
    "for subject_id in df_subjects_complete.keys():   \n",
    "#     if subject_id!='CW001':\n",
    "#         continue\n",
    "    print('working on subject', subject_id)\n",
    "        \n",
    "    df = df_subjects_complete[subject_id]\n",
    "    \n",
    "    \n",
    "    TASKS = np.unique(df_subjects_complete[subject_id]['task_id'])\n",
    "    for task_id in TASKS:\n",
    "        # 1. get df of a task\n",
    "        df_task = df[df['task_id']==task_id] \n",
    "#         if task_id == 6: # focus on task 6 only\n",
    "        if task_id == task_id_target: # focus on task 6 only\n",
    "\n",
    "            br_sim_sig = df_task['br_sim_sig'].values\n",
    "            br = df_task['br'].values\n",
    "            hr = df_task['heart_rate_cosmed'].values\n",
    "\n",
    "            Pxx_list = []\n",
    "            Pxx_names = []\n",
    "\n",
    "            # method 1: convert to STFT\n",
    "            for surrogate_name in modalities:\n",
    "                \n",
    "                \n",
    "                t_sig = df_task['time'].values\n",
    "\n",
    "                \n",
    "#                 print(surrogate_name)\n",
    "                mask = (df_predictions['task_id']==task_id) & (df_predictions['subject_id']==subject_id) & (df_predictions['surrogate_name']==surrogate_name)\n",
    "\n",
    "                df_predictions_sub = df_predictions[mask]\n",
    "                indices_RR = df_predictions_sub['indices_RR'].values\n",
    "                RR_est_coarse = df_predictions_sub['RR_est_coarse'].values\n",
    "                RR_label_coarse = df_predictions_sub['RR_label_coarse'].values\n",
    "\n",
    "                ts_cosmed = t_sig[indices_RR]\n",
    "                \n",
    "                surrogate_sig = df_task[surrogate_name].values\n",
    "\n",
    "                if PADDING:\n",
    "                    # print('padding 60s before and after')\n",
    "                    t_sig_padded, surrogate_sig_padded = get_padded_vectors(t_sig, surrogate_sig, Fs, sig_padded=60)\n",
    "                else:\n",
    "                    print('not padding, need to modify the code')\n",
    "                    break\n",
    "\n",
    "#                 mask_valid_cosmed = (ts_cosmed + start_offset > t_sig[0]) & (ts_cosmed + end_offset < t_sig[-1])\n",
    "                mask_valid_cosmed = (ts_cosmed + start_offset > t_sig_padded[0]) & (ts_cosmed + end_offset < t_sig_padded[-1])\n",
    "                t_sig_cosmed = ts_cosmed[mask_valid_cosmed]\n",
    "                \n",
    "#                 print(t_sig.shape, surrogate_sig.shape)\n",
    "\n",
    "                if norm_param is not None:\n",
    "#                     surrogate_sig = get_sur_norm(t_sig, surrogate_sig, norm_param, debug=False)\n",
    "                    surrogate_sig_padded = get_sur_norm(t_sig_padded, surrogate_sig_padded, norm_param, debug=False)\n",
    "\n",
    "#                 print(t_sig.shape, surrogate_sig.shape)\n",
    "\n",
    "#                 ts_Pxx_seq, Pxx_seq_surrogate, freq = extract_windows_single(t_sig_cosmed, t_sig, surrogate_sig, start_offset, end_offset, NFFT, noverlap)\n",
    "                ts_Pxx_seq, Pxx_seq_surrogate, freq = extract_windows_single(t_sig_cosmed, t_sig_padded, surrogate_sig_padded, start_offset, end_offset, NFFT, noverlap)\n",
    "\n",
    "                \n",
    "#                 sys.exit()\n",
    "                \n",
    "                Pxx_list.append(Pxx_seq_surrogate)\n",
    "\n",
    "            # size of Pxx_matrix = (N_seq, N_modality, N_window, N_freq)\n",
    "            Pxx_matrix = np.stack(Pxx_list, axis=3).transpose(0,3,1,2)\n",
    "            \n",
    "#             print('br sig')\n",
    "            \n",
    "            \n",
    "            if PADDING:\n",
    "                # print('padding 60s before and after')\n",
    "                t_sig_padded, br_sim_sig_padded = get_padded_vectors(t_sig, br_sim_sig, Fs, sig_padded=60)\n",
    "                t_sig_padded, hr_padded = get_padded_vectors(t_sig, hr, Fs, sig_padded=60)\n",
    "\n",
    "            ts_Pxx_seq, Pxx_seq_br_sim_sig, freq = extract_windows_single(t_sig_cosmed, t_sig_padded, br_sim_sig_padded, start_offset, end_offset, NFFT, noverlap)\n",
    "            hr_seq = get_hr_seq(ts_Pxx_seq, t_sig_padded, hr_padded)\n",
    "#             ts_Pxx_seq, Pxx_seq_br_sim_sig, freq = extract_windows_single(t_sig_cosmed, t_sig, br_sim_sig, start_offset, end_offset, NFFT, noverlap)\n",
    "#             hr_seq = get_hr_seq(ts_Pxx_seq, t_sig, hr)\n",
    "\n",
    "            # method 2: use ECG_AM and do min-max normalization on each column\n",
    "#             ts_Pxx_seq, Pxx_seq_ECG_AM, freq = extract_windows(ECG_AM, Fs)\n",
    "\n",
    "            label_sub_cosmed.append(Pxx_seq_br_sim_sig)\n",
    "            data_sub_cosmed.append(Pxx_matrix)\n",
    "\n",
    "            est_temporal_sub_cosmed.append(RR_est_coarse[mask_valid_cosmed])\n",
    "            label_temporal_sub_cosmed.append(RR_label_coarse[mask_valid_cosmed])\n",
    "            meta_sub_cosmed.append(np.ones(ts_Pxx_seq.shape[0])*int(subject_id[-3:]))\n",
    "            ts_sub_cosmed.append(ts_Pxx_seq)\n",
    "            hr_sub_cosmed.append(hr_seq)\n",
    "\n",
    "            \n",
    "#             print(ts_sub_cosmed[-1].shape, meta_sub_cosmed[-1].shape, est_temporal_sub_cosmed[-1].shape, data_sub_cosmed[-1].shape, label_sub_cosmed[-1].shape, label_temporal_sub_cosmed[-1].shape)\n",
    "#             sys.exit()\n",
    "            \n",
    "# print(Pxx_names)\n",
    "# print(freq)\n",
    "\n",
    "# data_saver(Pxx_names, 'Pxx_names', outputdir)\n",
    "# data_saver(freq, 'freq', outputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (M,N) = ts_Pxx_seq.shape\n",
    "\n",
    "# hr_seq = np.zeros((M,N))\n",
    "\n",
    "# for i in range(M):\n",
    "#     for j in range(N):\n",
    "#         index = np.where(np.around(t_sig_padded, decimals=3)==np.around(ts_Pxx_seq[i,j], decimals=3))[0]\n",
    "#         print(index, ts_Pxx_seq[i,j], t_sig_padded)\n",
    "#         hr_seq[i,j] = hr[index]\n",
    "# # return hr_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(t_sig_padded==ts_Pxx_seq[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_Pxx_seq.shape, t_sig_padded.shape, hr_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_sig_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_sig_cosmed, t_sig, surrogate_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_sig.shape, surrogate_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_sig_cosmed.shape, t_sig.shape, surrogate_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cosmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_valid_cosmed = (ts_cosmed + start_offset > t_sig[0]) & (ts_cosmed + end_offset < t_sig[-1])\n",
    "# mask_valid_cosmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cosmed + start_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cosmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_sig_cosmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: remove this fat ass cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Pxx_testing = False\n",
    "if plot_Pxx_testing == True:\n",
    "    inspect_TF_rep(t_sig, ECG_AM, br_sim_sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Pxx_testing = False\n",
    "if plot_Pxx_testing == True:\n",
    "    inspect_TF_rep(t_sig, SCG_AMpt, br_sim_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Pxx_testing = False\n",
    "if plot_Pxx_testing == True:\n",
    "    inspect_TF_rep(t_sig, SCG_AM_norm, br_sim_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG_AMpt_norm = get_sur_norm(ECG_AMpt, length_medfilt=2001)\n",
    "# SCG_AM_norm = get_sur_norm2(t_sig, SCG_AM, norm_param, debug=False)\n",
    "\n",
    "plot_Pxx_testing = False\n",
    "if plot_Pxx_testing == True:\n",
    "    inspect_TF_rep(t_sig, SCG_AM_norm, br_sim_sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sub = np.concatenate(label_sub,axis=0)\n",
    "data_sub = np.concatenate(data_sub,axis=0)\n",
    "meta_sub = np.concatenate(meta_sub,axis=0)\n",
    "ts_sub = np.concatenate(ts_sub,axis=0)\n",
    "hr_sub = np.concatenate(hr_sub,axis=0)\n",
    "\n",
    "data_sub =  float2uint8(data_sub)\n",
    "label_sub =  float2uint8(label_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sub.shape, data_sub.shape, meta_sub.shape, ts_sub.shape, hr_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sub_cosmed = np.concatenate(label_sub_cosmed,axis=0)\n",
    "data_sub_cosmed = np.concatenate(data_sub_cosmed,axis=0)\n",
    "meta_sub_cosmed = np.concatenate(meta_sub_cosmed,axis=0)\n",
    "ts_sub_cosmed = np.concatenate(ts_sub_cosmed,axis=0)\n",
    "hr_sub_cosmed = np.concatenate(hr_sub_cosmed,axis=0)\n",
    "\n",
    "est_temporal_sub_cosmed = np.concatenate(est_temporal_sub_cosmed,axis=0)\n",
    "label_temporal_sub_cosmed = np.concatenate(label_temporal_sub_cosmed,axis=0)\n",
    "\n",
    "data_sub_cosmed =  float2uint8(data_sub_cosmed)\n",
    "label_sub_cosmed =  float2uint8(label_sub_cosmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_sub_cosmed.shape, ts_sub_cosmed.shape, meta_sub_cosmed.shape, est_temporal_sub_cosmed.shape, data_sub_cosmed.shape, label_sub_cosmed.shape, label_temporal_sub_cosmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_sub_cosmed[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: split data, implement U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_set(ids_arr, data_arr):\n",
    "    indices_set = []\n",
    "    for id_sub in ids_arr:\n",
    "        indices_set.append(np.where(data_arr==id_sub)[0])\n",
    "    return np.concatenate(indices_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_matrix(data, label, meta, ts, hr, indices_set, est_temporal=None, label_temporal=None, set_name='null'):\n",
    "\n",
    "    data = data[indices_set,:,:,:]\n",
    "    label = label[indices_set,:,:]\n",
    "    meta = meta[indices_set]\n",
    "    ts = ts[indices_set, :]\n",
    "    hr = hr[indices_set, :]\n",
    "    \n",
    "    if (est_temporal is not None) & (label_temporal is not None):\n",
    "        est_temporal = est_temporal[indices_set]\n",
    "        label_temporal = label_temporal[indices_set]\n",
    "        return data, label, meta, ts, hr, est_temporal, label_temporal\n",
    "    else:\n",
    "        return data, label, meta, ts, hr\n",
    "\n",
    "def save_matrix(data, label, meta, ts, hr, outputdir, est_temporal=None, label_temporal=None, set_name='null'):\n",
    "    outputdir_set = outputdir+set_name+'/'\n",
    "\n",
    "    if not os.path.exists(outputdir_set):\n",
    "        os.makedirs(outputdir_set)\n",
    "\n",
    "    data_saver(data, 'data', outputdir_set)\n",
    "    data_saver(label, 'label', outputdir_set)\n",
    "    data_saver(meta, 'meta', outputdir_set)\n",
    "    data_saver(ts, 'ts', outputdir_set)\n",
    "    data_saver(hr, 'hr', outputdir_set)\n",
    "    \n",
    "    if (est_temporal is not None) & (label_temporal is not None):\n",
    "        data_saver(est_temporal, 'est_temporal', outputdir_set)\n",
    "        data_saver(label_temporal, 'label_temporal', outputdir_set)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSO CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_all = np.unique(meta_sub)\n",
    "# kfold = ids_all.shape[0]\n",
    "# kf = KFold(n_splits=kfold, shuffle=True, random_state=i_seed)\n",
    "# kf.get_n_splits(ids_all)\n",
    "# print(kf)  \n",
    "\n",
    "# for i_CV, (train_idx, val_idx) in enumerate(kf.split(ids_all)):\n",
    "    \n",
    "#     outputdir_CV = outputdir+'CV{}/'.format(i_CV)\n",
    "#     print('index CV', i_CV)\n",
    "#     print('\\tSub IDs | TRAIN:', np.sort(ids_all[train_idx]), 'VAL:', np.sort(ids_all[val_idx]))\n",
    "\n",
    "    \n",
    "    \n",
    "#     ids_train = ids_all[train_idx]\n",
    "#     ids_val = ids_all[val_idx]\n",
    "    \n",
    "    \n",
    "#     # interpolated datapoints\n",
    "#     indices_TRAIN = get_indices_set(ids_train, meta_sub)\n",
    "#     indices_TEST = get_indices_set(ids_val, meta_sub)\n",
    "    \n",
    "#     data_TRAIN, label_TRAIN, meta_TRAIN, ts_TRAIN, hr_TRAIN = split_matrix(data_sub, label_sub, meta_sub, ts_sub, hr_sub, indices_TRAIN, set_name='TRAIN')\n",
    "#     save_matrix(data_TRAIN, label_TRAIN, meta_TRAIN, ts_TRAIN, hr_TRAIN, outputdir_CV, set_name='TRAIN')\n",
    "    \n",
    "#     data_TEST, label_TEST, meta_TEST, ts_TEST, hr_TEST = split_matrix(data_sub, label_sub, meta_sub, ts_sub, hr_sub, indices_TEST, set_name='TEST')\n",
    "#     save_matrix(data_TEST, label_TEST, meta_TEST, ts_TEST, hr_TEST, outputdir_CV, set_name='TEST')\n",
    "\n",
    "    \n",
    "\n",
    "#     indices_TRAINc = get_indices_set(ids_train, meta_sub_cosmed)\n",
    "#     indices_TESTc = get_indices_set(ids_val, meta_sub_cosmed)\n",
    "\n",
    "#     data_TRAINc, label_TRAINc, meta_TRAINc, ts_TRAINc, hr_TRAINc, est_temporal_TRAINc, label_temporal_TRAINc = split_matrix(data_sub_cosmed, label_sub_cosmed, meta_sub_cosmed, ts_sub_cosmed, hr_sub_cosmed, indices_TRAINc, est_temporal_sub_cosmed, label_temporal_sub_cosmed, set_name='TRAIN_cosmed')\n",
    "#     save_matrix(data_TRAINc, label_TRAINc, meta_TRAINc, ts_TRAINc, hr_TRAINc, outputdir_CV, est_temporal_TRAINc, label_temporal_TRAINc, set_name='TRAIN_cosmed')\n",
    "\n",
    "#     data_TESTc, label_TESTc, meta_TESTc, ts_TESTc, hr_TESTc, est_temporal_TESTc, label_temporal_TESTc = split_matrix(data_sub_cosmed, label_sub_cosmed, meta_sub_cosmed, ts_sub_cosmed, hr_sub_cosmed, indices_TESTc, est_temporal_sub_cosmed, label_temporal_sub_cosmed, set_name='TEST_cosmed')\n",
    "#     save_matrix(data_TESTc, label_TESTc, meta_TESTc, ts_TESTc, hr_TESTc, outputdir_CV, est_temporal_TESTc, label_temporal_TESTc, set_name='TEST_cosmed')\n",
    "\n",
    "    \n",
    "#     data_saver(Pxx_names, 'Pxx_names', outputdir_CV)\n",
    "#     data_saver(freq, 'freq', outputdir_CV)\n",
    "# #     save_matrix(data_train, label_train, meta_train, ts_train, hr_train, outputdir+'CV{}/'.format(i_rep,i_CV), set_name='train')\n",
    "# #     save_matrix(data_val, label_val, meta_val, ts_val, hr_val, outputdir+'CV{}/'.format(i_rep,i_CV), set_name='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_all = np.unique(meta_sub)\n",
    "N_sub = ids_all.shape[0]\n",
    "# np.shuffle(i_sub_unique_all)\n",
    "\n",
    "np.random.seed(i_seed)\n",
    "np.random.shuffle(ids_all)\n",
    "# i_sub_unique_all\n",
    "\n",
    "ids_TRAIN = ids_all[:int(N_sub*.7)]\n",
    "# ids_val = ids_train[int(ids_train.shape[0]*.7):]\n",
    "# ids_train = ids_train[:int(ids_train.shape[0]*.7)]\n",
    "\n",
    "\n",
    "ids_TEST = ids_all[int(N_sub*.7):]\n",
    "\n",
    "# ids_TRAIN, ids_TEST\n",
    "\n",
    "# interpolated datapoints\n",
    "indices_TRAIN = get_indices_set(ids_TRAIN, meta_sub)\n",
    "indices_TEST = get_indices_set(ids_TEST, meta_sub)\n",
    "data_TRAIN, label_TRAIN, meta_TRAIN, ts_TRAIN, hr_TRAIN = split_matrix(data_sub, label_sub, meta_sub, ts_sub, hr_sub, indices_TRAIN, set_name='TRAIN')\n",
    "save_matrix(data_TRAIN, label_TRAIN, meta_TRAIN, ts_TRAIN, hr_TRAIN, outputdir, set_name='TRAIN')\n",
    "\n",
    "data_TEST, label_TEST, meta_TEST, ts_TEST, hr_TEST = split_matrix(data_sub, label_sub, meta_sub, ts_sub, hr_sub, indices_TEST, set_name='TEST')\n",
    "save_matrix(data_TEST, label_TEST, meta_TEST, ts_TEST, hr_TEST, outputdir, set_name='TEST')\n",
    "\n",
    "\n",
    "\n",
    "# COSMED datapoints\n",
    "# indices_TEST = get_indices_set(ids_TEST, meta_sub)\n",
    "indices_TRAINc= get_indices_set(ids_TRAIN, meta_sub_cosmed)\n",
    "indices_TESTc = get_indices_set(ids_TEST, meta_sub_cosmed)\n",
    "\n",
    "data_TRAINc, label_TRAINc, meta_TRAINc, ts_TRAINc, hr_TRAINc, est_temporal_TRAINc, label_temporal_TRAINc = split_matrix(data_sub_cosmed, label_sub_cosmed, meta_sub_cosmed, ts_sub_cosmed, hr_sub_cosmed, indices_TRAINc, est_temporal_sub_cosmed, label_temporal_sub_cosmed, set_name='TRAIN_cosmed')\n",
    "save_matrix(data_TRAINc, label_TRAINc, meta_TRAINc, ts_TRAINc, hr_TRAINc, outputdir, est_temporal_TRAINc, label_temporal_TRAINc, set_name='TRAIN_cosmed')\n",
    "\n",
    "data_TESTc, label_TESTc, meta_TESTc, ts_TESTc, hr_TESTc, est_temporal_TESTc, label_temporal_TESTc = split_matrix(data_sub_cosmed, label_sub_cosmed, meta_sub_cosmed, ts_sub_cosmed, hr_sub_cosmed, indices_TESTc, est_temporal_sub_cosmed, label_temporal_sub_cosmed, set_name='TEST_cosmed')\n",
    "save_matrix(data_TESTc, label_TESTc, meta_TESTc, ts_TESTc, hr_TESTc, outputdir, est_temporal_TESTc, label_temporal_TESTc, set_name='TEST_cosmed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_TRAIN.shape, data_TEST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "CV_n = 5\n",
    "rep_n = 5\n",
    "\n",
    "kfold = CV_n\n",
    "\n",
    "print('all ids_TRAIN', ids_TRAIN)\n",
    "print('all ids_TEST', ids_TEST)\n",
    "print('will save to', outputdir)\n",
    "for i_rep in range(rep_n):\n",
    "\n",
    "    print('\\n\\n')\n",
    "    kf = KFold(n_splits=kfold, shuffle=True, random_state=i_seed+i_rep)\n",
    "    kf.get_n_splits(ids_TRAIN)\n",
    "    print(kf)  \n",
    "\n",
    "    for i_CV, (train_idx, val_idx) in enumerate(kf.split(ids_TRAIN)):\n",
    "        print('----------------Splitting for rep {}, CV {}----------------'.format(i_rep, i_CV))\n",
    "        print(\"Sub ID | TRAIN:\", np.sort(ids_TRAIN[train_idx]), \"VAL:\", np.sort(ids_TRAIN[val_idx]))\n",
    "        print('index CV', CV_n*i_rep+i_CV)\n",
    "\n",
    "        ids_train = ids_TRAIN[train_idx]\n",
    "        ids_val = ids_TRAIN[val_idx]\n",
    "        \n",
    "        indices_train = get_indices_set(ids_train, meta_sub)\n",
    "        indices_val = get_indices_set(ids_val, meta_sub)\n",
    "    \n",
    "        data_train, label_train, meta_train, ts_train, hr_train = split_matrix(data_sub, label_sub, meta_sub, ts_sub, hr_sub, indices_train, set_name='train')\n",
    "        data_val, label_val, meta_val, ts_val, hr_val = split_matrix(data_sub, label_sub, meta_sub, ts_sub, hr_sub, indices_val, set_name='val')\n",
    "\n",
    "        save_matrix(data_train, label_train, meta_train, ts_train, hr_train, outputdir+'rep{}/CV{}/'.format(i_rep,i_CV), set_name='train')\n",
    "        save_matrix(data_val, label_val, meta_val, ts_val, hr_val, outputdir+'rep{}/CV{}/'.format(i_rep,i_CV), set_name='val')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================== TEST ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR and RR trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBD (already in stage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# RR = np.linspace(label_range_dict['br'][0], label_range_dict['br'][1], 100)\n",
    "# HR = np.linspace(label_range_dict['heart_rate_cosmed'][0], label_range_dict['heart_rate_cosmed'][1], 100)\n",
    "\n",
    "# fig, (ax1) = plt.subplots(1, 1, figsize=(5,5), dpi=120)\n",
    "# fontsize=15\n",
    "\n",
    "# ax1.fill_between(HR, 0, RR, alpha=0.5, label='feasible region')\n",
    "# ax1.fill_between(HR, RR[-1], RR, color='gray', alpha=0.1, label='infeasible region')\n",
    "# ax1.set_title('feasible \"Nyquist region\" to derive RR using EDR', fontsize=fontsize)\n",
    "\n",
    "# ax1.set_ylabel(r'$F_{signal}$ RR (bpm)', fontsize=fontsize)\n",
    "# ax1.set_xlabel(r'$F_{sampling}$ HR (bpm)', fontsize=fontsize)\n",
    "# ax1.set_xlim(HR[0], HR[-1])\n",
    "# ax1.set_ylim(RR[0], RR[-1])\n",
    "# ax1.legend(frameon=True, loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CWT research (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pywt\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# x = np.arange(512)\n",
    "# y = np.sin(2*np.pi*x/32)\n",
    "# coef, freqs=pywt.cwt(y,np.arange(1,129),'gaus1')\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,5))\n",
    "# ax1.plot(x,y)\n",
    "# ax1.set_xlim(x[0], x[-1])\n",
    "\n",
    "\n",
    "# ax2.imshow(coef, extent=[x[0], x[-1], 1, 129]) # doctest: +SKIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pywt\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# t = np.linspace(-1, 1, 200, endpoint=False)\n",
    "# sig  = np.cos(2 * np.pi * 7 * t) + np.real(np.exp(-7*(t-0.4)**2)*np.exp(1j*2*np.pi*2*(t-0.4)))\n",
    "# widths = np.arange(1, 31)\n",
    "# cwtmatr, freqs = pywt.cwt(sig, widths, 'mexh')\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,5))\n",
    "# ax1.plot(t,sig)\n",
    "# ax1.set_xlim(t[0], t[-1])\n",
    "# ax2.imshow(cwtmatr, extent=[-1, 1, 1, 31], cmap='PRGn', aspect='auto',\n",
    "#             vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())  # doctest: +SKIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [-offset:]\n",
    "# offset = 100000\n",
    "# wavelet_name = 'gaus8'\n",
    "# wavlist = pywt.wavelist(kind='continuous')\n",
    "# wavlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pywt\n",
    "# from pywt import scale2frequency\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# t = df_task['time'].values[-offset:]\n",
    "# # sig  = ECG_AM_norm[-offset:]\n",
    "# sig  = ECG_AM[-offset:]\n",
    "# # sig = br_sim_sig\n",
    "# widths = np.arange(1, 31)\n",
    "# cwtmatr, freqs = pywt.cwt(sig, widths, wavelet_name)\n",
    "# f = scale2frequency(wavelet_name, widths)\n",
    "\n",
    "# fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(20,5))\n",
    "# ax1.plot(t,sig)\n",
    "# ax1.set_xlim(t[0], t[-1])\n",
    "# # ax2.imshow(cwtmatr, extent=[-1, 1, 1, 31], cmap='PRGn', aspect='auto',\n",
    "# #             vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())  # doctest: +SKIP\n",
    "\n",
    "# # ax2.imshow(cwtmatr, extent=[-1, 1, f[0], f[-1]], cmap='viridis', aspect='auto',\n",
    "# #             vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())  # doctest: +SKIP\n",
    "# ax2.imshow(cwtmatr, extent=[-1, 1, f[0], f[-1]], cmap='viridis', aspect='auto')\n",
    "# ax3.plot(t[50:-50], cwtmatr[5,50:-50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pywt\n",
    "# from pywt import scale2frequency\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# t = df_task['time'].values[-offset:]\n",
    "# # sig  = ECG_AM_norm\n",
    "# sig = br_sim_sig[-offset:]\n",
    "# widths = np.arange(1, 31)\n",
    "# cwtmatr, freqs = pywt.cwt(sig, widths, wavelet_name)\n",
    "# f = scale2frequency(wavelet_name, widths)/Fs \n",
    "\n",
    "# fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(20,5))\n",
    "# ax1.plot(t,sig)\n",
    "# ax1.set_xlim(t[0], t[-1])\n",
    "# # ax2.imshow(cwtmatr, extent=[-1, 1, 1, 31], cmap='PRGn', aspect='auto',\n",
    "# #             vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())  # doctest: +SKIP\n",
    "\n",
    "# ax2.imshow(cwtmatr, extent=[-1, 1, f[0], f[-1]], cmap='viridis', aspect='auto',\n",
    "#             vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())  # doctest: +SKIP\n",
    "\n",
    "# ax3.plot(t[50:-50], cwtmatr[1,50:-50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig = br_sim_sig[0:int(100*Fs)]\n",
    "# aaa = scipy.fftpack.fft(sig)\n",
    "\n",
    "# T = 1/Fs\n",
    "# N = sig.shape[0]\n",
    "# xf = np.linspace(0.0, 1.0/(2.0*T), int(N/2)+1)\n",
    "\n",
    "# xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import signal\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Generate a test signal, a 2 Vrms sine wave at 1234 Hz, corrupted by 0.001 V**2/Hz of white noise sampled at 10 kHz.\n",
    "\n",
    "# fs = 10e3\n",
    "# N = 1e5\n",
    "# amp = 2*np.sqrt(2)\n",
    "# freq = 1234.0\n",
    "# noise_power = 0.001 * fs / 2\n",
    "# time = np.arange(N) / fs\n",
    "# x = amp*np.sin(2*np.pi*freq*time)\n",
    "# x += np.random.normal(scale=np.sqrt(noise_power), size=time.shape)\n",
    "\n",
    "\n",
    "# f, Pxx_den = signal.welch(x, fs, nperseg=1024)\n",
    "# plt.semilogy(f, Pxx_den)\n",
    "# plt.ylim([0.5e-3, 1])\n",
    "# plt.xlabel('frequency [Hz]')\n",
    "# plt.ylabel('PSD [V**2/Hz]')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(Pxx_den[256:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# f, Pxx_spec = signal.welch(x, fs, 'flattop', 1024, scaling='spectrum')\n",
    "# plt.figure()\n",
    "# plt.semilogy(f, np.sqrt(Pxx_spec))\n",
    "# plt.xlabel('frequency [Hz]')\n",
    "# plt.ylabel('Linear spectrum [V RMS]')\n",
    "# plt.show()\n",
    "# # The peak height in the power spectrum is an estimate of the RMS amplitude.\n",
    "\n",
    "# np.sqrt(Pxx_spec.max())\n",
    "# # 2.0077340678640727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================== TEST ========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check normalization\n",
    "TODO: make these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Pxx, freqs, bins = plot_sig_spectrogram(br_sim_sig, br, Fs, cmap=cmap)\n",
    "# # indices = Pxx.argmax(axis=0)\n",
    "# # br_arr = freqs[indices]*60 \n",
    "# # print(br_arr.max(), br_arr.min())\n",
    "\n",
    "# # Pxx, freqs, bins = plot_sig_spectrogram(ECG_AM_filt, br, Fs, cmap=cmap)\n",
    "\n",
    "# # indices = Pxx.argmax(axis=0)\n",
    "# # br_arr = freqs[indices]*60 \n",
    "# # print(br_arr.max(), br_arr.min())\n",
    "\n",
    "\n",
    "# # Pxx, freqs, bins = plot_sig_spectrogram(SCG_AM_filt, br, Fs, cmap=cmap)\n",
    "# # indices = Pxx.argmax(axis=0)\n",
    "# # br_arr = freqs[indices]*60 \n",
    "# # print(br_arr.max(), br_arr.min())\n",
    "\n",
    "# ####### sig normalized (+1/-1)\n",
    "\n",
    "# print(br.max(), br.min())\n",
    "\n",
    "# Pxx1, freqs, bins = plot_sig_spectrogram(br_sim_sig, br, Fs, cmap=cmap)\n",
    "# indices = Pxx1.argmax(axis=0)\n",
    "# br_arr1 = freqs[indices]*60 \n",
    "# print(br_arr1.max(), br_arr1.min())\n",
    "\n",
    "# Pxx2, freqs, bins = plot_sig_spectrogram(ECG_AM_norm, br, Fs, cmap=cmap)\n",
    "\n",
    "# indices = Pxx2.argmax(axis=0)\n",
    "# br_arr2 = freqs[indices]*60 \n",
    "# print(br_arr2.max(), br_arr2.min())\n",
    "\n",
    "\n",
    "# # Pxx3, freqs, bins = plot_sig_spectrogram(SCG_AM_norm, br, Fs, cmap=cmap)\n",
    "# # indices = Pxx3.argmax(axis=0)\n",
    "# # br_arr3 = freqs[indices]*60 \n",
    "# # print(br_arr3.max(), br_arr3.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check xcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lag_finder(y1, y2, sr):\n",
    "#     n = len(y1)\n",
    "\n",
    "#     corr = signal.correlate(y2, y1, mode='same') / np.sqrt(signal.correlate(y1, y1, mode='same')[int(n/2)] * signal.correlate(y2, y2, mode='same')[int(n/2)])\n",
    "\n",
    "#     delay_arr = np.linspace(-0.5*n/sr, 0.5*n/sr, n)\n",
    "#     delay = delay_arr[np.argmax(corr)]\n",
    "#     print('y2 is ' + str(delay) + ' behind y1')\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(delay_arr, corr)\n",
    "#     plt.title('Lag: ' + str(np.round(delay, 3)) + ' s')\n",
    "#     plt.xlabel('Lag')\n",
    "#     plt.ylabel('Correlation coeff')\n",
    "#     plt.show()\n",
    "#     return delay\n",
    "\n",
    "# t = np.arange(br_sim_sig.shape[0])/Fs\n",
    "\n",
    "\n",
    "# shift = lag_finder(br_sim_sig, ECG_AM_norm, sr=Fs)\n",
    "\n",
    "\n",
    "# figure, (ax0) = plt.subplots(1, 1, figsize=(40,2))\n",
    "\n",
    "# ax0.plot(t, br_sim_sig, 'blue')\n",
    "\n",
    "# ax0.plot(t, ECG_AM_norm, 'red', alpha=0.5)\n",
    "\n",
    "# ax0.scatter(t+shift, ECG_AM_norm, c='k',s=0.01, alpha=0.8)\n",
    "# ax0.set_xlabel('time (sec)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# another approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_names = ['time', 'ECG', 'accelX', 'accelY', 'accelZ', \n",
    "#                 'br', 'br_sim_sig', \n",
    "#                 'ECG_AM', 'ECG_FM', 'ECG_BW', \n",
    "#                 'SCG_AM', 'SCG_FM', 'SCG_BW', \n",
    "#                 'PEP_FM', \n",
    "#                 'task_id', 'subject_id'\n",
    "#                ]\n",
    "\n",
    "# indices_data = [1,2,3,4,7,10,13]\n",
    "# indices_data = [1,4]\n",
    "# indices_label = [5,6]\n",
    "# indices_meta = [14,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer_dur = 5 # sec, don't use the first and last 5 seconds\n",
    "# window_dur = 8 # sec, please refer to the RespNet paper\n",
    "# window_size = int(window_dur*Fs)\n",
    "\n",
    "# overlap_perc = 0.5\n",
    "\n",
    "# window_shift = int((1-overlap_perc)*window_size)\n",
    "        \n",
    "    \n",
    "# data_windows = []\n",
    "\n",
    "# for subject_id in df_subjects.keys():   \n",
    "#     print('working on subject', subject_id)\n",
    "    \n",
    "#     df = df_subjects[subject_id]    \n",
    "\n",
    "    \n",
    "#     TASKS = np.unique(df_subjects[subject_id]['task_id'])\n",
    "#     for task_id in TASKS:\n",
    "#         df_task = df[df['task_id']==task_id] \n",
    "        \n",
    "#         data_matrix = df_task[column_names].values\n",
    "#         data_matrix = data_matrix[buffer_dur*Fs:-buffer_dur*Fs]\n",
    "\n",
    "\n",
    "\n",
    "#         N_window = math.floor((data_matrix.shape[0]-window_size)/window_shift)+1 # the amount of epochs there should be\n",
    "\n",
    "#         indexer = np.arange(window_size)[None, :] + window_shift*np.arange(N_window)[:, None]\n",
    "#         data_matrix = data_matrix[indexer,:]\n",
    "# #         sys.exit()\n",
    "#         # TODO: move downsample to stage2 so I can inspect the effect of downsampling\n",
    "# #         data_matrix = data_matrix[:,::10,:]\n",
    "#         data_windows.append(data_matrix)\n",
    "        \n",
    "# data_windows = np.concatenate(data_windows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_all = np.unique(data_windows[:,0,-1])\n",
    "# N_sub = ids_all.shape[0]\n",
    "# # np.shuffle(i_sub_unique_all)\n",
    "\n",
    "# np.random.seed(i_seed)\n",
    "# np.random.shuffle(ids_all)\n",
    "# # i_sub_unique_all\n",
    "\n",
    "# ids_train = ids_all[:int(N_sub*.7)]\n",
    "# ids_val = ids_train[int(ids_train.shape[0]*.7):]\n",
    "# ids_train = ids_train[:int(ids_train.shape[0]*.7)]\n",
    "\n",
    "\n",
    "# ids_test = ids_all[int(N_sub*.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_train, ids_val, ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_indices_set(ids_arr, data_arr):\n",
    "#     indices_set = []\n",
    "#     for id_sub in ids_arr:\n",
    "#         indices_set.append(np.where(data_arr==id_sub)[0])\n",
    "#     return np.concatenate(indices_set)\n",
    "\n",
    "\n",
    "\n",
    "# indices_train = get_indices_set(ids_train, data_windows[:,0,-1])\n",
    "# indices_val = get_indices_set(ids_val, data_windows[:,0,-1])\n",
    "# indices_test = get_indices_set(ids_test, data_windows[:,0,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_matrix(data_windows, indices_set, set_name='null'):\n",
    "\n",
    "#     data = data_windows[:,:,indices_data][indices_set,:,:]\n",
    "#     label = data_windows[:,:,indices_label][indices_set,:,:]\n",
    "#     meta = data_windows[:,:,indices_meta][indices_set,0,:]\n",
    "#     return data, label, meta\n",
    "\n",
    "# def save_matrix(data, label, meta, outputdir, set_name='null'):\n",
    "#     outputdir_set = outputdir+set_name+'/'\n",
    "\n",
    "#     if not os.path.exists(outputdir_set):\n",
    "#         os.makedirs(outputdir_set)\n",
    "\n",
    "#     data_saver(data, 'data', outputdir_set)\n",
    "#     data_saver(label, 'label', outputdir_set)\n",
    "#     data_saver(meta, 'meta', outputdir_set)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalization (0 mean unit variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train, label_train, meta_train = split_matrix(data_windows, indices_train, set_name='train')\n",
    "# data_val, label_val, meta_val = split_matrix(data_windows, indices_val, set_name='val')\n",
    "# data_test, label_test, meta_test = split_matrix(data_windows, indices_test, set_name='test')\n",
    "\n",
    "# data_mean = data_train.mean()\n",
    "# data_std = data_train.std()\n",
    "\n",
    "# data_train = (data_train - data_mean) / data_std\n",
    "# data_val = (data_val - data_mean) / data_std\n",
    "# data_test = (data_test - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_matrix(data_train, label_train, meta_train, outputdir, set_name='train')\n",
    "# save_matrix(data_val, label_val, meta_val, outputdir, set_name='val')\n",
    "# save_matrix(data_test, label_test, meta_test, outputdir, set_name='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for axis in range(aaa.shape[2]):\n",
    "#     fig=plt.figure(figsize=(5, 5), dpi= 80, facecolor='w', edgecolor='k')\n",
    "#     ax = fig.add_subplot(1, 1, 1)\n",
    "#     ax.hist(aaa.reshape(-1), 200, alpha=0.5, label='axis{}'.format(axis))\n",
    "#     ax.legend( fontsize = 15 )\n",
    "#     ax.set_ylabel('count', fontsize = 15)\n",
    "#     ax.set_xlabel('raw value (a.u.)', fontsize = 15)\n",
    "#     ax.set_title('raw value distribution', fontsize = 20)\n",
    "\n",
    "#     ax.set_xlim([np.min(aaa),np.max(aaa)])\n",
    "\n",
    "#     fig.savefig(outputdir + 'raw_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all.shape, actlabels_all.shape, sub_all.shape, DataNameList_idx_all.shape\n",
    "\n",
    "# data_saver(data_all, 'data', outputdir_train)\n",
    "# data_saver(actlabels_all, 'labels', outputdir_train)\n",
    "# data_saver(sub_all, 'i_sub', outputdir_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # for set_name in ['train', 'val', 'test']:\n",
    "\n",
    "# def save_data_ML()\n",
    "#     outputdir_set = outputdir+set_name+'/'\n",
    "\n",
    "#     if not os.path.exists(outputdir_set):\n",
    "#         os.makedirs(outputdir_set)\n",
    "\n",
    "#     data_saver(data, 'data', outputdir_set)\n",
    "#     data_saver(label, 'label', outputdir_set)\n",
    "#     data_saver(meta, 'meta', outputdir_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# print('{}\\t{}\\t{}\\t{}\\t\\t{}'.format('sig', 'MSE_peaks', 'MSE_valleys', 'xcoeff', 'delay'))\n",
    "\n",
    "\n",
    "# for i, surrogate_name in enumerate(surrogate_dict.keys()):\n",
    "\n",
    "#     sig_mod = surrogate_dict[surrogate_name]['normed']\n",
    "\n",
    "\n",
    "#     RR_peaks, RR_valleys = get_RR_interp(ts, sig_mod)\n",
    "    \n",
    "#     r = np.corrcoef(RR_label, RR_peaks)\n",
    "    \n",
    "    \n",
    "#     RMSE_peaks = np.sqrt(mean_squared_error(RR_label[indices_RR], RR_peaks[indices_RR]))\n",
    "#     RMSE_valleys = np.sqrt(mean_squared_error(RR_label[indices_RR], RR_valleys[indices_RR]))\n",
    "#     xcoeff = np.corrcoef( sig_mod, br_sim_sig )[0,1]\n",
    "    \n",
    "# #     fig = plt.figure(figsize=(12,4), dpi=60)\n",
    "# #     ax = fig.add_subplot(111)\n",
    "# #     ax.plot(t_raw, br_sim_sig, 'steelblue')\n",
    "# #     ax.plot(t_raw, sig_mod, 'r')\n",
    "\n",
    "#     npts = sig_mod.shape[0]\n",
    "#     lags = np.arange(-npts + 1, npts)\n",
    "\n",
    "#     ccov = np.correlate(sig_mod - sig_mod.mean(), br_sim_sig_norm - br_sim_sig_norm.mean(), mode='full')\n",
    "#     ccor = ccov / (npts * sig_mod.std() * br_sim_sig_norm.std())\n",
    "\n",
    "#     fig = plt.figure(figsize=(12,4), dpi=60)\n",
    "\n",
    "# #     fig, axs = plt.subplots(nrows=2, dpi=60)\n",
    "#     fig.subplots_adjust(hspace=0.4)\n",
    "#     ax = fig.add_subplot(2,1,1)\n",
    "#     ax.plot(t_raw, sig_mod, 'b', label='sig_mod')\n",
    "#     ax.plot(t_raw, br_sim_sig_norm, 'r', label='br_sim')\n",
    "#     ax.set_ylim(-10, 10)\n",
    "#     ax.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "\n",
    "#     ax = fig.add_subplot(2,1,2)\n",
    "#     ax.plot(lags/1000, ccor)\n",
    "\n",
    "#     i = ccor.argmax()\n",
    "#     ax.scatter((i-npts)/1000, ccor[i])\n",
    "    \n",
    "#     delay = (i-npts)/1000\n",
    "    \n",
    "#     print('{}\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}\\t\\t{:.2f}'.format(surrogate_name, RMSE_peaks, RMSE_valleys, xcoeff, delay))\n",
    "# #     sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# for i, acc_name in enumerate(['accelX', 'accelY', 'accelZ']):\n",
    "#     sig_beats = scg_beats[acc_name]\n",
    "\n",
    "#     # TODO: replace this with SQI based outlier removal\n",
    "#     indices_CI = arg_CI(np.var(sig_beats,axis=0), confidence_interv=90)\n",
    "#     print(indices_CI.shape)\n",
    "#     sig_beats = sig_beats[:,indices_CI]\n",
    "    \n",
    "    \n",
    "#     (i_aos, data_aos) = i_fiducials[acc_name]\n",
    "\n",
    "#     ax = fig.add_subplot(3, 1, i+1)\n",
    "#     plot_beats(ax, sig_beats, i_fiducials=(i_aos[indices_CI], data_aos[indices_CI]), Fs=FS_SCG, sig_name='[{}, {}] - {}'.format(subject_id, task_name, acc_name), color='steelblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(4,12), dpi=80)\n",
    "\n",
    "# for i, acc_name in enumerate(['accelX', 'accelY', 'accelZ']):\n",
    "#     sig_beats = scg_beats[acc_name]\n",
    "\n",
    "#     # TODO: replace this with SQI based outlier removal\n",
    "#     indices_CI = arg_CI(np.var(sig_beats,axis=0), confidence_interv=90)\n",
    "#     print(indices_CI.shape)\n",
    "#     sig_beats = sig_beats[:,indices_CI]\n",
    "    \n",
    "    \n",
    "#     (i_aos, data_aos) = i_fiducials[acc_name]\n",
    "\n",
    "#     ax = fig.add_subplot(3, 1, i+1)\n",
    "#     plot_beats(ax, sig_beats, i_fiducials=(i_aos[indices_CI], data_aos[indices_CI]), Fs=FS_SCG, sig_name='[{}, {}] - {}'.format(subject_id, task_name, acc_name), color='steelblue')\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspect patch signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # don't really need this (TBD)\n",
    "# def plot_sig_spectrogram(sig, FS):\n",
    "#     x = sig\n",
    "#     N = x.shape[0]\n",
    "#     t_sig = np.linspace(0, (N-1)/FS, N, endpoint=False)\n",
    "\n",
    "#     f, t, Sxx = signal.spectrogram(x, FS, nperseg=128)\n",
    "\n",
    "#     figure, (ax_raw, ax_spectrogram) = plt.subplots(2, 1, figsize=(20,3))\n",
    "\n",
    "#     ax_raw.plot(t_sig, x, 'red')\n",
    "#     ax_raw.set_xlim([0,t_sig[-1]])\n",
    "\n",
    "#     fontdict = {'size': 10}\n",
    "\n",
    "#     NFFT = int(FS*0.5)  # 5ms window\n",
    "#     noverlap = int(FS*0.5)\n",
    "\n",
    "#     Pxx, freqs, bins, im = ax_spectrogram.specgram(x,Fs=FS, NFFT=NFFT)\n",
    "#     ax_spectrogram.set_xlim([0,t_sig[-1]])\n",
    "\n",
    "#     ax_spectrogram.set_xlabel('time (sec)', fontdict=fontdict)\n",
    "#     ax_spectrogram.set_ylabel('Freq (Hz)', fontdict=fontdict)\n",
    "    \n",
    "\n",
    "# # plot_sig_spectrogram(sig=ecg_filt, FS=FS_ECG)\n",
    "\n",
    "# def get_spetral(sig):\n",
    "\n",
    "#     N_window = sig.shape[0]\n",
    "\n",
    "#     sig_spectral = np.zeros((N_window//2, sig.shape[1]))\n",
    "#     T = 1/FS_ACC\n",
    "#     sig_f = np.linspace(0.0, 1.0/(2.0*T), int(N_window/2))\n",
    "\n",
    "#     for i in range(sig.shape[1]):\n",
    "#         v_sig = sig[:,i]\n",
    "#         yf = scipy.fftpack.fft(v_sig)\n",
    "#         yf_scaled = 2.0/N * np.abs(yf[:N_window//2])\n",
    "#         sig_spectral[:,i] = yf_scaled\n",
    "\n",
    "#     return sig_f, sig_spectral\n",
    "\n",
    "# ecg_f, ecg_spectral = get_spetral(ecg_beats)\n",
    "\n",
    "# def plot_spectral(xf, yf, freq_show=100):\n",
    "\n",
    "#     fig = plt.figure(figsize=(5, 5), dpi=80)\n",
    "#     fontdict = {'size': 15}\n",
    "\n",
    "#     ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "#     # freq_show = 100 # Hz\n",
    "#     yf = yf[xf<freq_show,:]\n",
    "#     xf = xf[xf<freq_show]\n",
    "\n",
    "#     ax.plot(xf, yf, color='skyblue', alpha=0.3)\n",
    "#     ax.plot(xf, yf.mean(axis=1), color='steelblue')\n",
    "\n",
    "#     ax.scatter(xf[yf.mean(axis=1).argmax()], yf.mean(axis=1).max(), s=35, color='steelblue', zorder=5)\n",
    "    \n",
    "#     ax.set_title( 'Frequency domain', fontdict=fontdict)\n",
    "#     ax.set_xlabel('frequency (Hz)', fontdict=fontdict)\n",
    "#     ax.set_ylabel('mag (a.u.)', fontdict=fontdict)\n",
    "    \n",
    "# # plot_spectral(acc_f, acc_spectral[:,0:50], freq_show=100)\n",
    "# def get_envelope(sig):\n",
    "#     analytic_signal = hilbert(sig)\n",
    "#     amplitude_envelope = np.abs(analytic_signal)\n",
    "#     return amplitude_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mienv",
   "language": "python",
   "name": "mienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
